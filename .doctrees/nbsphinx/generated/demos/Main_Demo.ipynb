{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/neelnanda-io/TransformerLens/blob/main/demos/Main_Demo.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer Lens Main Demo Notebook\n",
    "\n",
    "<b style=\"color: red\">To use this notebook, go to Runtime > Change Runtime Type and select GPU as the hardware accelerator.</b>\n",
    "\n",
    "This is a reference notebook covering the main features of the [TransformerLens](https://github.com/neelnanda-io/TransformerLens) library for mechanistic interpretability. See [Callum McDougall's tutorial](https://transformerlens-intro.streamlit.app/TransformerLens_&_induction_circuits) for a more structured and gentler introduction to the library"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tips for reading this Colab:**\n",
    "* You can run all this code for yourself! \n",
    "* The graphs are interactive!\n",
    "* Use the table of contents pane in the sidebar to navigate\n",
    "* Collapse irrelevant sections with the dropdown arrows\n",
    "* Search the page using the search in the sidebar, not CTRL+F"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "(No need to read)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-08T19:27:24.221758Z",
     "iopub.status.busy": "2023-11-08T19:27:24.221260Z",
     "iopub.status.idle": "2023-11-08T19:27:24.232172Z",
     "shell.execute_reply": "2023-11-08T19:27:24.231710Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "DEVELOPMENT_MODE = False\n",
    "# Detect if we're running in Google Colab\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "    print(\"Running as a Colab notebook\")\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "\n",
    "# Install if in Colab\n",
    "if IN_COLAB:\n",
    "    %pip install transformer_lens\n",
    "    %pip install circuitsvis\n",
    "    # Install a faster Node version\n",
    "    !curl -fsSL https://deb.nodesource.com/setup_16.x | sudo -E bash -; sudo apt-get install -y nodejs  # noqa\n",
    "\n",
    "# Hot reload in development mode & not running on the CD\n",
    "if not IN_COLAB:\n",
    "    from IPython import get_ipython\n",
    "    ip = get_ipython()\n",
    "    if not ip.extension_manager.loaded:\n",
    "        ip.extension_manager.load('autoreload')\n",
    "        %autoreload 2\n",
    "        \n",
    "IN_GITHUB = os.getenv(\"GITHUB_ACTIONS\") == \"true\"\n",
    "IN_GITHUB = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-08T19:27:24.234347Z",
     "iopub.status.busy": "2023-11-08T19:27:24.234003Z",
     "iopub.status.idle": "2023-11-08T19:27:24.359298Z",
     "shell.execute_reply": "2023-11-08T19:27:24.358774Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using renderer: colab\n"
     ]
    }
   ],
   "source": [
    "# Plotly needs a different renderer for VSCode/Notebooks vs Colab argh\n",
    "import plotly.io as pio\n",
    "if IN_COLAB or not DEVELOPMENT_MODE:\n",
    "    pio.renderers.default = \"colab\"\n",
    "else:\n",
    "    pio.renderers.default = \"notebook_connected\"\n",
    "print(f\"Using renderer: {pio.renderers.default}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-08T19:27:24.361526Z",
     "iopub.status.busy": "2023-11-08T19:27:24.361157Z",
     "iopub.status.idle": "2023-11-08T19:27:25.788323Z",
     "shell.execute_reply": "2023-11-08T19:27:25.787692Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"circuits-vis-7dbbc636-2c5c\" style=\"margin: 15px 0;\"/>\n",
       "    <script crossorigin type=\"module\">\n",
       "    import { render, Hello } from \"https://unpkg.com/circuitsvis@1.43.1/dist/cdn/esm.js\";\n",
       "    render(\n",
       "      \"circuits-vis-7dbbc636-2c5c\",\n",
       "      Hello,\n",
       "      {\"name\": \"Neel\"}\n",
       "    )\n",
       "    </script>"
      ],
      "text/plain": [
       "<circuitsvis.utils.render.RenderedHTML at 0x7fa320414510>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import circuitsvis as cv\n",
    "# Testing that the library works\n",
    "cv.examples.hello(\"Neel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-08T19:27:25.790764Z",
     "iopub.status.busy": "2023-11-08T19:27:25.790324Z",
     "iopub.status.idle": "2023-11-08T19:27:26.093078Z",
     "shell.execute_reply": "2023-11-08T19:27:26.092470Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import stuff\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import einops\n",
    "from fancy_einsum import einsum\n",
    "import tqdm.auto as tqdm\n",
    "import plotly.express as px\n",
    "\n",
    "from jaxtyping import Float\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-08T19:27:26.095755Z",
     "iopub.status.busy": "2023-11-08T19:27:26.095235Z",
     "iopub.status.idle": "2023-11-08T19:27:27.535025Z",
     "shell.execute_reply": "2023-11-08T19:27:27.534376Z"
    }
   },
   "outputs": [],
   "source": [
    "# import transformer_lens\n",
    "import transformer_lens.utils as utils\n",
    "from transformer_lens.hook_points import (\n",
    "    HookPoint,\n",
    ")  # Hooking utilities\n",
    "from transformer_lens import HookedTransformer, FactoredMatrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We turn automatic differentiation off, to save GPU memory, as this notebook focuses on model inference not model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-08T19:27:27.537914Z",
     "iopub.status.busy": "2023-11-08T19:27:27.537550Z",
     "iopub.status.idle": "2023-11-08T19:27:27.541401Z",
     "shell.execute_reply": "2023-11-08T19:27:27.540845Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x7fa22a5a9e10>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting helper functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-08T19:27:27.543545Z",
     "iopub.status.busy": "2023-11-08T19:27:27.543183Z",
     "iopub.status.idle": "2023-11-08T19:27:27.547943Z",
     "shell.execute_reply": "2023-11-08T19:27:27.547459Z"
    }
   },
   "outputs": [],
   "source": [
    "def imshow(tensor, renderer=None, xaxis=\"\", yaxis=\"\", **kwargs):\n",
    "    px.imshow(utils.to_numpy(tensor), color_continuous_midpoint=0.0, color_continuous_scale=\"RdBu\", labels={\"x\":xaxis, \"y\":yaxis}, **kwargs).show(renderer)\n",
    "\n",
    "def line(tensor, renderer=None, xaxis=\"\", yaxis=\"\", **kwargs):\n",
    "    px.line(utils.to_numpy(tensor), labels={\"x\":xaxis, \"y\":yaxis}, **kwargs).show(renderer)\n",
    "\n",
    "def scatter(x, y, xaxis=\"\", yaxis=\"\", caxis=\"\", renderer=None, **kwargs):\n",
    "    x = utils.to_numpy(x)\n",
    "    y = utils.to_numpy(y)\n",
    "    px.scatter(y=y, x=x, labels={\"x\":xaxis, \"y\":yaxis, \"color\":caxis}, **kwargs).show(renderer)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a demo notebook for [TransformerLens](https://github.com/neelnanda-io/TransformerLens), **a library I ([Neel Nanda](https://neelnanda.io)) wrote for doing [mechanistic interpretability](https://distill.pub/2020/circuits/zoom-in/) of GPT-2 Style language models.** The goal of mechanistic interpretability is to take a trained model and reverse engineer the algorithms the model learned during training from its weights. It is a fact about the world today that we have computer programs that can essentially speak English at a human level (GPT-3, PaLM, etc), yet we have no idea how they work nor how to write one ourselves. This offends me greatly, and I would like to solve this! Mechanistic interpretability is a very young and small field, and there are a *lot* of open problems - if you would like to help, please try working on one! **If you want to skill up, check out [my guide to getting started](https://neelnanda.io/getting-started), and if you want to jump into an open problem check out my sequence [200 Concrete Open Problems in Mechanistic Interpretability](https://neelnanda.io/concrete-open-problems).**\n",
    "\n",
    "I wrote this library because after I left the Anthropic interpretability team and started doing independent research, I got extremely frustrated by the state of open source tooling. There's a lot of excellent infrastructure like HuggingFace and DeepSpeed to *use* or *train* models, but very little to dig into their internals and reverse engineer how they work. **This library tries to solve that**, and to make it easy to get into the field even if you don't work at an industry org with real infrastructure! The core features were heavily inspired by [Anthropic's excellent Garcon tool](https://transformer-circuits.pub/2021/garcon/index.html). Credit to Nelson Elhage and Chris Olah for building Garcon and showing me the value of good infrastructure for accelerating exploratory research!\n",
    "\n",
    "The core design principle I've followed is to enable exploratory analysis - one of the most fun parts of mechanistic interpretability compared to normal ML is the extremely short feedback loops! The point of this library is to keep the gap between having an experiment idea and seeing the results as small as possible, to make it easy for **research to feel like play** and to enter a flow state. This notebook demonstrates how the library works and how to use it, but if you want to see how well it works for exploratory research, check out [my notebook analysing Indirect Objection Identification](https://neelnanda.io/exploratory-analysis-demo) or [my recording of myself doing research](https://www.youtube.com/watch?v=yo4QvDn-vsU)!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and Running Models\n",
    "\n",
    "TransformerLens comes loaded with >40 open source GPT-style models. You can load any of them in with `HookedTransformer.from_pretrained(MODEL_NAME)`. For this demo notebook we'll look at GPT-2 Small, an 80M parameter model, see the Available Models section for info on the rest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-08T19:27:27.550169Z",
     "iopub.status.busy": "2023-11-08T19:27:27.549849Z",
     "iopub.status.idle": "2023-11-08T19:27:27.552733Z",
     "shell.execute_reply": "2023-11-08T19:27:27.552239Z"
    }
   },
   "outputs": [],
   "source": [
    "device = utils.get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-08T19:27:27.554840Z",
     "iopub.status.busy": "2023-11-08T19:27:27.554508Z",
     "iopub.status.idle": "2023-11-08T19:27:29.895555Z",
     "shell.execute_reply": "2023-11-08T19:27:29.894913Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2-small into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "# NBVAL_IGNORE_OUTPUT\n",
    "model = HookedTransformer.from_pretrained(\"gpt2-small\", device=device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To try the model out, let's find the loss on this text! Models can be run on a single string or a tensor of tokens (shape: [batch, position], all integers), and the possible return types are: \n",
    "* \"logits\" (shape [batch, position, d_vocab], floats), \n",
    "* \"loss\" (the cross-entropy loss when predicting the next token), \n",
    "* \"both\" (a tuple of (logits, loss)) \n",
    "* None (run the model, but don't calculate the logits - this is faster when we only want to use intermediate activations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-08T19:27:29.897994Z",
     "iopub.status.busy": "2023-11-08T19:27:29.897614Z",
     "iopub.status.idle": "2023-11-08T19:27:30.223623Z",
     "shell.execute_reply": "2023-11-08T19:27:30.222994Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loss: tensor(4.1758)\n"
     ]
    }
   ],
   "source": [
    "model_description_text = \"\"\"## Loading Models\n",
    "\n",
    "HookedTransformer comes loaded with >40 open source GPT-style models. You can load any of them in with `HookedTransformer.from_pretrained(MODEL_NAME)`. See my explainer for documentation of all supported models, and this table for hyper-parameters and the name used to load them. Each model is loaded into the consistent HookedTransformer architecture, designed to be clean, consistent and interpretability-friendly. \n",
    "\n",
    "For this demo notebook we'll look at GPT-2 Small, an 80M parameter model. To try the model the model out, let's find the loss on this paragraph!\"\"\"\n",
    "loss = model(model_description_text, return_type=\"loss\")\n",
    "print(\"Model loss:\", loss)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caching all Activations\n",
    "\n",
    "The first basic operation when doing mechanistic interpretability is to break open the black box of the model and look at all of the internal activations of a model. This can be done with `logits, cache = model.run_with_cache(tokens)`. Let's try this out on the first line of the abstract of the GPT-2 paper.\n",
    "\n",
    "<details><summary>On `remove_batch_dim`</summary>\n",
    "\n",
    "Every activation inside the model begins with a batch dimension. Here, because we only entered a single batch dimension, that dimension is always length 1 and kinda annoying, so passing in the `remove_batch_dim=True` keyword removes it. `gpt2_cache_no_batch_dim = gpt2_cache.remove_batch_dim()` would have achieved the same effect.\n",
    "</details?>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-08T19:27:30.225957Z",
     "iopub.status.busy": "2023-11-08T19:27:30.225586Z",
     "iopub.status.idle": "2023-11-08T19:27:30.355507Z",
     "shell.execute_reply": "2023-11-08T19:27:30.354875Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "gpt2_text = \"Natural language processing tasks, such as question answering, machine translation, reading comprehension, and summarization, are typically approached with supervised learning on taskspecific datasets.\"\n",
    "gpt2_tokens = model.to_tokens(gpt2_text)\n",
    "print(gpt2_tokens.device)\n",
    "gpt2_logits, gpt2_cache = model.run_with_cache(gpt2_tokens, remove_batch_dim=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize the attention pattern of all the heads in layer 0, using [Alan Cooney's CircuitsVis library](https://github.com/alan-cooney/CircuitsVis) (based on [Anthropic's PySvelte library](https://github.com/anthropics/PySvelte)). \n",
    "\n",
    "We look this the attention pattern in `gpt2_cache`, an `ActivationCache` object, by entering in the name of the activation, followed by the layer index (here, the activation is called \"attn\" and the layer index is 0). This has shape [head_index, destination_position, source_position], and we use the `model.to_str_tokens` method to convert the text to a list of tokens as strings, since there is an attention weight between each pair of tokens.\n",
    "\n",
    "This visualization is interactive! Try hovering over a token or head, and click to lock. The grid on the top left and for each head is the attention pattern as a destination position by source position grid. It's lower triangular because GPT-2 has **causal attention**, attention can only look backwards, so information can only move forwards in the network.\n",
    "\n",
    "See the ActivationCache section for more on what `gpt2_cache` can do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-08T19:27:30.357935Z",
     "iopub.status.busy": "2023-11-08T19:27:30.357599Z",
     "iopub.status.idle": "2023-11-08T19:27:30.362026Z",
     "shell.execute_reply": "2023-11-08T19:27:30.361473Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'transformer_lens.ActivationCache.ActivationCache'>\n",
      "torch.Size([12, 33, 33])\n"
     ]
    }
   ],
   "source": [
    "print(type(gpt2_cache))\n",
    "attention_pattern = gpt2_cache[\"pattern\", 0, \"attn\"]\n",
    "print(attention_pattern.shape)\n",
    "gpt2_str_tokens = model.to_str_tokens(gpt2_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-08T19:27:30.364023Z",
     "iopub.status.busy": "2023-11-08T19:27:30.363696Z",
     "iopub.status.idle": "2023-11-08T19:27:30.486226Z",
     "shell.execute_reply": "2023-11-08T19:27:30.485688Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0 Head Attention Patterns:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div id=\"circuits-vis-646c0315-7105\" style=\"margin: 15px 0;\"/>\n",
       "    <script crossorigin type=\"module\">\n",
       "    import { render, AttentionPatterns } from \"https://unpkg.com/circuitsvis@1.43.1/dist/cdn/esm.js\";\n",
       "    render(\n",
       "      \"circuits-vis-646c0315-7105\",\n",
       "      AttentionPatterns,\n",
       "      {\"tokens\": [\"<|endoftext|>\", \"Natural\", \" language\", \" processing\", \" tasks\", \",\", \" such\", \" as\", \" question\", \" answering\", \",\", \" machine\", \" translation\", \",\", \" reading\", \" comprehension\", \",\", \" and\", \" summar\", \"ization\", \",\", \" are\", \" typically\", \" approached\", \" with\", \" supervised\", \" learning\", \" on\", \" tasks\", \"pe\", \"cific\", \" datasets\", \".\"], \"attention\": [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9639418721199036, 0.03605814278125763, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8389372229576111, 0.1182878389954567, 0.04277484863996506, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4743611216545105, 0.13382025063037872, 0.27371737360954285, 0.11810112744569778, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.35606443881988525, 0.10184910148382187, 0.23054225742816925, 0.20397400856018066, 0.10757027566432953, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6660143733024597, 0.16866376996040344, 0.04535674676299095, 0.03885500505566597, 0.06775480508804321, 0.013355279341340065, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.38626962900161743, 0.285109281539917, 0.07609006762504578, 0.05908379331231117, 0.07223352789878845, 0.039796341210603714, 0.08141741901636124, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3775394856929779, 0.1883881688117981, 0.11723987013101578, 0.08685602247714996, 0.0666918084025383, 0.03500017523765564, 0.09693004190921783, 0.03135441616177559, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4869752824306488, 0.06781316548585892, 0.07952871918678284, 0.0848078578710556, 0.1590261608362198, 0.029577823355793953, 0.025685928761959076, 0.016474608331918716, 0.050110384821891785, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2906550168991089, 0.0401349700987339, 0.14614863693714142, 0.0994059145450592, 0.15389196574687958, 0.03900161013007164, 0.02498897723853588, 0.031841278076171875, 0.10222824662923813, 0.0717034637928009, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.39624103903770447, 0.0969417542219162, 0.027270644903182983, 0.02355135791003704, 0.03723449259996414, 0.006502412259578705, 0.08118755370378494, 0.013088461011648178, 0.06990595161914825, 0.24043096601963043, 0.007645339239388704, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.24864791333675385, 0.1380205750465393, 0.09235316514968872, 0.08676129579544067, 0.1381969451904297, 0.05914197117090225, 0.03223859518766403, 0.031582385301589966, 0.03048943728208542, 0.03873482719063759, 0.06671839207410812, 0.0371144562959671, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.19148443639278412, 0.1617259532213211, 0.07445938885211945, 0.07740949094295502, 0.021961115300655365, 0.03392129763960838, 0.051250215619802475, 0.01951923593878746, 0.03132445365190506, 0.04020152613520622, 0.038742680102586746, 0.21578849852085114, 0.04221167787909508, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3704318404197693, 0.08681415021419525, 0.02458467148244381, 0.02161632478237152, 0.03238872438669205, 0.005422743037343025, 0.0727522224187851, 0.011272797361016273, 0.06329693645238876, 0.217268168926239, 0.006367159076035023, 0.029603807255625725, 0.05099845305085182, 0.007182054687291384, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.19737651944160461, 0.04603996500372887, 0.043999820947647095, 0.1337345838546753, 0.05424822121858597, 0.025475721806287766, 0.027563506737351418, 0.021570932120084763, 0.05171823501586914, 0.06458097696304321, 0.028064634650945663, 0.23551592230796814, 0.019129814580082893, 0.02996351197361946, 0.02101767621934414, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.08907235413789749, 0.019288338720798492, 0.1665353775024414, 0.07281264662742615, 0.047386400401592255, 0.024487901479005814, 0.028987325727939606, 0.019370369613170624, 0.026673024520277977, 0.0731663629412651, 0.02570459432899952, 0.042423591017723083, 0.05869460478425026, 0.02893269993364811, 0.18119069933891296, 0.0952737107872963, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2816729247570038, 0.06441289931535721, 0.018008556216955185, 0.01616961695253849, 0.023183872923254967, 0.0037532970309257507, 0.05472245812416077, 0.007909760810434818, 0.04616469517350197, 0.16947266459465027, 0.004361647181212902, 0.021011337637901306, 0.0354907289147377, 0.00493256701156497, 0.0955522358417511, 0.147263303399086, 0.005917456932365894, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.21305488049983978, 0.05912370607256889, 0.03382086753845215, 0.02747686579823494, 0.02839355543255806, 0.008422905579209328, 0.0400853268802166, 0.011629259213805199, 0.052951909601688385, 0.15404638648033142, 0.0098318075761199, 0.03610190376639366, 0.047372907400131226, 0.01106918603181839, 0.09972470253705978, 0.13971355557441711, 0.013185342773795128, 0.013994931243360043, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.15871699154376984, 0.043878890573978424, 0.08712151646614075, 0.08998464792966843, 0.030738590285182, 0.0341489352285862, 0.024917257949709892, 0.03139195591211319, 0.024823861196637154, 0.019790327176451683, 0.036254845559597015, 0.020694414153695107, 0.04284068942070007, 0.03820899501442909, 0.06234658882021904, 0.10919702053070068, 0.0413760244846344, 0.049167610704898834, 0.054400913417339325, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.10485512018203735, 0.12122291326522827, 0.0648747980594635, 0.08768714964389801, 0.03434053063392639, 0.01748395524919033, 0.03415181487798691, 0.01528915110975504, 0.023312119767069817, 0.02830650471150875, 0.018720479682087898, 0.028111927211284637, 0.041905295103788376, 0.020989559590816498, 0.04678506776690483, 0.08659638464450836, 0.023631839081645012, 0.024273160845041275, 0.16702401638031006, 0.010438229888677597, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.22901973128318787, 0.05184381082653999, 0.013585173524916172, 0.012337238527834415, 0.018005426973104477, 0.0027703619562089443, 0.04238128289580345, 0.005856256000697613, 0.03614486753940582, 0.13039222359657288, 0.003153424011543393, 0.015672560781240463, 0.027800412848591805, 0.003554322523996234, 0.07460814714431763, 0.11298281699419022, 0.00427226722240448, 0.006832206156104803, 0.18569746613502502, 0.018073637038469315, 0.005016351584345102, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.18869926035404205, 0.034387119114398956, 0.022344736382365227, 0.019972726702690125, 0.016354018822312355, 0.00685655465349555, 0.020859045907855034, 0.005695999134331942, 0.034159183502197266, 0.07260984927415848, 0.007857207208871841, 0.018040236085653305, 0.026904456317424774, 0.009020395576953888, 0.06876447051763535, 0.17578737437725067, 0.010720068588852882, 0.00928453542292118, 0.1925639808177948, 0.025180328637361526, 0.012639072723686695, 0.021299349144101143, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1195831373333931, 0.022259412333369255, 0.032947126775979996, 0.02017023041844368, 0.035653308033943176, 0.013459905982017517, 0.017516475170850754, 0.010057874955236912, 0.025856448337435722, 0.05955953523516655, 0.015084504149854183, 0.015008730813860893, 0.053174685686826706, 0.016597604379057884, 0.041555263102054596, 0.1312934160232544, 0.019296662881970406, 0.015855029225349426, 0.1792508363723755, 0.01618383638560772, 0.022295530885457993, 0.015463392250239849, 0.10187703371047974, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.14615529775619507, 0.02672750875353813, 0.016624556854367256, 0.018987691029906273, 0.06278637796640396, 0.015317165292799473, 0.019792238250374794, 0.01422776747494936, 0.025458170101046562, 0.04530354216694832, 0.016364358365535736, 0.0374930314719677, 0.01328864973038435, 0.017496539279818535, 0.0399458184838295, 0.05881757661700249, 0.019260980188846588, 0.024616027250885963, 0.038219694048166275, 0.02157779410481453, 0.020949898287653923, 0.07973216474056244, 0.050176091492176056, 0.17068107426166534, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.11321668326854706, 0.03674636408686638, 0.011786575429141521, 0.010274875909090042, 0.020370667800307274, 0.0052438885904848576, 0.015918850898742676, 0.005266785155981779, 0.024891739711165428, 0.06593259423971176, 0.005933661013841629, 0.018209032714366913, 0.021020200103521347, 0.0066674984991550446, 0.034828804433345795, 0.13742126524448395, 0.007927048951387405, 0.008618667721748352, 0.1137719601392746, 0.013557437807321548, 0.009277837350964546, 0.0261213555932045, 0.08499342948198318, 0.19073905050754547, 0.011263744905591011, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1333771049976349, 0.026216605678200722, 0.038271546363830566, 0.07152579724788666, 0.05317768082022667, 0.013925841078162193, 0.007084188517183065, 0.013450146652758121, 0.009841440245509148, 0.01178977731615305, 0.013537583872675896, 0.0381549596786499, 0.04193304851651192, 0.013882285915315151, 0.037071458995342255, 0.13838458061218262, 0.014846335165202618, 0.03156952187418938, 0.05598174408078194, 0.015536683611571789, 0.01595635898411274, 0.045455556362867355, 0.01669965125620365, 0.02532576024532318, 0.036718931049108505, 0.08028540760278702, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.10608971863985062, 0.019107716158032417, 0.024468660354614258, 0.027496395632624626, 0.01636580377817154, 0.005011421162635088, 0.010413105599582195, 0.006081141531467438, 0.005301061552017927, 0.011143162846565247, 0.004565386101603508, 0.018969915807247162, 0.004321118351072073, 0.00481497822329402, 0.029409408569335938, 0.028682027012109756, 0.005097254645079374, 0.0072343479841947556, 0.03412593528628349, 0.010370595380663872, 0.005643266253173351, 0.007283586077392101, 0.02938956581056118, 0.010038798674941063, 0.009134513325989246, 0.546663224697113, 0.012777911499142647, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.10467305779457092, 0.03321939706802368, 0.015341253019869328, 0.009373552165925503, 0.026595458388328552, 0.0057878089137375355, 0.013571349903941154, 0.004554884973913431, 0.02805890329182148, 0.026107221841812134, 0.006353435572236776, 0.013315828517079353, 0.02662825584411621, 0.006888874340802431, 0.06204750016331673, 0.05890704691410065, 0.008068052120506763, 0.007557097356766462, 0.08522787690162659, 0.017075758427381516, 0.009256888180971146, 0.019695766270160675, 0.12617811560630798, 0.13061513006687164, 0.011351045221090317, 0.0898437350988388, 0.046381521970033646, 0.007325289770960808, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0856190174818039, 0.02143894135951996, 0.056412577629089355, 0.0570666566491127, 0.019802208989858627, 0.006727498024702072, 0.005809164140373468, 0.004516260698437691, 0.0031647467985749245, 0.01761520281434059, 0.006174598820507526, 0.08767973631620407, 0.012299862690269947, 0.006350454408675432, 0.017522139474749565, 0.14295215904712677, 0.006585489492863417, 0.007875688374042511, 0.030078936368227005, 0.013907496817409992, 0.0073766945861279964, 0.007684784941375256, 0.022160839289426804, 0.01238502562046051, 0.011890063062310219, 0.08669770509004593, 0.19902527332305908, 0.013594473712146282, 0.02958623133599758, 0.0, 0.0, 0.0, 0.0], [0.14064589142799377, 0.013298705220222473, 0.015702955424785614, 0.01735786534845829, 0.02233150787651539, 0.02967226877808571, 0.04172082245349884, 0.018995430320501328, 0.03827710822224617, 0.04863562062382698, 0.03094690665602684, 0.016023889183998108, 0.020880892872810364, 0.0324382409453392, 0.030558118596673012, 0.022808337584137917, 0.03537760674953461, 0.031451597809791565, 0.03497114032506943, 0.01867910474538803, 0.038219090551137924, 0.02257886528968811, 0.06819561123847961, 0.04214095696806908, 0.028620854020118713, 0.03775002062320709, 0.018578054383397102, 0.03376872092485428, 0.03641696646809578, 0.01295685674995184, 0.0, 0.0, 0.0], [0.07168620079755783, 0.06924446672201157, 0.019306901842355728, 0.014161975122988224, 0.016823187470436096, 0.019380606710910797, 0.019257400184869766, 0.0220036618411541, 0.013706523925065994, 0.035783782601356506, 0.018465187400579453, 0.05207169055938721, 0.020085182040929794, 0.01986212283372879, 0.02066211588680744, 0.04725164175033569, 0.021076709032058716, 0.0367872416973114, 0.02432408556342125, 0.003827549982815981, 0.02392067387700081, 0.008533225394785404, 0.026241622865200043, 0.02738005481660366, 0.03461199998855591, 0.022884158417582512, 0.10047905147075653, 0.06913496553897858, 0.02547457255423069, 0.06495601683855057, 0.030615385621786118, 0.0, 0.0], [0.06910776346921921, 0.0370122455060482, 0.03862114995718002, 0.05933326855301857, 0.01592354290187359, 0.007918563671410084, 0.010371050797402859, 0.006615665275603533, 0.0025200776290148497, 0.026019366458058357, 0.00790522899478674, 0.02965201810002327, 0.040006235241889954, 0.008451342582702637, 0.010741152800619602, 0.05027563124895096, 0.009428857825696468, 0.01360103115439415, 0.05036921054124832, 0.03176715224981308, 0.010793029330670834, 0.007216803263872862, 0.006478430703282356, 0.01480061188340187, 0.021585972979664803, 0.15769484639167786, 0.08884761482477188, 0.019016927108168602, 0.02972934953868389, 0.03316137194633484, 0.05088365823030472, 0.034150850027799606, 0.0], [0.14375510811805725, 0.01681104302406311, 0.00938666146248579, 0.006830314174294472, 0.011656844057142735, 0.0015672282315790653, 0.019711479544639587, 0.002398042008280754, 0.021235888823866844, 0.04683680832386017, 0.001690514967776835, 0.005827189888805151, 0.011980000883340836, 0.0018251389265060425, 0.042313337326049805, 0.05491374433040619, 0.0021786559373140335, 0.002417011419311166, 0.09604067355394363, 0.00575287826359272, 0.0025577880442142487, 0.00712122255936265, 0.08889928460121155, 0.10852081328630447, 0.005179054569453001, 0.03657734766602516, 0.024719923734664917, 0.0037347630131989717, 0.031077098101377487, 0.016887947916984558, 0.09450866281986237, 0.07171519845724106, 0.0033723192755132914]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0004246663593221456, 0.9995753169059753, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0005621908348985016, 0.016407271847128868, 0.9830306172370911, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0011627554195001721, 0.021681973710656166, 0.0037620372604578733, 0.9733933210372925, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [3.7244368286337703e-05, 0.0001720225263852626, 0.0002814392792060971, 0.0027421435806900263, 0.9967671632766724, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.008268453180789948, 0.00023985625011846423, 7.361917960224673e-05, 6.43773382762447e-05, 0.0001756635756464675, 0.9911779761314392, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0012215046444907784, 0.00540044903755188, 0.0016716319369152188, 0.0004077559569850564, 0.0006163658108562231, 0.0010931181022897363, 0.9895892143249512, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0012459794525057077, 0.0009121232433244586, 0.0005976726533845067, 0.00013656896771863103, 0.00033041107235476375, 0.001572281587868929, 0.003880825825035572, 0.9913240671157837, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00028217487852089107, 0.004068178590387106, 0.002660515485331416, 0.0013093105517327785, 0.008030476048588753, 0.0002879090898204595, 0.00022922898642718792, 0.0003948427038267255, 0.9827372431755066, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [3.47392306139227e-05, 0.00039538307464681566, 0.00013272685464471579, 0.0002585221081972122, 0.001085555530153215, 9.198026964440942e-05, 0.000326707202475518, 0.000542744412086904, 0.006105918437242508, 0.9910256266593933, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0033785076811909676, 5.090881677460857e-05, 1.6452078853035346e-05, 1.6926167518249713e-05, 4.181407712167129e-05, 0.49394041299819946, 0.00012981290637981147, 0.0008837333880364895, 3.22120358760003e-05, 2.7252099243924022e-05, 0.5014819502830505, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [8.41604924062267e-05, 0.0013417223235592246, 0.001261359197087586, 0.0021450745407491922, 0.004042362794280052, 0.0004830532125197351, 0.00011582656588871032, 0.0001520359655842185, 2.692530870262999e-05, 0.00012675125617533922, 0.0003128990938421339, 0.9899078607559204, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0003782230196520686, 0.000983756617642939, 0.03934125974774361, 0.002732245484367013, 0.0036680209450423717, 0.00011039189848816022, 0.00012931032688356936, 0.00021743457182310522, 0.00010623293928802013, 0.0007748186471872032, 6.647665577474982e-05, 0.0003148664836771786, 0.9511768817901611, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0021017210092395544, 2.443688026687596e-05, 7.788784387230407e-06, 8.651617463328876e-06, 2.014002893702127e-05, 0.2997135818004608, 7.525280670961365e-05, 0.0004898309125564992, 1.8459475541021675e-05, 1.5344538041972555e-05, 0.32833895087242126, 4.175798312644474e-05, 6.46918533675489e-06, 0.36913764476776123, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0001496832846896723, 0.00011296618322376162, 0.00036294886376708746, 0.00018591222760733217, 0.00016460906772408634, 4.1432296711718664e-05, 2.8764745366061106e-05, 7.786951027810574e-05, 0.0009200992644764483, 0.010340196080505848, 2.7572366889216937e-05, 1.7833237507147714e-05, 0.0003305456193629652, 2.4375704015255906e-05, 0.9872152805328369, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00010753834794741124, 0.0021781898103654385, 0.0020426097325980663, 0.00425192853435874, 0.006989907473325729, 2.5118790290434845e-05, 0.0007779038860462606, 0.0005783543456345797, 0.0029378440231084824, 0.03322538733482361, 1.7199259673361667e-05, 0.0008936485392041504, 0.0015238573541864753, 1.4656818166258745e-05, 0.0062226406298577785, 0.9382131695747375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0013634886126965284, 1.322607567999512e-05, 4.013951183878817e-06, 4.803066985914484e-06, 1.0257464055030141e-05, 0.19665959477424622, 4.527264172793366e-05, 0.0002776262699626386, 1.1714446372934617e-05, 9.473313184571452e-06, 0.22919613122940063, 2.6430654543219134e-05, 4.1018488445843104e-06, 0.26576101779937744, 8.51534878165694e-06, 4.536034794000443e-06, 0.30659982562065125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0008924754220061004, 0.00013490821584127843, 4.779844675795175e-05, 5.803707608720288e-05, 0.0001048016274580732, 0.012799093499779701, 0.0007168253068812191, 0.03257954120635986, 2.6449979486642405e-05, 0.00011185073526576161, 0.011884265579283237, 4.0102739149006084e-05, 5.555408642976545e-05, 0.012377867475152016, 0.00010783469042507932, 5.4043703130446374e-05, 0.013122130185365677, 0.9148862957954407, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [5.07531922266935e-06, 4.3961466872133315e-05, 3.398504850338213e-05, 7.940301293274388e-05, 5.4779167840024456e-05, 7.921550491118978e-07, 9.313333066529594e-06, 7.727086085651536e-06, 8.597270061727613e-05, 0.0001227404281962663, 5.141488941262651e-07, 1.702796907920856e-06, 3.834186645690352e-05, 4.4509752683552506e-07, 0.00013928249245509505, 0.00032758008455857635, 3.994804558260512e-07, 3.948134235542966e-06, 0.999043881893158, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [9.346190927317366e-05, 0.0018395759398117661, 0.0025233139749616385, 0.01808723248541355, 0.0029363781213760376, 0.00027335842605680227, 4.8729798436397687e-05, 0.00042127809138037264, 0.00015624363732058555, 0.0009748339653015137, 0.00020533608039841056, 0.0010228835744783282, 0.0019548055715858936, 0.0001947038690559566, 0.0011294218711555004, 0.0016656137304380536, 0.0001873406145023182, 0.000950345944147557, 0.00044551800237968564, 0.9648897647857666, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0010859703179448843, 8.512334716215264e-06, 2.53072653322306e-06, 3.0625210456491914e-06, 5.9751241678895894e-06, 0.13292619585990906, 3.3453237847425044e-05, 0.00018891232321038842, 8.477757546643261e-06, 6.5404224187659565e-06, 0.1644591987133026, 1.8130021999240853e-05, 3.062742962356424e-06, 0.19719168543815613, 6.429836503230035e-06, 3.444740059421747e-06, 0.23317117989063263, 0.002279625041410327, 3.713433443408576e-06, 3.5288030630908906e-05, 0.2685586214065552, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0004197956877760589, 0.00011805014219135046, 0.00014240515884011984, 3.796788223553449e-05, 0.00019043180509470403, 0.00176512252073735, 0.0005709833349101245, 0.0005008857697248459, 8.840763621265069e-05, 0.0001420867774868384, 0.001663984265178442, 3.348111204104498e-05, 2.4414004656136967e-05, 0.00175465049687773, 6.520311580970883e-05, 2.414266964478884e-05, 0.0018299149814993143, 0.0015691040316596627, 3.974881110480055e-05, 0.00015712414460722357, 0.0018554475391283631, 0.9870065450668335, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [7.501784421037883e-05, 0.0014379833592101932, 6.345151632558554e-05, 0.00010864839714486152, 0.00015633183647878468, 3.210126124031376e-06, 0.002203281968832016, 0.0002207657671533525, 5.2403021982172504e-05, 4.8815836635185406e-05, 2.264463546453044e-06, 1.5327248547691852e-05, 4.157144758210052e-06, 2.0228428638802143e-06, 6.2968028942123055e-06, 4.8486737796338275e-05, 1.992900934055797e-06, 3.2470077712787315e-05, 0.0012695096665993333, 1.9632627299870364e-05, 1.8090934190695407e-06, 0.0005810296279378235, 0.9936450719833374, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [7.450144039466977e-05, 0.0006139380275271833, 0.0009361182455904782, 0.0008487782906740904, 0.0028506300877779722, 1.0365030902903527e-05, 0.00021614236175082624, 0.00017397513147443533, 0.0020508375018835068, 0.005805291701108217, 8.05522267910419e-06, 8.086584421107545e-05, 0.000770243292208761, 7.288177130249096e-06, 0.001057614921592176, 0.0022755940444767475, 6.663255135208601e-06, 0.00011621018347796053, 0.0005972448270767927, 8.736289601074532e-05, 6.332325483526802e-06, 6.096452852943912e-05, 6.0905720602022484e-05, 0.9812840819358826, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0005848745349794626, 0.00015909200010355562, 1.083647021005163e-05, 7.365475903498009e-05, 0.00011349534906912595, 0.0008256662986241281, 0.00031911072437651455, 0.018529992550611496, 1.0226589438389055e-05, 4.9587219109525904e-05, 0.0007716424879617989, 4.454819281818345e-05, 9.865025276667438e-06, 0.0008067170856520534, 2.2673882995150052e-05, 1.2464139217627235e-05, 0.0008449103333987296, 0.008790107443928719, 3.5792407288681716e-05, 3.66286258213222e-05, 0.0008917523664422333, 0.0010791767854243517, 0.0003708462754730135, 0.0001083713723346591, 0.9654979109764099, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [1.6459925973322242e-05, 0.0001715245598461479, 3.208317866665311e-05, 0.00010234172805212438, 0.0026318796444684267, 9.886184670904186e-06, 3.250848749303259e-05, 3.7417539715534076e-05, 0.00012631539721041918, 4.9912112444872037e-05, 8.302540663862601e-06, 8.443422120762989e-05, 3.127968739136122e-05, 7.633363566128537e-06, 1.0101352927449625e-05, 5.6673809012863785e-05, 7.442129117407603e-06, 2.7689655325957574e-05, 1.841835728555452e-05, 2.879437261071871e-06, 6.840427886345424e-06, 4.279875156498747e-06, 0.00043176571489311755, 0.0001761750172590837, 8.995599637273699e-05, 0.9958257675170898, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [2.6368099497631192e-05, 0.00018008743063546717, 0.0001808295346563682, 0.00030464722658507526, 0.00039390946039929986, 4.674849333241582e-05, 2.7231719286646694e-05, 4.8734953452367336e-05, 0.00029131697374396026, 0.0004206168814562261, 3.804643711191602e-05, 0.00025245139840990305, 5.6067434343276545e-05, 3.82037615054287e-05, 0.0015365129802376032, 0.0012537221191450953, 3.593428846215829e-05, 2.303666406078264e-05, 0.00018036243272945285, 0.00012266113481018692, 3.517787263263017e-05, 6.924685294507071e-05, 0.00011267305671935901, 0.0008507389575242996, 0.00014361889043357223, 0.00023528003657702357, 0.9930958151817322, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0007048257393762469, 5.675388456438668e-05, 3.3512919799250085e-06, 7.472656761819962e-06, 1.7859458239399828e-05, 0.0008156527183018625, 4.952957169734873e-05, 0.0013530976139008999, 3.7417627027025446e-05, 0.0001437800528947264, 0.0007639331743121147, 9.991684237320442e-06, 2.884440846173675e-06, 0.0007552225142717361, 0.00010159600788028911, 3.120546807622304e-06, 0.0008060947293415666, 0.0011406760895624757, 1.4343102520797402e-05, 9.910175322147552e-06, 0.0008649185765534639, 8.66326445247978e-05, 3.469540024525486e-05, 0.00010265829769195989, 0.007663473952561617, 4.187890954199247e-05, 3.4908694033219945e-06, 0.9844047427177429, 0.0, 0.0, 0.0, 0.0, 0.0], [2.0288327505113557e-05, 2.9542719858000055e-05, 5.037501978222281e-05, 0.0009778322419151664, 0.3728255331516266, 6.661317456746474e-06, 1.573363806528505e-05, 3.981242480222136e-05, 0.00022353234817273915, 0.00012674317986238748, 5.118443823448615e-06, 0.00024116170243360102, 1.2973835509910714e-05, 4.80069502373226e-06, 2.3321656044572592e-05, 7.723525050096214e-05, 4.593436187860789e-06, 1.9647119188448414e-05, 0.00021129958622623235, 1.1453519618953578e-05, 4.380488462629728e-06, 1.4442666724789888e-05, 3.6767421988770366e-05, 0.00011845329572679475, 3.797718454734422e-05, 0.0007802760228514671, 0.0004048362316098064, 1.0429552276036702e-05, 0.6236647963523865, 0.0, 0.0, 0.0, 0.0], [2.0582907382049598e-05, 8.83124303072691e-05, 0.00020454880723264068, 0.00030188984237611294, 8.223887562053278e-05, 1.970439734577667e-05, 0.00014085113070905209, 2.8963144359295256e-05, 7.669377737329341e-06, 3.724613270605914e-05, 1.673677070357371e-05, 6.404696614481509e-05, 0.0006910584052093327, 1.6027554011088796e-05, 0.00015603679639752954, 0.0001482591324020177, 1.5700070434832014e-05, 9.155381849268451e-05, 8.525082375854254e-05, 4.904512934444938e-06, 1.5784382412675768e-05, 5.293112189974636e-05, 0.0005298351752571762, 0.0005658394657075405, 6.167318497318774e-05, 6.729490996804088e-05, 0.0003077442815992981, 1.0369148185418453e-05, 6.799342372687533e-05, 0.9960988759994507, 0.0, 0.0, 0.0], [1.3371305612963624e-05, 0.0009821526473388076, 0.00041548089939169586, 0.00011442326649557799, 0.0003873073437716812, 5.660855094902217e-06, 0.0012746263528242707, 0.0005708062089979649, 0.0006383618456311524, 0.0005776655161753297, 4.127729425817961e-06, 9.161743037111592e-06, 9.14283373276703e-05, 3.774864126171451e-06, 1.3575295270129573e-05, 0.0002916174125857651, 3.447485596552724e-06, 7.899185584392399e-05, 0.0031891181133687496, 4.885079306404805e-06, 3.1652807592763565e-06, 1.4087455383560155e-05, 0.0001567141298437491, 0.0003544885548762977, 0.00017265455971937627, 0.0013050627894699574, 0.0002186766650993377, 2.6776693630381487e-05, 0.00026460157823748887, 1.3334517461771611e-05, 0.9888005256652832, 0.0, 0.0], [2.745506208157167e-05, 0.00016438262537121773, 7.99642366473563e-05, 0.0011914960341528058, 0.0007883630460128188, 2.658414359757444e-06, 3.0057593903620727e-05, 7.457976153091295e-06, 0.00014940995606593788, 2.8857133656856604e-05, 1.873827500276093e-06, 0.00033288003760389984, 5.16086038260255e-05, 1.7577465314388974e-06, 0.00012656602484639734, 0.00014267012011259794, 1.6954454622464254e-06, 2.1952573661110364e-05, 0.00023040804080665112, 4.429338878253475e-05, 1.6103306279546814e-06, 2.7008050892618485e-05, 0.00023884844267740846, 0.00019046018132939935, 9.496127859165426e-06, 0.00044664356391876936, 0.00022095769236329943, 5.379170943342615e-06, 0.0006956402794457972, 0.0001547076681163162, 0.0002548544143792242, 0.9943286776542664, 0.0], [0.006231046747416258, 9.72282505244948e-05, 6.871603090985445e-06, 2.1151136024855077e-05, 5.828053326695226e-05, 0.007238902151584625, 2.0987936295568943e-05, 0.0002545907336752862, 6.243871030164883e-05, 2.09246627491666e-05, 0.007872143760323524, 5.585329927271232e-05, 9.868786946753971e-06, 0.009169397875666618, 7.203009590739384e-05, 7.068700597301358e-06, 0.010345976799726486, 0.0013096530456095934, 3.803680374403484e-05, 8.022711699595675e-05, 0.012053261511027813, 4.071998773724772e-05, 3.686068112074281e-06, 3.4713455534074455e-05, 0.0005061827832832932, 8.918950334191322e-05, 2.9112115953466855e-05, 0.0012772809714078903, 8.489656465826556e-05, 0.00018447409092914313, 0.00013425754150375724, 6.813061190769076e-05, 0.9425214529037476]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.943029522895813, 0.05697045475244522, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9185556173324585, 0.032800041139125824, 0.048644352704286575, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8779287934303284, 0.056434281170368195, 0.04271192103624344, 0.022924991324543953, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.804131805896759, 0.029098201543092728, 0.07556731253862381, 0.05643591657280922, 0.03476676344871521, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.494310587644577, 0.020183544605970383, 0.027966560795903206, 0.01831907592713833, 0.031442031264305115, 0.40777823328971863, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6057478189468384, 0.02924243174493313, 0.09491512924432755, 0.07609348744153976, 0.06614658236503601, 0.08705786615610123, 0.0407966673374176, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.448382169008255, 0.04542431980371475, 0.0740148201584816, 0.06864845752716064, 0.0937662422657013, 0.0877426415681839, 0.0653427243232727, 0.1166786178946495, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.49169260263442993, 0.137820765376091, 0.03955018147826195, 0.06153321638703346, 0.045399632304906845, 0.040731463581323624, 0.062287040054798126, 0.05861866846680641, 0.06236644834280014, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5404124855995178, 0.044426627457141876, 0.03957854211330414, 0.04188809171319008, 0.07529857009649277, 0.04669506475329399, 0.048475231975317, 0.05500520393252373, 0.08293062448501587, 0.02528950944542885, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.28273552656173706, 0.014234171248972416, 0.017647748813033104, 0.011433069594204426, 0.021741706877946854, 0.2666538953781128, 0.015403537079691887, 0.04734928905963898, 0.017767542973160744, 0.013926065526902676, 0.29110750555992126, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.34496626257896423, 0.04611678048968315, 0.05771545320749283, 0.11131856590509415, 0.11289365589618683, 0.027930336073040962, 0.03859188035130501, 0.05656527727842331, 0.05864057317376137, 0.06648597121238708, 0.026114359498023987, 0.052660852670669556, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4699217677116394, 0.032015684992074966, 0.1077289804816246, 0.027006756514310837, 0.04465879872441292, 0.022773563861846924, 0.0231170654296875, 0.025491520762443542, 0.04950268566608429, 0.02657393552362919, 0.01970885880291462, 0.06337957084178925, 0.08812079578638077, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.20661765336990356, 0.010379297658801079, 0.012261927127838135, 0.008319094777107239, 0.016007069498300552, 0.1952773928642273, 0.011453290469944477, 0.03475670516490936, 0.01307358592748642, 0.010938972234725952, 0.21602484583854675, 0.005866494961082935, 0.02364230714738369, 0.23538129031658173, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.33993491530418396, 0.029161641374230385, 0.09540712088346481, 0.03395187482237816, 0.08440456539392471, 0.012559544295072556, 0.02935866080224514, 0.024564160034060478, 0.10622433573007584, 0.04689216986298561, 0.01146959513425827, 0.006369194947183132, 0.11145271360874176, 0.011317990720272064, 0.0569315068423748, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4040881097316742, 0.02419566921889782, 0.03891005739569664, 0.014727430418133736, 0.024456560611724854, 0.03845002129673958, 0.03923037275671959, 0.037171371281147, 0.06030002981424332, 0.04198544844985008, 0.037167180329561234, 0.01639123074710369, 0.039289690554142, 0.03772978112101555, 0.13448573648929596, 0.011421295814216137, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.15876445174217224, 0.008203905075788498, 0.009295269846916199, 0.006221715360879898, 0.011793200857937336, 0.15069788694381714, 0.008851953782141209, 0.026313530281186104, 0.010186916217207909, 0.008433728478848934, 0.16762234270572662, 0.004420033656060696, 0.01821179874241352, 0.18350808322429657, 0.020927341654896736, 0.006447792984545231, 0.2001000940799713, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.17539213597774506, 0.020569654181599617, 0.01829143427312374, 0.00929802656173706, 0.017377890646457672, 0.042534783482551575, 0.02070159651339054, 0.05044395849108696, 0.02543805167078972, 0.017218226566910744, 0.04311535134911537, 0.013349833898246288, 0.028528600931167603, 0.0459725484251976, 0.03408820554614067, 0.01983421854674816, 0.04992840066552162, 0.36791712045669556, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.26033347845077515, 0.017148377373814583, 0.03745277225971222, 0.07594799995422363, 0.04674697667360306, 0.018068531528115273, 0.031346458941698074, 0.037415143102407455, 0.07175809890031815, 0.05872536823153496, 0.0170787014067173, 0.04030592367053032, 0.05706355720758438, 0.01711357943713665, 0.10491336137056351, 0.046705346554517746, 0.017230210825800896, 0.024682143703103065, 0.019963981583714485, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.30547064542770386, 0.05190496891736984, 0.043468985706567764, 0.021846851333975792, 0.021017182618379593, 0.03390473872423172, 0.04190469905734062, 0.03909287601709366, 0.028871973976492882, 0.023003436625003815, 0.03205801174044609, 0.023334508761763573, 0.0711059421300888, 0.03290088474750519, 0.061641961336135864, 0.031832627952098846, 0.03376764431595802, 0.045714881271123886, 0.03501523658633232, 0.022141894325613976, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1224295049905777, 0.006105297245085239, 0.006670297123491764, 0.00458177737891674, 0.009337781928479671, 0.11381794512271881, 0.006783356424421072, 0.01971990056335926, 0.00758085772395134, 0.00661364383995533, 0.12765927612781525, 0.003502656938508153, 0.014002329669892788, 0.14000988006591797, 0.015684882178902626, 0.005092612002044916, 0.15336216986179352, 0.03527414798736572, 0.022465629503130913, 0.006954455282539129, 0.17235167324543, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.20538491010665894, 0.03477853164076805, 0.014682918787002563, 0.03118330053985119, 0.0309312641620636, 0.021952766925096512, 0.03290864825248718, 0.05740533396601677, 0.05587517097592354, 0.04864276573061943, 0.023520752787590027, 0.01510855183005333, 0.02738633006811142, 0.02451842837035656, 0.06060458719730377, 0.03477614372968674, 0.0261378213763237, 0.05168433114886284, 0.06281404197216034, 0.020291464403271675, 0.028601735830307007, 0.09081017971038818, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.23978599905967712, 0.03132349252700806, 0.05037754029035568, 0.01586942747235298, 0.03901456668972969, 0.02280554547905922, 0.04285357519984245, 0.02888229675590992, 0.04046262800693512, 0.03410724923014641, 0.022644521668553352, 0.039230700582265854, 0.0723857581615448, 0.022345518693327904, 0.049581028521060944, 0.03193334862589836, 0.02332560531795025, 0.04521358758211136, 0.03055434860289097, 0.022876491770148277, 0.024732308462262154, 0.05549483001232147, 0.014199569821357727, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.23581692576408386, 0.0205583106726408, 0.04375004768371582, 0.02970486506819725, 0.03703876584768295, 0.014953458681702614, 0.04004310816526413, 0.027184365317225456, 0.045761838555336, 0.03809257969260216, 0.014181879349052906, 0.03789154067635536, 0.06518243253231049, 0.014182924292981625, 0.05489494279026985, 0.023720961064100266, 0.014592783525586128, 0.025570034980773926, 0.07356184720993042, 0.03918232396245003, 0.014925515279173851, 0.046288661658763885, 0.027801064774394035, 0.015118849463760853, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.14254967868328094, 0.012010163627564907, 0.016881294548511505, 0.02074255794286728, 0.03245176002383232, 0.029625998809933662, 0.030295221135020256, 0.05620871111750603, 0.029608746990561485, 0.02948184125125408, 0.032639842480421066, 0.010038232430815697, 0.04078620672225952, 0.03462785482406616, 0.03391634672880173, 0.020155752077698708, 0.03684317693114281, 0.0606469102203846, 0.04744713753461838, 0.03252528980374336, 0.04040035977959633, 0.05947762355208397, 0.03129401430487633, 0.04792547971010208, 0.07141980528831482, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2222907692193985, 0.059111353009939194, 0.03702675551176071, 0.04059012606739998, 0.027254510670900345, 0.019174767658114433, 0.03171538934111595, 0.020462147891521454, 0.03811326250433922, 0.019927889108657837, 0.018538912758231163, 0.015436707064509392, 0.04536490887403488, 0.019355757161974907, 0.05035829544067383, 0.03328138589859009, 0.02017974853515625, 0.036794353276491165, 0.0433138869702816, 0.02847641333937645, 0.02131732925772667, 0.047712888568639755, 0.013107034377753735, 0.026336049661040306, 0.03021136112511158, 0.03454800322651863, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2843813896179199, 0.023870108649134636, 0.04641883075237274, 0.010260097682476044, 0.03390985727310181, 0.01830146834254265, 0.02370888739824295, 0.0247668270021677, 0.025767754763364792, 0.02296881563961506, 0.016735462471842766, 0.013406947255134583, 0.045986615121364594, 0.01667323336005211, 0.08106391876935959, 0.05033260956406593, 0.016726171597838402, 0.01990479975938797, 0.030325334519147873, 0.01014632172882557, 0.0173182375729084, 0.019040964543819427, 0.011081119067966938, 0.05204639211297035, 0.03335351124405861, 0.038808830082416534, 0.012695515528321266, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.11854357272386551, 0.01335094589740038, 0.013422034680843353, 0.0302731953561306, 0.02616293355822563, 0.020776210352778435, 0.021280208602547646, 0.03798934072256088, 0.03536445274949074, 0.03665178269147873, 0.0220040176063776, 0.015380042605102062, 0.030023131519556046, 0.023299671709537506, 0.030007552355527878, 0.014861369505524635, 0.02452193759381771, 0.03999800235033035, 0.03900156170129776, 0.03600766509771347, 0.026851212605834007, 0.06795872002840042, 0.038931310176849365, 0.057258062064647675, 0.06659834086894989, 0.03075685352087021, 0.023343214765191078, 0.05938267707824707, 0.0, 0.0, 0.0, 0.0, 0.0], [0.25091853737831116, 0.01135188341140747, 0.023033952340483665, 0.01884976588189602, 0.01320881862193346, 0.01643040031194687, 0.03763698413968086, 0.021519407629966736, 0.03823148086667061, 0.03122309409081936, 0.01608109660446644, 0.017179008573293686, 0.0823964774608612, 0.01577541045844555, 0.04969312623143196, 0.03397902101278305, 0.016469145193696022, 0.025656109675765038, 0.053269319236278534, 0.024380972608923912, 0.01703290082514286, 0.031062550842761993, 0.014834260568022728, 0.04310779646039009, 0.027818359434604645, 0.015127941034734249, 0.012749834917485714, 0.0268526803702116, 0.014129594899713993, 0.0, 0.0, 0.0, 0.0], [0.19256949424743652, 0.02283368445932865, 0.01449588593095541, 0.02805502340197563, 0.03290427103638649, 0.01857709139585495, 0.02377672679722309, 0.014988912269473076, 0.027755482122302055, 0.019952137023210526, 0.018426885828375816, 0.02680848352611065, 0.04026195406913757, 0.018957331776618958, 0.01998024620115757, 0.03905032202601433, 0.019494347274303436, 0.03071431629359722, 0.07932325452566147, 0.03619767352938652, 0.02037958800792694, 0.023319300264120102, 0.018723847344517708, 0.05692770332098007, 0.023927533999085426, 0.039243243634700775, 0.021783525124192238, 0.020374206826090813, 0.041788339614868164, 0.008409246802330017, 0.0, 0.0, 0.0], [0.1891939789056778, 0.014352073892951012, 0.0278293639421463, 0.018936049193143845, 0.05455230548977852, 0.024302387610077858, 0.020752564072608948, 0.030501794070005417, 0.016900427639484406, 0.029904043301939964, 0.02311178669333458, 0.021664857864379883, 0.03335980325937271, 0.02305050566792488, 0.027927029877901077, 0.02625349350273609, 0.0242579597979784, 0.02439497597515583, 0.01766667328774929, 0.022081058472394943, 0.02544150874018669, 0.023996734991669655, 0.015941407531499863, 0.021863484755158424, 0.048762742429971695, 0.01023405883461237, 0.025762978941202164, 0.061923280358314514, 0.06737109273672104, 0.01818411983549595, 0.009525518864393234, 0.0, 0.0], [0.27111953496932983, 0.05460573360323906, 0.03970598429441452, 0.03512895479798317, 0.02031375840306282, 0.008183857426047325, 0.02255663461983204, 0.01403643749654293, 0.02619847282767296, 0.03235534578561783, 0.007185020949691534, 0.010813488624989986, 0.051626089960336685, 0.007057536393404007, 0.04232775792479515, 0.01850598119199276, 0.006952998694032431, 0.012550849467515945, 0.037855178117752075, 0.014787370339035988, 0.007130765821784735, 0.018956711515784264, 0.010758964344859123, 0.02354053035378456, 0.01625620760023594, 0.007915407419204712, 0.03652311861515045, 0.01456227246671915, 0.019251471385359764, 0.010911808349192142, 0.034396685659885406, 0.06592900305986404, 0.0], [0.14836539328098297, 0.01450689323246479, 0.0076462929137051105, 0.011038759723305702, 0.026302475482225418, 0.013194828294217587, 0.02718488685786724, 0.017392205074429512, 0.01612214557826519, 0.03288078308105469, 0.014050282537937164, 0.007167350500822067, 0.016120057553052902, 0.014647024683654308, 0.018450887873768806, 0.013102127239108086, 0.01528322882950306, 0.014542991295456886, 0.05961218848824501, 0.02238386683166027, 0.01679699309170246, 0.10928261280059814, 0.07263996452093124, 0.08393710106611252, 0.025248991325497627, 0.03774847090244293, 0.016226936131715775, 0.024953868240118027, 0.0421658456325531, 0.004525810945779085, 0.01449135784059763, 0.01914571225643158, 0.022841649129986763]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.09646989405155182, 0.9035300612449646, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0432523675262928, 0.08177752792835236, 0.8749701380729675, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.09995397925376892, 0.025312725454568863, 0.020108042284846306, 0.8546252250671387, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.024889368563890457, 0.00320735527202487, 0.0018421593122184277, 0.022361500188708305, 0.9476996660232544, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.10732380300760269, 0.017841672524809837, 0.019553344696760178, 0.04333319514989853, 0.10211500525474548, 0.7098329067230225, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.006426361855119467, 0.00044797820737585425, 0.00014756589371245354, 0.0004693672526627779, 0.0014411886222660542, 0.003859694814309478, 0.98720782995224, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0010354593396186829, 0.0001990183664020151, 0.00016020424664020538, 6.937277794349939e-05, 0.00038674211828038096, 0.005171594675630331, 0.8964056372642517, 0.09657203406095505, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.001288329716771841, 0.00032334469142369926, 0.0002652714028954506, 0.0002549059281591326, 0.000201298258616589, 0.00010048996773548424, 0.0005700881010852754, 0.00040912977419793606, 0.9965871572494507, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0001874157169368118, 1.6196530850720592e-05, 4.2281039895897266e-06, 0.0002875888312701136, 1.1125704986625351e-05, 9.805656191019807e-06, 0.0001556719362270087, 7.632971392013133e-05, 0.0034869094379246235, 0.9957647323608398, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.015741512179374695, 0.0006393603980541229, 0.00045715278247371316, 0.0009912523673847318, 0.002114036353304982, 0.018089773133397102, 0.047120336443185806, 0.07010911405086517, 0.061528295278549194, 0.27690401673316956, 0.5063051581382751, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0006166601087898016, 0.0005207082722336054, 4.61151976196561e-05, 0.0014613015810027719, 0.0005623759934678674, 4.447608080226928e-05, 0.00036539699067361653, 0.0002860166132450104, 0.004506131634116173, 0.005816526710987091, 0.0007244550506584346, 0.9850499033927917, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0010478567564859986, 3.0628176318714395e-05, 0.0001734501274768263, 5.423119000624865e-05, 6.388423207681626e-05, 1.1261137842666358e-05, 1.7169008060591295e-05, 1.3931334251537919e-05, 0.0020760411862283945, 0.0002692685811780393, 0.00015268517017830163, 0.0036844341084361076, 0.992405116558075, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.010746276937425137, 0.0002535435778554529, 0.0001532293827040121, 0.0002928702742792666, 0.0005376795306801796, 0.004423546139150858, 0.009884335100650787, 0.012843052856624126, 0.012738611549139023, 0.05966855213046074, 0.10772999376058578, 0.024745717644691467, 0.07808699458837509, 0.6778956055641174, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00041218005935661495, 2.6218716811854392e-05, 1.775590681063477e-05, 0.00019181905372533947, 3.2979528441501316e-06, 3.912678948836401e-06, 1.0438098797749262e-05, 4.906854428554652e-06, 0.0005868573789484799, 0.003038153052330017, 3.693125108839013e-05, 0.0007724309107288718, 0.009622602723538876, 0.00016094397869892418, 0.9851115345954895, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00010886572999879718, 3.5845419006363954e-06, 5.191653144720476e-06, 3.083834599237889e-05, 1.8408729374641553e-05, 7.954758416417462e-07, 3.3532076031406177e-06, 6.5743715822463855e-06, 0.0007270933710969985, 0.0018232448492199183, 7.853259376133792e-06, 0.00030627482919953763, 0.006975042168051004, 3.485084016574547e-05, 0.028292659670114517, 0.96165531873703, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.006073984317481518, 8.815195906208828e-05, 4.583777626976371e-05, 8.250468818005174e-05, 0.00012720433005597442, 0.0009312504553236067, 0.001669998513534665, 0.001938195782713592, 0.00210169586353004, 0.010131667368113995, 0.01604730635881424, 0.003835385199636221, 0.012242134660482407, 0.10037058591842651, 0.07853128761053085, 0.10997356474399567, 0.6558092832565308, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0021862974390387535, 1.189291742775822e-05, 1.67359448823845e-05, 2.081541060761083e-05, 2.116253017447889e-05, 0.000771492428611964, 0.0008652104297652841, 0.0005560294375754893, 0.0001565588463563472, 0.001949990983121097, 0.010891200974583626, 0.0003954311250708997, 0.0015144689241424203, 0.06916307657957077, 0.004308103583753109, 0.004035161342471838, 0.4939703941345215, 0.40916597843170166, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [1.979802800633479e-05, 4.972388865098765e-07, 9.165694869750496e-09, 1.3230416584519844e-07, 5.601832597790235e-08, 1.1903900087872898e-08, 6.153117055873736e-07, 4.068558112635401e-08, 4.517459274211433e-06, 1.4017791727383155e-05, 1.6456915830076468e-07, 1.086384372683824e-06, 7.44406133890152e-06, 1.0056654673462617e-06, 2.75950224022381e-05, 0.00031378038693219423, 6.201130872796057e-06, 8.213370165321976e-06, 0.9995948672294617, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [6.4971732172125485e-06, 8.692009600963502e-07, 1.4051377092982875e-06, 3.770482237541728e-07, 3.32917210243977e-07, 6.104961158825972e-08, 2.542995147791771e-08, 1.1067757554883428e-07, 3.670876321848482e-05, 5.704807790607447e-07, 6.17234604760597e-07, 0.00015627933316864073, 0.00014737897436134517, 3.0103781227808213e-06, 6.130653491709381e-05, 0.0017769908299669623, 1.8545933926361613e-05, 3.42631246894598e-05, 0.9233514070510864, 0.07440324872732162, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0036490026395767927, 3.7494322896236554e-05, 1.7470785678597167e-05, 2.8449197998270392e-05, 3.312420813017525e-05, 0.00019569217693060637, 0.0002647593501023948, 0.00024690444115549326, 0.0002803317329380661, 0.0013949198182672262, 0.0017910305177792907, 0.0004246798052918166, 0.0014623702736571431, 0.009717746637761593, 0.008053951896727085, 0.01320058386772871, 0.06315968185663223, 0.07152796536684036, 0.07523110508918762, 0.02420508675277233, 0.7250776290893555, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0006410900969058275, 3.925709279428702e-06, 1.160738406724704e-06, 1.537548200758465e-06, 9.072650755115319e-07, 8.058204912231304e-06, 1.3223971109255217e-05, 4.619937044481048e-06, 3.6788398574572057e-05, 4.565183917293325e-05, 7.577823998872191e-05, 2.2741798602510244e-05, 5.6684530136408284e-05, 0.00047375087160617113, 0.0003640770446509123, 0.0004240030830260366, 0.003757338970899582, 0.0043631307780742645, 0.007395231630653143, 0.0050226314924657345, 0.05575621873140335, 0.9215314984321594, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0005377689958550036, 8.12255905202619e-07, 2.301862195963622e-06, 1.4700397059641546e-06, 1.8703678961173864e-06, 6.02451621034561e-07, 4.12783674619277e-06, 1.670579308665765e-06, 2.0471957213885617e-06, 7.430038385791704e-05, 3.5942323393101105e-06, 7.171528068283806e-06, 3.052822648896836e-05, 1.8927752535091713e-05, 0.0002543879672884941, 0.0001949639990925789, 0.00012626573152374476, 0.000182305506314151, 0.003735228208824992, 0.0006727130967192352, 0.0015798343811184168, 0.011177700012922287, 0.9813893437385559, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [8.512814383720979e-05, 4.870865382144984e-07, 1.2458955325200805e-06, 2.0811235401652084e-07, 1.92428601053507e-07, 3.704030859807972e-08, 4.555238604098122e-07, 5.5045557445509985e-08, 1.532036321805208e-06, 5.083299129182706e-06, 2.1400977345820138e-07, 1.459530608372006e-06, 1.4768357686989475e-05, 1.0635022817950812e-06, 2.9461476515280083e-05, 5.7288212701678276e-05, 6.615699021494947e-06, 7.844200808904134e-06, 0.00015063839964568615, 0.00022636978246737272, 7.973585888976231e-05, 0.00013040869089309126, 0.010868423618376255, 0.988331139087677, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0004166325961705297, 2.250373881906853e-06, 5.27054771737312e-06, 2.7549118385650218e-05, 3.9630609535379335e-05, 7.514735443692189e-06, 8.100932063825894e-06, 1.1581340913835447e-05, 1.3205964023654815e-05, 6.750722241122276e-05, 2.5212739274138585e-05, 1.4860726878396235e-05, 7.521701627410948e-05, 0.00011457462824182585, 0.00025745335733518004, 0.0003666863194666803, 0.0006904747569933534, 0.0014518487732857466, 0.0032460209913551807, 0.0006353403441607952, 0.008745570667088032, 0.01519087329506874, 0.0181502103805542, 0.1330331414937973, 0.8174033164978027, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [1.673923725320492e-05, 8.245302751674899e-08, 3.257380143395494e-08, 2.873734317176968e-08, 1.6217650511407555e-07, 1.5275384290802663e-09, 2.327860215700639e-08, 5.576728856482305e-09, 1.2825768180846353e-07, 1.342944955240455e-07, 6.160537857624604e-09, 2.523252646824403e-07, 3.2057509997684974e-06, 2.6277227505033807e-08, 7.619941584380285e-07, 7.901960088929627e-06, 1.394044062408284e-07, 1.95525771573557e-07, 0.00032022586674429476, 8.173670948963263e-07, 1.5629991594323656e-06, 3.7631600662280107e-06, 0.0007450510165654123, 0.003715218510478735, 3.934428241336718e-05, 0.9951443076133728, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00023842290102038532, 5.040124960942194e-06, 1.3208604059400386e-06, 8.59982810652582e-06, 5.166078608453972e-06, 1.347093814274558e-07, 6.710822617606027e-07, 2.6997005875273317e-07, 6.345731435430935e-06, 4.417831223690882e-05, 2.7444934858067427e-07, 2.017119368247222e-05, 1.652662831475027e-05, 8.122791541609331e-07, 0.00010770991502795368, 0.0001239744306076318, 3.5075922824034933e-06, 8.50584820000222e-06, 6.98026196914725e-05, 0.00026813664590008557, 2.8792839657398872e-05, 0.00011957906826864928, 0.00012961667380295694, 0.007425930816680193, 0.0007109709549695253, 0.005815013311803341, 0.9848405718803406, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00040899484883993864, 6.095364710745343e-07, 1.9963911199738504e-06, 9.310338100476656e-06, 3.7690531371481484e-06, 1.987657697100076e-06, 4.576551191348699e-07, 1.0690732779039536e-06, 3.08717972075101e-06, 9.2114050858072e-06, 4.724369318864774e-06, 1.207004288517055e-06, 5.095615506434115e-06, 1.804711610020604e-05, 4.857869498664513e-05, 4.169382373220287e-05, 0.00010537512571318075, 0.00022466866357717663, 0.00011528612958500162, 0.0002492896164767444, 0.0013673147186636925, 0.0016190342139452696, 0.0013275149976834655, 0.0034917802549898624, 0.06305665522813797, 0.006469063460826874, 0.09512648731470108, 0.8262876868247986, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00031804724130779505, 1.4181854339767597e-06, 3.185500361269078e-07, 2.7823130039905664e-06, 5.388598219724372e-05, 4.300602185480784e-08, 5.386275461205514e-07, 8.497840298105075e-08, 5.999714289828262e-07, 4.110329427930992e-06, 7.099398402488077e-08, 8.454322824036353e-07, 2.52661493505002e-06, 2.198388386887018e-07, 6.098251105868258e-06, 2.113004302373156e-05, 9.411810424353462e-07, 9.950393859980977e-07, 3.0413597414735705e-05, 2.976994665004895e-06, 8.453859663859475e-06, 2.6007011911133304e-05, 0.00023055827477946877, 0.0013383382465690374, 0.00021758257935289294, 0.00701440405100584, 0.017924044281244278, 0.0005302675999701023, 0.9722621440887451, 0.0, 0.0, 0.0, 0.0], [1.8505315324546245e-07, 5.565692351439111e-09, 7.262683787701008e-10, 7.745998509278706e-09, 1.507951097323712e-08, 8.228506209739805e-10, 1.7915348093922034e-09, 1.7345647140842857e-09, 1.0962556196147943e-08, 5.0032749498996054e-08, 3.9228162940219136e-09, 1.0013924622853665e-07, 2.3337792143252045e-08, 1.6555254944705666e-08, 5.1713197279923406e-08, 1.6146042014497652e-07, 9.827901692460728e-08, 2.7074545982941345e-07, 5.411987331171986e-06, 2.5083886612264905e-07, 1.1805956319221877e-06, 2.8004258183500497e-06, 4.61038098364952e-06, 0.0002267923264298588, 5.794247772428207e-05, 0.0004519548383541405, 0.00011976478708675131, 0.00023980921832844615, 0.0018740047235041857, 0.9970145225524902, 0.0, 0.0, 0.0], [4.347462163423188e-05, 2.968874923681142e-06, 3.919365099136485e-07, 9.117065360442211e-07, 4.364489711861097e-07, 4.686581789314914e-09, 9.240378062713717e-08, 1.2419349992853768e-08, 7.188964445958845e-08, 6.304543944679608e-07, 6.108888950251412e-09, 1.9987160726486763e-07, 1.4578660056940862e-06, 1.4727343788933922e-08, 1.7957309239591268e-07, 2.6422712835483253e-05, 5.112656609185251e-08, 4.710683043640529e-08, 0.0015761172398924828, 2.198943093389971e-06, 3.333982192543772e-07, 2.181483296226361e-06, 0.00016240392869804054, 0.001777764642611146, 1.1749229997803923e-05, 0.0036160871386528015, 6.199482595548034e-05, 3.5168195609003305e-05, 0.0011488678865134716, 0.016085581853985786, 0.9754422307014465, 0.0, 0.0], [0.00115629390347749, 6.199041763466084e-06, 6.137789227977919e-07, 3.102660230069887e-06, 8.228423666878371e-07, 4.3660193682626414e-08, 9.363273534290784e-08, 2.7735543639550997e-08, 5.109519634061144e-07, 1.2355309308986762e-06, 3.8253045175906664e-08, 1.1272317124166875e-06, 1.900891675177263e-06, 8.714057031511402e-08, 5.398188022809336e-06, 7.393458417936927e-06, 3.128881189695676e-07, 3.0146313179102435e-07, 0.00013595391646958888, 1.33438479679171e-05, 2.3996522031666245e-06, 3.871273293043487e-05, 0.0008219636511057615, 0.0006131280679255724, 2.151845910702832e-05, 0.004140730947256088, 0.0008760871132835746, 0.00011684626952046528, 0.0021590692922472954, 0.027525287121534348, 0.04434971883893013, 0.9179997444152832, 0.0], [0.0031942930072546005, 4.681677819462493e-05, 3.499128797557205e-05, 2.7043091904488392e-05, 1.400032670062501e-05, 1.7085134459193796e-05, 8.05188847152749e-06, 3.909832685167203e-06, 1.0716951692302246e-05, 1.793078627088107e-05, 1.4207501408236567e-05, 2.6911289751296863e-05, 2.641200444486458e-05, 3.110020770691335e-05, 1.1198583706573118e-05, 5.485506699187681e-05, 0.00011474493658170104, 0.00010493677837075666, 0.0002806306292768568, 0.0002083908038912341, 0.0009329257882200181, 0.0018990013049915433, 0.001126758987084031, 0.0019257273524999619, 0.003917159512639046, 0.0074994550086557865, 0.010695934295654297, 0.023199882358312607, 0.030398162081837654, 0.12729351222515106, 0.04325327277183533, 0.1766805648803711, 0.5669295191764832]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2530863881111145, 0.7469136118888855, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.30671587586402893, 0.32906386256217957, 0.3642202913761139, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.07416973263025284, 0.16189663112163544, 0.0543258972465992, 0.7096076607704163, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1668822020292282, 0.03901781514286995, 0.03822460398077965, 0.21398356556892395, 0.5418918132781982, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.19483646750450134, 0.2111925184726715, 0.05150563269853592, 0.08703833818435669, 0.2299955189228058, 0.22543160617351532, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.13900136947631836, 0.02974863536655903, 0.038606949150562286, 0.05133272334933281, 0.192842498421669, 0.08012373000383377, 0.4683440625667572, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.08969780802726746, 0.04080599173903465, 0.03473307937383652, 0.08414524793624878, 0.09911049157381058, 0.07059448957443237, 0.1361657679080963, 0.44474709033966064, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.059865184128284454, 0.020190445706248283, 0.018785320222377777, 0.1058472990989685, 0.057948824018239975, 0.027517711743712425, 0.0566631518304348, 0.08226760476827621, 0.5709145069122314, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.010379265993833542, 0.0046982537023723125, 0.004143986385315657, 0.0072914063930511475, 0.0062566958367824554, 0.0033180483151227236, 0.009175017476081848, 0.018754413351416588, 0.03393147885799408, 0.9020513892173767, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.07270114868879318, 0.0477648600935936, 0.010500334203243256, 0.01615942269563675, 0.04617821425199509, 0.0524945929646492, 0.05184569209814072, 0.2118951827287674, 0.035158198326826096, 0.17267179489135742, 0.28263059258461, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.015126901678740978, 0.004731191322207451, 0.002322632120922208, 0.006575741805136204, 0.018362468108534813, 0.00333966757170856, 0.00878422986716032, 0.007409750949591398, 0.006289812736213207, 0.07638947665691376, 0.012003494426608086, 0.8386645317077637, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0323319248855114, 0.010628960095345974, 0.0026151640340685844, 0.0011762919602915645, 0.003093285020440817, 0.0015055524418130517, 0.0070797149091959, 0.0028344676829874516, 0.005003879778087139, 0.012032576836645603, 0.0039877742528915405, 0.051872368901968, 0.8658380508422852, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.050455909222364426, 0.02653883770108223, 0.005783270113170147, 0.008087296970188618, 0.021799389272928238, 0.025670325383543968, 0.02277902513742447, 0.09139908105134964, 0.015017375349998474, 0.07093919813632965, 0.12448633462190628, 0.1266833394765854, 0.0610213540494442, 0.34933924674987793, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.05474122241139412, 0.05296845734119415, 0.003988128621131182, 0.012351619079709053, 0.004415620118379593, 0.003596278140321374, 0.011385710909962654, 0.009828068315982819, 0.014749745838344097, 0.07078825682401657, 0.011209191754460335, 0.051640573889017105, 0.19734397530555725, 0.027129271999001503, 0.4738638401031494, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.007163067813962698, 0.0049638464115560055, 0.0027692278381437063, 0.0019424431957304478, 0.010544744320213795, 0.0014144883025437593, 0.0036636642180383205, 0.003149948548525572, 0.005481296218931675, 0.021614043042063713, 0.003922200761735439, 0.0793507993221283, 0.2247791737318039, 0.009166955016553402, 0.027402665466070175, 0.5926714539527893, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.03461107611656189, 0.015296359546482563, 0.003095125313848257, 0.0038990986067801714, 0.009989402256906033, 0.011446868069469929, 0.009189354255795479, 0.033565156161785126, 0.005761210806667805, 0.025581011548638344, 0.04384687542915344, 0.04521361365914345, 0.020553385838866234, 0.11962335556745529, 0.1567324697971344, 0.13173449039459229, 0.3298611044883728, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.017253868281841278, 0.004397526849061251, 0.004968691151589155, 0.007064315490424633, 0.0066348956897854805, 0.006910950876772404, 0.011386899277567863, 0.016178511083126068, 0.020317766815423965, 0.020396806299686432, 0.023422103375196457, 0.018909122794866562, 0.04024205356836319, 0.06200674548745155, 0.1164536252617836, 0.07975103706121445, 0.1686447113752365, 0.37506043910980225, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.002459116280078888, 0.00024919764837250113, 3.400466084713116e-05, 0.0002113294176524505, 0.00020066798606421798, 0.00012589257676154375, 0.00036506837932392955, 0.00037359801353886724, 0.00013798549480270594, 0.0004702212172560394, 0.00027151827816851437, 0.003417078172788024, 0.0006049809162504971, 0.0005454609636217356, 0.0008937675156630576, 0.0015852133510634303, 0.0012150752590969205, 0.00282126828096807, 0.9840186238288879, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00015282446111086756, 0.03892364725470543, 0.00047152009210549295, 0.00037318209069781005, 3.271796595072374e-05, 1.0635602848196868e-05, 3.824579835054465e-06, 1.3244705769466236e-05, 6.41892256680876e-05, 2.7344342015567236e-05, 2.831998426700011e-05, 0.002229567850008607, 0.00138663814868778, 7.163523696362972e-05, 0.00014025566633790731, 0.008246444165706635, 0.00019678653916344047, 0.0002054668584605679, 0.8976380228996277, 0.04978375509381294, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.02645810693502426, 0.010410889983177185, 0.0021332555916160345, 0.002456019166857004, 0.0055426000617444515, 0.005954570136964321, 0.0041958331130445, 0.013451538980007172, 0.0023519538808614016, 0.009471961297094822, 0.015433428809046745, 0.014804957434535027, 0.006865760777145624, 0.03787316754460335, 0.04744933918118477, 0.04547283798456192, 0.1019916757941246, 0.08666391670703888, 0.06470182538032532, 0.10160762816667557, 0.3947088122367859, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.021157899871468544, 0.0035484349355101585, 0.001744112349115312, 0.003509307513013482, 0.004201894160360098, 0.0025777784176170826, 0.004015856422483921, 0.00459899939596653, 0.003955155611038208, 0.00645583588629961, 0.005907893646508455, 0.003733163233846426, 0.009013409726321697, 0.013927978463470936, 0.029895812273025513, 0.02008231356739998, 0.038044415414333344, 0.0688309296965599, 0.08152893930673599, 0.0383402518928051, 0.1516025811433792, 0.48332706093788147, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0014211684465408325, 0.0004069012065883726, 0.00027144214254803956, 0.0014869243605062366, 0.0006475152331404388, 0.0002567152841947973, 0.0002729761181399226, 0.0005059849936515093, 0.00017537493840791285, 0.0012059592409059405, 0.0005902895354665816, 0.0004307388444431126, 0.0003699960943777114, 0.001332283834926784, 0.0007594270864501595, 0.0025183064863085747, 0.003599977120757103, 0.004756715148687363, 0.011892927810549736, 0.003410215489566326, 0.013851096853613853, 0.05907324701547623, 0.8907638192176819, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00505886459723115, 0.0008823543903417885, 0.0015358265955001116, 0.0016909865662455559, 0.0013438730966299772, 0.0004949708236381412, 0.0006572254933416843, 0.000552159093786031, 0.000581209606025368, 0.002054560463875532, 0.0008380875224247575, 0.0010067472467198968, 0.0011300853220745921, 0.0016139923827722669, 0.005022872239351273, 0.014576874673366547, 0.003714331891387701, 0.004681476857513189, 0.007913822308182716, 0.006778391543775797, 0.012291365303099155, 0.027733037248253822, 0.1021464467048645, 0.7957004308700562, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.004004697315394878, 0.0004576972278300673, 0.0015645206440240145, 0.003137204796075821, 0.0019937455654144287, 0.0003789263137150556, 0.0004957779310643673, 0.0005698016029782593, 0.0010052064899355173, 0.0023432252928614616, 0.0005772153381258249, 0.0016756132245063782, 0.003078737063333392, 0.0012285253033041954, 0.005278326570987701, 0.006328054238110781, 0.003151732264086604, 0.0053193094208836555, 0.021383123472332954, 0.006147708278149366, 0.012332222424447536, 0.07402161508798599, 0.12114018946886063, 0.5611116886138916, 0.16127510368824005, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0011286542285233736, 4.9889109504874796e-05, 4.129114677198231e-05, 9.249603317584842e-05, 5.513622454600409e-05, 3.8617254176642746e-05, 5.5920278100529686e-05, 0.00014896267384756356, 5.509215043275617e-06, 6.817427492933348e-05, 3.6204455682309344e-05, 4.6239569201134145e-05, 0.001065501943230629, 5.91987554798834e-05, 7.787253707647324e-05, 0.00038421223871409893, 0.00011692426778608933, 0.0002242824120912701, 0.000508398690726608, 0.0001562813704367727, 0.00032331488910131156, 0.0007086822879500687, 0.0009207420516759157, 0.0008559720008634031, 0.004414452239871025, 0.9884170889854431, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0024299698416143656, 0.0036596343852579594, 0.00063449761364609, 0.0006202654330991209, 0.002987675601616502, 0.00034763687290251255, 0.0005059162504039705, 0.00041149748722091317, 0.00021321575331967324, 0.000650934234727174, 0.00039556968840770423, 0.1698645055294037, 0.002188898855820298, 0.0006812380743212998, 0.0008683764026500285, 0.008905130438506603, 0.001463852939195931, 0.0013394576963037252, 0.006495130248367786, 0.007638714276254177, 0.004619397688657045, 0.0031617898494005203, 0.014200895093381405, 0.04639659821987152, 0.02278607152402401, 0.21939246356487274, 0.4771406650543213, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.015610319562256336, 0.0009648059494793415, 0.0010281821014359593, 0.007148509845137596, 0.005316647235304117, 0.0005432680482044816, 0.0007839882746338844, 0.00047082966193556786, 0.0022980361245572567, 0.005463093984872103, 0.0005483070272020996, 0.0008661489700898528, 0.0009035550756379962, 0.0009251962183043361, 0.008375930599868298, 0.0014478107914328575, 0.0020614899694919586, 0.003693382255733013, 0.017008855938911438, 0.0061386749148368835, 0.007041890639811754, 0.04128708317875862, 0.06922487169504166, 0.26617181301116943, 0.05024212971329689, 0.1144513413310051, 0.13764891028404236, 0.2323349416255951, 0.0, 0.0, 0.0, 0.0, 0.0], [0.021895306184887886, 0.0013514551101252437, 0.0013727976474910975, 0.005157721694558859, 0.010932796634733677, 0.00044522207463160157, 0.0016178301302716136, 0.0005713265272788703, 0.0007700271089561284, 0.003093535080552101, 0.00036163468030281365, 0.0009329015738330781, 0.0019032416166737676, 0.0005254389252513647, 0.0007036188035272062, 0.0015780640533193946, 0.0010200472315773368, 0.0009346723672933877, 0.005167578347027302, 0.0007855422445572913, 0.0028796817641705275, 0.006337142549455166, 0.04951414838433266, 0.021886903792619705, 0.03004683181643486, 0.06941600143909454, 0.029953863471746445, 0.06111626327037811, 0.6677284240722656, 0.0, 0.0, 0.0, 0.0], [0.0002946658350992948, 8.08511977083981e-05, 0.00011992642976110801, 0.00017153997032437474, 0.0003899005532730371, 8.630252705188468e-05, 5.253727795206942e-05, 6.616376049350947e-05, 0.00011378383351257071, 6.200082134455442e-05, 0.00011238016304560006, 0.0005867313011549413, 9.784993017092347e-05, 0.00021334877237677574, 0.00040444263140670955, 0.0004726236220449209, 0.00047307342174462974, 0.0005199516890570521, 0.0008571160142309964, 0.00022720196284353733, 0.0015976777067407966, 0.0014780634082853794, 0.0016501408535987139, 0.00933963991701603, 0.01279268879443407, 0.012606944888830185, 0.021659567952156067, 0.0288674458861351, 0.07784785330295563, 0.8267576694488525, 0.0, 0.0, 0.0], [0.0006396539392881095, 0.00019920240447390825, 0.0003378460241947323, 0.00032286165514960885, 0.00038839809712953866, 2.251143814646639e-05, 0.00011559666745597497, 1.968370270333253e-05, 8.749760309001431e-05, 0.00016675743972882628, 2.1353196643758565e-05, 0.00018257695774082094, 0.002879622159525752, 3.2708376238588244e-05, 6.355983350658789e-05, 0.0009078498114831746, 6.314198981272057e-05, 4.9545076763024554e-05, 0.005010190419852734, 0.00021555765124503523, 0.00018923325114883482, 0.00023579830303788185, 0.0021191714331507683, 0.003475240198895335, 0.0004957509227097034, 0.012673033401370049, 0.0026274602860212326, 0.0011926383012905717, 0.028011504560709, 0.14214584231376648, 0.7951081991195679, 0.0, 0.0], [0.005492147523909807, 0.0014179612044245005, 6.310050957836211e-05, 0.0009282372775487602, 0.0004675875243265182, 9.701211820356548e-05, 5.678690649801865e-05, 6.824053707532585e-05, 4.054802775499411e-05, 0.00021011449280194938, 6.534699787152931e-05, 0.00011957778770010918, 9.082331962417811e-05, 9.077353024622425e-05, 0.00013827496150042862, 0.00041228361078538, 0.0001690058852545917, 0.00013570708688348532, 0.002428322099149227, 0.00020654806576203555, 0.0004959598300047219, 0.00016561975644435734, 0.0018254027236253023, 0.001680815708823502, 0.001018735347315669, 0.015071477741003036, 0.0034083749633282423, 0.0033841929398477077, 0.018865516409277916, 0.010037442669272423, 0.00825955905020237, 0.923088550567627, 0.0], [0.009386115707457066, 0.0017380566569045186, 0.0018091693054884672, 0.0014350261772051454, 0.001681282534264028, 0.0019791314844042063, 0.001414343249052763, 0.0021127823274582624, 0.0012016958789899945, 0.001046764780767262, 0.0012532490072771907, 0.0012125702342018485, 0.0006952429539524019, 0.001685017836280167, 0.0012904985342174768, 0.0014949430478736758, 0.0030524623580276966, 0.006176410708576441, 0.003993156366050243, 0.002994523150846362, 0.008827605284750462, 0.009542393498122692, 0.010477361269295216, 0.021451439708471298, 0.06221359223127365, 0.026861054822802544, 0.03390643373131752, 0.11987609416246414, 0.05027470737695694, 0.02679685316979885, 0.03116571344435215, 0.10728638619184494, 0.4436679780483246]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.10520479083061218, 0.8947951793670654, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.03907211124897003, 0.002017225371673703, 0.9589106440544128, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.015578641556203365, 0.0008392545278184116, 0.0006979772006161511, 0.9828841090202332, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.008856471627950668, 9.934287845680956e-06, 1.1174832252436318e-05, 0.0003024702600669116, 0.9908198714256287, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.35445019602775574, 0.030589278787374496, 0.05988955497741699, 0.022903522476553917, 0.04747588187456131, 0.4846915602684021, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.044768933206796646, 0.0015664654783904552, 0.0003773848293349147, 0.0002507324970792979, 0.0004088971472810954, 0.0002606558846309781, 0.9523669481277466, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.09058346599340439, 0.0011470753233879805, 0.006027346942573786, 0.000546847702935338, 0.0017094232607632875, 0.00378508516587317, 0.0026845417451113462, 0.8935161828994751, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.006010720040649176, 2.4289069187943824e-05, 0.00031266716541722417, 1.8682918380363844e-05, 0.0002979242999572307, 9.904515536618419e-06, 6.619554824283114e-06, 7.912191222203546e-07, 0.9933184385299683, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0045468187890946865, 0.00020019362273160368, 0.00029920271481387317, 0.001336395158432424, 0.0003267655265517533, 8.741366741560341e-07, 1.7415704860468395e-05, 2.7834167326545867e-07, 0.00029665243346244097, 0.9929754734039307, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.12262559682130814, 0.02392657846212387, 0.038276489824056625, 0.01617196388542652, 0.030366232618689537, 0.293759286403656, 0.10661353170871735, 0.0705995038151741, 0.041900090873241425, 0.017833104357123375, 0.2379276007413864, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0008121057762764394, 0.00011546660243766382, 0.00013500906061381102, 5.5392923968611285e-05, 0.0001317415590165183, 1.0027196140072192e-06, 1.3799102589473478e-06, 1.6001614255856111e-07, 1.8972989437315846e-06, 5.419660737970844e-07, 4.753100597554294e-07, 0.9987448453903198, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0013333020033314824, 0.00010533037857385352, 0.0007669597980566323, 0.0009021886507980525, 3.5708292216440896e-06, 8.120475740724942e-07, 1.403809051225835e-07, 9.5612755046659e-08, 1.6865038787727826e-06, 2.9789038308081217e-05, 4.3813363959088747e-07, 1.196578750750632e-06, 0.9968544840812683, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0815979614853859, 0.021388858556747437, 0.028877150267362595, 0.012675791047513485, 0.024931589141488075, 0.229964941740036, 0.10401231795549393, 0.06472097337245941, 0.03460092470049858, 0.015198714099824429, 0.18564164638519287, 0.020528050139546394, 0.005003852304071188, 0.17085722088813782, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0013488857075572014, 8.92121170181781e-05, 0.0006859967252239585, 0.0006963216583244503, 2.1248622942948714e-05, 3.7633941474268795e-07, 6.2267383782455e-07, 4.3072165567537013e-07, 7.091880888765445e-06, 0.0013103700475767255, 1.611375211041377e-07, 9.548753041599412e-07, 0.00016453623538836837, 1.1531936650044372e-07, 0.9956737160682678, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0010867505334317684, 0.0004072484443895519, 0.00010700311395339668, 0.000678271462675184, 0.00011028484004782513, 1.318426257057581e-07, 2.660271150034532e-07, 4.6195768277357274e-07, 8.409714610024821e-06, 0.0007784894551150501, 5.109449574547398e-08, 8.792079029262823e-07, 4.934294702252373e-05, 3.4893233191723994e-08, 0.000114411988761276, 0.9966580867767334, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.05868087336421013, 0.01878575049340725, 0.024067310616374016, 0.011013143695890903, 0.02145637385547161, 0.19110563397407532, 0.09902720898389816, 0.06065867841243744, 0.03016272559762001, 0.014801908284425735, 0.15370333194732666, 0.016615159809589386, 0.004385382402688265, 0.14085330069065094, 0.01501499768346548, 0.005390205420553684, 0.13427792489528656, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.07323037087917328, 0.028374575078487396, 0.02105823904275894, 0.007611880078911781, 0.010053581558167934, 0.06553949415683746, 0.1455976516008377, 0.08620842546224594, 0.010241266340017319, 0.0074257380329072475, 0.04526270553469658, 0.006621459033340216, 0.0011621779995039105, 0.03923855349421501, 0.00825688149780035, 0.0030656903982162476, 0.0361226424574852, 0.40492865443229675, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [7.944500976009294e-05, 1.8382123698756914e-06, 3.7134324060161816e-08, 1.5575307770632207e-05, 3.4723789212876e-06, 1.3165096790501707e-09, 2.703870904952055e-08, 1.7186652101486288e-08, 9.2322629541286e-08, 1.350637921859743e-05, 4.4787887287789374e-10, 2.041673052843862e-09, 5.5420287026208825e-08, 3.0638666603799436e-10, 4.2177234149676224e-07, 7.065880708978511e-06, 2.424434542014353e-10, 1.4397358860662735e-09, 0.9998784065246582, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.002934493590146303, 0.0005883843987248838, 0.004250304773449898, 0.0040284618735313416, 0.00011592944065341726, 4.3316217670508195e-06, 6.773899713152787e-06, 7.076467591105029e-05, 0.0002495267544873059, 0.0003159338375553489, 2.08243977795064e-06, 4.4092124880990013e-05, 0.00030446931486949325, 1.4702561657031765e-06, 0.0001976135972654447, 0.0013599261874333024, 1.2478651569836074e-06, 6.875188319099834e-06, 0.00019261146371718496, 0.9853246808052063, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.040565334260463715, 0.017898330464959145, 0.020600970834493637, 0.00982110109180212, 0.0178828164935112, 0.15653996169567108, 0.09208230674266815, 0.056288257241249084, 0.0266613457351923, 0.01447127852588892, 0.12537628412246704, 0.013986771926283836, 0.003927927929908037, 0.11453617364168167, 0.013395380228757858, 0.004846665542572737, 0.10880248248577118, 0.04953397437930107, 0.005186410620808601, 0.00442087184637785, 0.10317537933588028, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.024536332115530968, 0.0031243376433849335, 0.0009699301444925368, 4.6315424697240815e-05, 0.00013434763241093606, 0.0006453943788073957, 0.011668852530419827, 0.0003271345340181142, 0.00045730432611890137, 2.3976095690159127e-05, 0.00034454185515642166, 4.996423376724124e-05, 2.575740472821053e-05, 0.00028217773069627583, 6.525323442474473e-06, 4.981804067938356e-06, 0.00023554022482130677, 0.0002664511266630143, 2.5311126591986977e-05, 2.9761064070044085e-05, 0.0001880926574813202, 0.9566068649291992, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0020759988110512495, 0.00014591786020901054, 5.28989803569857e-05, 4.218077810946852e-05, 4.738718780572526e-05, 4.14233113588125e-07, 0.00012964299821760505, 2.425099773972761e-05, 1.8034025970337098e-06, 1.483928144807578e-06, 1.4489980060261587e-07, 4.199931936454959e-06, 4.1068410894240515e-08, 1.0260500005188078e-07, 8.285463763968437e-07, 5.781902245871606e-07, 7.69515864362802e-08, 6.669609575737923e-08, 6.472614768426865e-05, 1.570090148561576e-06, 5.6418304694716426e-08, 4.403035745781381e-06, 0.997401237487793, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0005159105057828128, 0.00011814619938377291, 3.270557863288559e-05, 0.00021188679966144264, 4.5635159040102735e-05, 2.924881243870914e-07, 3.057936737604905e-06, 7.607346219629108e-08, 0.00013753658276982605, 0.0005283537902869284, 1.1576003089430742e-07, 4.028573584946571e-06, 2.07929269890883e-06, 8.805408668877135e-08, 0.00010051677963929251, 4.431615161593072e-05, 6.963698950812613e-08, 9.373022180625412e-08, 3.3377655199728906e-05, 1.5888872439973056e-05, 5.6106753021367695e-08, 7.05262834799214e-08, 9.389261322212406e-06, 0.9981963038444519, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.06915222853422165, 0.014032107777893543, 0.005599095020443201, 0.0012576848967000842, 0.0008467998122796416, 0.00960117019712925, 0.008965769782662392, 0.052476879209280014, 0.0002502836869098246, 0.0009063849574886262, 0.00541990390047431, 0.0007309208740480244, 0.00019187941506970674, 0.004396578762680292, 0.005964717827737331, 0.0003558541357051581, 0.003877015318721533, 0.009727222844958305, 0.0011023484403267503, 0.00036442867713049054, 0.003413955681025982, 0.0030523540917783976, 0.005698245484381914, 0.0002955728559754789, 0.7923206090927124, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0010461537167429924, 1.9557141058612615e-05, 1.7358959212288028e-06, 3.1030376703711227e-05, 2.73079531325493e-05, 1.0180698062356441e-08, 4.815767624677392e-07, 1.749424853869641e-07, 7.31240987761339e-08, 7.983068712746899e-07, 3.4643101720632785e-09, 4.9067175496020354e-06, 1.0718932230702194e-07, 2.352543715389288e-09, 2.383409878348175e-07, 1.3731333865507622e-06, 1.828867168818249e-09, 6.247621975319362e-09, 9.208330084220506e-06, 1.6384256014134735e-06, 1.2523899695082719e-09, 8.271274221094416e-10, 8.456770046905149e-06, 3.118676431768108e-06, 9.241420961814129e-09, 0.9988435506820679, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0010544934775680304, 0.00021373237541411072, 0.00028157219639979303, 0.0011373378802090883, 0.00014783968799747527, 2.00685326490202e-06, 4.831355909118429e-06, 3.48233857039304e-06, 5.100349881104194e-06, 0.000124204860185273, 9.301529075855797e-07, 1.0582622962829191e-05, 1.1688286576827522e-05, 7.077518944242911e-07, 0.003411600599065423, 0.00019905276712961495, 5.995618153065152e-07, 4.643046622732072e-07, 1.9585138943511993e-05, 0.00011087791790487245, 4.7500583377768635e-07, 3.2808881655910227e-07, 4.535358584689675e-06, 5.1617193093989044e-05, 3.247476740853017e-07, 1.3071385183138773e-05, 0.9931889772415161, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.024200769141316414, 0.002820131368935108, 0.004319298546761274, 0.0009108305675908923, 0.0017753951251506805, 0.003809915855526924, 0.00295332376845181, 0.016714781522750854, 0.0013931734720245004, 0.005003185477107763, 0.002276089508086443, 0.0005876413779333234, 0.0009901626035571098, 0.0018066938500851393, 0.003131241537630558, 0.00023389386478811502, 0.0016082720831036568, 0.009910304099321365, 0.002853953745216131, 0.00020495144417509437, 0.001371265621855855, 0.006919008679687977, 0.001033657230436802, 0.0001452838332625106, 0.017489802092313766, 0.00046553119318559766, 0.0003024086472578347, 0.884769082069397, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0005256090662442148, 3.528650950102019e-06, 1.703768475636025e-06, 9.408179903402925e-05, 0.6647976040840149, 1.6531491553450905e-07, 9.511112466498162e-07, 8.886883620107255e-07, 1.701671317277942e-05, 3.7421832530526444e-05, 6.832266308265389e-08, 9.810898518480826e-06, 7.548737102069936e-08, 4.9632518539510784e-08, 2.0393888462422183e-06, 7.686538992857095e-06, 4.066851388984105e-08, 2.6744315206883584e-08, 3.343187927384861e-05, 4.341078749803273e-07, 3.007988169656528e-08, 3.206056931048806e-08, 4.900574822386261e-06, 3.060942390220589e-06, 1.4603195985785078e-08, 2.2145539332996123e-05, 9.21115315577481e-06, 3.164272044386962e-08, 0.33442792296409607, 0.0, 0.0, 0.0, 0.0], [0.004676995798945427, 0.00028021298930980265, 8.346086542587727e-05, 3.1570127703162143e-06, 4.0653472410667746e-07, 1.3343502303087007e-07, 2.6423564122524112e-05, 1.1439978919725036e-07, 2.7872323471456184e-07, 3.7496031382033834e-06, 4.652898155654839e-08, 1.7213984619957046e-06, 1.816560342149387e-07, 3.148470284486393e-08, 1.8334252160912e-07, 5.214737086589594e-08, 2.521581166092801e-08, 3.078435284464831e-08, 7.142030256090948e-08, 1.6640143485346925e-08, 1.7768224225278573e-08, 8.634508930072116e-08, 2.8009649213345256e-06, 8.454136946056678e-07, 3.098357481690073e-08, 2.927863533841446e-07, 5.676222940564912e-07, 5.055412088950106e-09, 2.914098296002976e-08, 0.9949181079864502, 0.0, 0.0, 0.0], [5.636792411678471e-05, 0.00020023711840622127, 1.6319079350068932e-06, 1.5089327689565835e-06, 1.7779733752831817e-05, 5.95644145118257e-10, 6.940369075891795e-06, 5.034019867622419e-09, 2.1682852491267113e-07, 1.7164272776426515e-06, 1.9326303057898286e-10, 1.8911425314627195e-08, 9.538840117784275e-08, 1.2946883842790413e-10, 8.07715050399338e-09, 4.386615546536632e-05, 9.768683778554887e-11, 5.256080015669795e-10, 6.93216934450902e-05, 7.505880716962565e-08, 7.069290985928234e-11, 3.988046870517792e-08, 1.0610276149236597e-05, 2.2120727862784406e-06, 8.688633701403603e-10, 9.928487088473048e-06, 5.390094592883088e-09, 1.1354458345769203e-10, 3.060037442992325e-06, 3.8945589153627225e-07, 0.9995738863945007, 0.0, 0.0], [0.00035569723695516586, 1.9489458281896077e-05, 9.160958143183962e-06, 1.308523951593088e-05, 2.380885234742891e-05, 2.9718961513935938e-08, 4.160590469837189e-05, 1.7756491388354334e-07, 6.896235049680399e-07, 1.0506230410101125e-06, 1.2230765733534099e-08, 4.290543984097894e-06, 3.2958271845018317e-07, 9.21108966878137e-09, 1.7466396684540086e-06, 4.682785402110312e-06, 7.44272554698e-09, 9.673800427378865e-09, 3.9665097574470565e-05, 7.324891839743941e-07, 5.5436903956262995e-09, 1.0396706073834139e-07, 1.4401548469322734e-05, 8.873331353242975e-06, 5.9894045278952035e-09, 1.5627769244019873e-05, 2.9811192234774353e-06, 6.874329550043967e-09, 4.854650796914939e-06, 7.072258540574694e-06, 6.210680112417322e-06, 0.999423623085022, 0.0], [0.05455271899700165, 0.01642906293272972, 0.01600833609700203, 0.006986880674958229, 0.02488415315747261, 0.07376930117607117, 0.07933779805898666, 0.055945515632629395, 0.02726821042597294, 0.013368778862059116, 0.055903077125549316, 0.00722302682697773, 0.005426580086350441, 0.05012327805161476, 0.00827906746417284, 0.0030609634704887867, 0.046822961419820786, 0.04751850292086601, 0.0028449452947825193, 0.0070379734970629215, 0.042827166616916656, 0.0513819120824337, 0.02728237584233284, 0.026375334709882736, 0.026159200817346573, 0.011997982859611511, 0.006220121402293444, 0.03648780286312103, 0.011124705895781517, 0.005218561738729477, 0.0025592029560357332, 0.0026040265802294016, 0.14697039127349854]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9192656874656677, 0.08073431998491287, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.45437392592430115, 0.4265042543411255, 0.11912184208631516, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5267521739006042, 0.22321628034114838, 0.12420628219842911, 0.12582530081272125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3903489112854004, 0.1709940880537033, 0.06872709095478058, 0.1837182492017746, 0.1862117052078247, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.19744232296943665, 0.25436848402023315, 0.14488448202610016, 0.18925851583480835, 0.20821933448314667, 0.005826779641211033, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.19473567605018616, 0.13241830468177795, 0.14391925930976868, 0.15120738744735718, 0.3002447783946991, 0.02058464288711548, 0.056889988481998444, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1269666701555252, 0.21597379446029663, 0.16089317202568054, 0.19698834419250488, 0.1884462684392929, 0.013544927351176739, 0.07520712912082672, 0.02197970077395439, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2912123203277588, 0.05954226851463318, 0.11079410463571548, 0.09717856347560883, 0.22345604002475739, 0.01626257784664631, 0.08719439059495926, 0.024762295186519623, 0.08959738910198212, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.22981953620910645, 0.038026757538318634, 0.1601383537054062, 0.11780407279729843, 0.1618119478225708, 0.03552818298339844, 0.07561112195253372, 0.02075604535639286, 0.10670626908540726, 0.05379769951105118, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.13314425945281982, 0.18858659267425537, 0.10808096081018448, 0.15994971990585327, 0.1773921102285385, 0.003598014358431101, 0.0250620786100626, 0.012862916104495525, 0.07453092187643051, 0.11275242269039154, 0.004039982333779335, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.16746403276920319, 0.14355222880840302, 0.06118571385741234, 0.17358076572418213, 0.10113829374313354, 0.017553474754095078, 0.03239529952406883, 0.00799549650400877, 0.05453450232744217, 0.07883201539516449, 0.017258208245038986, 0.14450997114181519, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.26996830105781555, 0.13029061257839203, 0.06605684757232666, 0.06156143546104431, 0.08437130600214005, 0.019846616312861443, 0.01631278730928898, 0.012965923175215721, 0.03231464698910713, 0.05254793167114258, 0.019868606701493263, 0.13695643842220306, 0.09693864732980728, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.09820350259542465, 0.13618648052215576, 0.0800577774643898, 0.12152864038944244, 0.1357937902212143, 0.0024323586840182543, 0.017789488658308983, 0.009086485020816326, 0.056375257670879364, 0.08521638810634613, 0.002753336215391755, 0.1520378738641739, 0.0994672104716301, 0.0030714040622115135, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1701289564371109, 0.08885712921619415, 0.09089688211679459, 0.08085789531469345, 0.11427339166402817, 0.010901479050517082, 0.014788419008255005, 0.005497372709214687, 0.051512569189071655, 0.053306855261325836, 0.010595818050205708, 0.09442280977964401, 0.13098116219043732, 0.011153685860335827, 0.07182560861110687, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.10365856438875198, 0.035885412245988846, 0.08803567290306091, 0.06087937578558922, 0.08348329365253448, 0.03080574795603752, 0.029615944251418114, 0.010918702930212021, 0.04049992933869362, 0.04288605973124504, 0.032192956656217575, 0.15008129179477692, 0.12658777832984924, 0.034902174025774, 0.05825432762503624, 0.07131282240152359, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.07047096639871597, 0.0960099920630455, 0.05621577426791191, 0.08699887245893478, 0.0993412435054779, 0.001629879348911345, 0.012408615089952946, 0.006380429025739431, 0.041014041751623154, 0.06348711997270584, 0.001848218496888876, 0.11387649178504944, 0.07328982651233673, 0.0020712928380817175, 0.07246165722608566, 0.20012778043746948, 0.002367777982726693, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.05659444257616997, 0.08906207978725433, 0.047032397240400314, 0.09457878023386002, 0.08793890476226807, 0.0019721658900380135, 0.01776767149567604, 0.005990428384393454, 0.06014860048890114, 0.08834964036941528, 0.002263767411932349, 0.1046152412891388, 0.06079370528459549, 0.002556620631366968, 0.07818622887134552, 0.19496023654937744, 0.0029299892485141754, 0.004259055946022272, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.15970617532730103, 0.026096440851688385, 0.04515179991722107, 0.034975796937942505, 0.08030674606561661, 0.05469035357236862, 0.040785446763038635, 0.026513049378991127, 0.02725192718207836, 0.03919816017150879, 0.053514350205659866, 0.0484292097389698, 0.0626426562666893, 0.05558209866285324, 0.05559665709733963, 0.04792960733175278, 0.05676325783133507, 0.048923004418611526, 0.03594319894909859, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.08663123846054077, 0.09557435661554337, 0.03673812001943588, 0.06946706771850586, 0.05681459233164787, 0.008190210908651352, 0.022195840254426003, 0.007642821408808231, 0.03146826848387718, 0.07555205374956131, 0.008965261280536652, 0.052634816616773605, 0.04491107165813446, 0.009935054928064346, 0.04481377452611923, 0.15198467671871185, 0.01093340665102005, 0.007993672043085098, 0.16402561962604523, 0.01352810487151146, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.04783453047275543, 0.06669355928897858, 0.03798918053507805, 0.06040370091795921, 0.06899044662714005, 0.0010267297038808465, 0.008172671310603619, 0.004158169962465763, 0.028268279507756233, 0.04407240077853203, 0.0011586471227928996, 0.0783291831612587, 0.050828997045755386, 0.0013004974462091923, 0.0490429662168026, 0.14145003259181976, 0.0014934339560568333, 0.002556685358285904, 0.17534077167510986, 0.12910206615924835, 0.0017870554002001882, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.041140902787446976, 0.04766073077917099, 0.035869985818862915, 0.066661037504673, 0.07969274371862411, 0.002365077380090952, 0.02034018374979496, 0.004854491911828518, 0.0643620640039444, 0.06737152487039566, 0.002707368927076459, 0.05596053600311279, 0.05648665875196457, 0.003076723078265786, 0.05354388803243637, 0.15165922045707703, 0.0035397163592278957, 0.004673927556723356, 0.16402719914913177, 0.059681568294763565, 0.004154941067099571, 0.010169520042836666, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0662880688905716, 0.04092540591955185, 0.027322685346007347, 0.045053672045469284, 0.06575217097997665, 0.015657568350434303, 0.02788187563419342, 0.013711261563003063, 0.031742945313453674, 0.052807457745075226, 0.015447774901986122, 0.032181113958358765, 0.03290105611085892, 0.01629885844886303, 0.0266366396099329, 0.09772849828004837, 0.017114214599132538, 0.01691945269703865, 0.09847067296504974, 0.04787908494472504, 0.018412543460726738, 0.015331601724028587, 0.17753538489341736, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.09801428765058517, 0.026328815147280693, 0.03586814925074577, 0.05713058263063431, 0.06943874806165695, 0.012128956615924835, 0.020909084007143974, 0.008747958578169346, 0.026999657973647118, 0.03726677596569061, 0.011716339737176895, 0.08499537408351898, 0.05501334369182587, 0.01219671405851841, 0.03563909977674484, 0.08789660036563873, 0.012970111332833767, 0.010851016268134117, 0.06408386677503586, 0.05963921174407005, 0.01449218112975359, 0.006093733478337526, 0.09761438518762589, 0.053964972496032715, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0276932492852211, 0.04073771834373474, 0.031223541125655174, 0.05879035219550133, 0.05601825192570686, 0.0015714798355475068, 0.01190804224461317, 0.0033397902734577656, 0.051765501499176025, 0.052912451326847076, 0.001825982122682035, 0.060300350189208984, 0.028357168659567833, 0.002087808446958661, 0.05086479336023331, 0.07898838818073273, 0.0023987058084458113, 0.0029048218857496977, 0.11135735362768173, 0.04586018994450569, 0.0028849169611930847, 0.011431249789893627, 0.1234055683016777, 0.1348847597837448, 0.006487555801868439, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.15390777587890625, 0.023786788806319237, 0.053202446550130844, 0.03963885083794594, 0.05711061879992485, 0.015628939494490623, 0.020206071436405182, 0.009252369403839111, 0.021311858668923378, 0.02902994118630886, 0.014741901308298111, 0.0612383708357811, 0.10112589597702026, 0.015157824382185936, 0.04335402324795723, 0.04090719297528267, 0.0157326627522707, 0.020073404535651207, 0.05374935641884804, 0.03468615189194679, 0.01698938012123108, 0.0063684978522360325, 0.04042016342282295, 0.031060414388775826, 0.013937165960669518, 0.06738191843032837, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.08555092662572861, 0.03505741059780121, 0.05885256081819534, 0.034979090094566345, 0.05178743600845337, 0.0025119921192526817, 0.004151220433413982, 0.002085918327793479, 0.014081120491027832, 0.02449135296046734, 0.002376002725213766, 0.09535117447376251, 0.07766135036945343, 0.0024908820632845163, 0.045726776123046875, 0.05774117261171341, 0.002660379046574235, 0.0033477561082690954, 0.04799828305840492, 0.026788825169205666, 0.0029587154276669025, 0.004655785858631134, 0.03607098385691643, 0.021599186584353447, 0.00478863250464201, 0.22052206099033356, 0.03371304273605347, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.020706715062260628, 0.037194062024354935, 0.01972370408475399, 0.038942236453294754, 0.03182700648903847, 0.0012253682361915708, 0.008815746754407883, 0.00240529328584671, 0.03457954525947571, 0.047298066318035126, 0.001395374652929604, 0.05148206278681755, 0.0204867422580719, 0.0015608381945639849, 0.03826117143034935, 0.048637520521879196, 0.0017825315007939935, 0.0025446037761867046, 0.06541350483894348, 0.0418856143951416, 0.002096060197800398, 0.00940138939768076, 0.0846002921462059, 0.09019989520311356, 0.005403276067227125, 0.22932566702365875, 0.05692271143198013, 0.005882916506379843, 0.0, 0.0, 0.0, 0.0, 0.0], [0.08582808822393417, 0.039671748876571655, 0.014841827563941479, 0.05653620883822441, 0.05960610881447792, 0.006987519562244415, 0.0101100979372859, 0.0028877253644168377, 0.015322855673730373, 0.025928759947419167, 0.006830446422100067, 0.033548951148986816, 0.021093526855111122, 0.00721315573900938, 0.01932339183986187, 0.05298227071762085, 0.0076586115173995495, 0.005157842300832272, 0.06523182988166809, 0.018170004710555077, 0.008534708060324192, 0.004368167370557785, 0.02691243775188923, 0.049627937376499176, 0.004404333420097828, 0.1938866823911667, 0.03933224827051163, 0.005363550968468189, 0.1126389130949974, 0.0, 0.0, 0.0, 0.0], [0.07040347158908844, 0.05926162004470825, 0.015334843657910824, 0.0241390373557806, 0.015728842467069626, 0.01949211023747921, 0.017311517149209976, 0.017303066328167915, 0.020563244819641113, 0.0451558418571949, 0.0218158308416605, 0.07079727202653885, 0.03006395697593689, 0.02354060858488083, 0.020684480667114258, 0.02116367220878601, 0.02644512802362442, 0.023540040478110313, 0.056637249886989594, 0.0336947925388813, 0.030707286670804024, 0.015993356704711914, 0.015474074520170689, 0.030803624540567398, 0.03180558606982231, 0.07969610393047333, 0.03437487408518791, 0.034537144005298615, 0.030624376609921455, 0.06290692090988159, 0.0, 0.0, 0.0], [0.05338500440120697, 0.02962152473628521, 0.021030090749263763, 0.02369571104645729, 0.03343641385436058, 0.018393825739622116, 0.024060716852545738, 0.02281002141535282, 0.01397236529737711, 0.028813548386096954, 0.019059741869568825, 0.015371966175734997, 0.02533530816435814, 0.019971951842308044, 0.01407573837786913, 0.0388445109128952, 0.021346213296055794, 0.01932142674922943, 0.056326594203710556, 0.0213600043207407, 0.023394573479890823, 0.023136641830205917, 0.06416383385658264, 0.06724689900875092, 0.0346951000392437, 0.04349019005894661, 0.03032725304365158, 0.032857123762369156, 0.05327507480978966, 0.0659981369972229, 0.0411824993789196, 0.0, 0.0], [0.18177087604999542, 0.019533153623342514, 0.02800292894244194, 0.02911018766462803, 0.04134833440184593, 0.01801948808133602, 0.010471731424331665, 0.008382911793887615, 0.015335792675614357, 0.021839452907443047, 0.01689334399998188, 0.038061387836933136, 0.03643865883350372, 0.017464257776737213, 0.026129070669412613, 0.040115050971508026, 0.018317215144634247, 0.012488214299082756, 0.051369696855545044, 0.019443845376372337, 0.019889768213033676, 0.0035764535423368216, 0.026232963427901268, 0.018429193645715714, 0.011723746545612812, 0.0327298678457737, 0.0348082073032856, 0.012035040184855461, 0.060302939265966415, 0.00787330698221922, 0.04227295145392418, 0.07958998531103134, 0.0], [0.015003404580056667, 0.020334860309958458, 0.007813435047864914, 0.01655357889831066, 0.016466092318296432, 0.00023809655976947397, 0.0019598910585045815, 0.0006898257415741682, 0.006483218166977167, 0.010734080336987972, 0.00024435287923552096, 0.014634673483669758, 0.009247622452676296, 0.0002605918562039733, 0.009339914657175541, 0.04272656887769699, 0.0002886395959649235, 0.00038116672658361495, 0.054749373346567154, 0.09452769160270691, 0.0003421127039473504, 0.0017270190874114633, 0.04745931178331375, 0.02661379985511303, 0.001023865770548582, 0.1653798520565033, 0.014187110587954521, 0.0013092352310195565, 0.047706540673971176, 0.0111984983086586, 0.2205076366662979, 0.139426127076149, 0.0004418626776896417]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9333657622337341, 0.06663426011800766, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3245236277580261, 0.5923718214035034, 0.08310455083847046, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1415974646806717, 0.5143810510635376, 0.2814413905143738, 0.06258013844490051, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.25262272357940674, 0.058340705931186676, 0.10458865016698837, 0.4411159157752991, 0.14333190023899078, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.18051552772521973, 0.09828907251358032, 0.10873960703611374, 0.1226268783211708, 0.0999554991722107, 0.3898734748363495, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.17192299664020538, 0.02332099713385105, 0.12332707643508911, 0.060764994472265244, 0.059717126190662384, 0.34759172797203064, 0.21335503458976746, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.09627040475606918, 0.046836212277412415, 0.02825731411576271, 0.03239252045750618, 0.058650437742471695, 0.15829354524612427, 0.3099649250507355, 0.26933467388153076, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.09948235750198364, 0.06464183330535889, 0.028671855106949806, 0.07305670529603958, 0.029787182807922363, 0.1396002322435379, 0.20754705369472504, 0.265802264213562, 0.09141054004430771, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.05632037669420242, 0.02988584339618683, 0.013419918715953827, 0.0024075540713965893, 0.013245469890534878, 0.045645419508218765, 0.055225711315870285, 0.10027103126049042, 0.6579985618591309, 0.02558005601167679, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.042669959366321564, 0.010426481254398823, 0.01065221056342125, 0.01344663742929697, 0.009353147819638252, 0.040159791707992554, 0.07105176150798798, 0.1373765468597412, 0.10423266142606735, 0.2173663228750229, 0.34326446056365967, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0296839140355587, 0.0025616430211812258, 0.004407483618706465, 0.034248705953359604, 0.014238743111491203, 0.028001833707094193, 0.022288035601377487, 0.07105964422225952, 0.04026234894990921, 0.5543041825294495, 0.17333050072193146, 0.025612998753786087, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.04039592295885086, 0.008631582371890545, 0.005494222976267338, 0.0038641407154500484, 0.023363107815384865, 0.027207026258111, 0.02567734755575657, 0.05048523098230362, 0.05105610191822052, 0.05041782185435295, 0.14164339005947113, 0.511528491973877, 0.06023566424846649, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.028706379234790802, 0.004808461759239435, 0.0047236536629498005, 0.005382600240409374, 0.003456039121374488, 0.014470171183347702, 0.02403739094734192, 0.0416262112557888, 0.03567296639084816, 0.07060734927654266, 0.10830988734960556, 0.05811617895960808, 0.2062121480703354, 0.39387065172195435, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.05342642217874527, 0.011923286132514477, 0.0155722601339221, 0.002112322486937046, 0.005851039197295904, 0.02217092365026474, 0.038184694945812225, 0.0274115689098835, 0.054642848670482635, 0.04910831153392792, 0.12328379601240158, 0.052871763706207275, 0.07545653730630875, 0.3701530992984772, 0.09783117473125458, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.008346711285412312, 0.00027852714993059635, 0.0011785987298935652, 0.002139549469575286, 0.002476167632266879, 0.002918291138485074, 0.004576893523335457, 0.003965593408793211, 0.004973020404577255, 0.011347766034305096, 0.013014068827033043, 0.0055459714494645596, 0.0208955816924572, 0.03838539123535156, 0.8750316500663757, 0.0049261897802352905, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.021700311452150345, 0.002678664866834879, 0.0023839266505092382, 0.0028156274929642677, 0.0015562352491542697, 0.006139409262686968, 0.009039808996021748, 0.013740861788392067, 0.012412207201123238, 0.024686550721526146, 0.03406905010342598, 0.017561476677656174, 0.06082962453365326, 0.12004056572914124, 0.11516796052455902, 0.12663687765598297, 0.42854082584381104, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.01968139037489891, 0.0028661887627094984, 0.002752861240878701, 0.0023642033338546753, 0.0022205759305506945, 0.004776970017701387, 0.005015391390770674, 0.007020782213658094, 0.006603003013879061, 0.01582488976418972, 0.02177913300693035, 0.02237590402364731, 0.039055563509464264, 0.07342635095119476, 0.07227564603090286, 0.08103632926940918, 0.2556319534778595, 0.36529290676116943, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.03443868085741997, 0.002429508836939931, 0.0027038794942200184, 0.0010108946589753032, 0.0028212431352585554, 0.009310666471719742, 0.007474070880562067, 0.010526398196816444, 0.019342618063092232, 0.006583386100828648, 0.030525268986821175, 0.008166547864675522, 0.023945648223161697, 0.08047986775636673, 0.044289398938417435, 0.048865146934986115, 0.2326631247997284, 0.38709723949432373, 0.04732643812894821, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0036976826377213, 0.006450955290347338, 0.000492172606755048, 0.0003069589438382536, 0.0001240077253896743, 0.001072736456990242, 0.0008858803194016218, 0.0013806363567709923, 0.0008200182928703725, 0.00027311858139000833, 0.0027830663602799177, 0.0352943055331707, 0.003561378689482808, 0.007148320320993662, 0.0016474081203341484, 0.01673167198896408, 0.019172819331288338, 0.022339211776852608, 0.8733667135238647, 0.00245096068829298, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.013628792949020863, 0.0014384457608684897, 0.0012188642285764217, 0.0012915866682305932, 0.0006118024466559291, 0.002140038413926959, 0.002746958751231432, 0.0033360482193529606, 0.0030918733682483435, 0.005988915916532278, 0.007237223908305168, 0.0035477466881275177, 0.01289195567369461, 0.022229144349694252, 0.02082424983382225, 0.026295335963368416, 0.0764816626906395, 0.16261446475982666, 0.12638667225837708, 0.10034441202878952, 0.4056537449359894, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.021432960405945778, 0.0007291642832569778, 0.0010889682453125715, 0.0008559629204683006, 0.001055659493431449, 0.0023542516864836216, 0.0018633344443514943, 0.0024869930930435658, 0.004011375363916159, 0.0036456268280744553, 0.0066366177052259445, 0.002459165407344699, 0.00810664240270853, 0.019501397386193275, 0.013945517130196095, 0.016831597313284874, 0.06727854162454605, 0.10203751176595688, 0.07506164908409119, 0.037855081260204315, 0.347415953874588, 0.2633460760116577, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.01837441511452198, 0.0016340137226507068, 0.0002648660447448492, 0.0006277099018916488, 0.0007212883210740983, 0.0022947124671190977, 0.0014375769533216953, 0.0024335708003491163, 0.0010225045261904597, 0.0021730936132371426, 0.005665966309607029, 0.000585706380661577, 0.00473030423745513, 0.015789616852998734, 0.009121059440076351, 0.006447892170399427, 0.049651850014925, 0.07221095263957977, 0.04530426487326622, 0.02253621816635132, 0.2338050752878189, 0.28100958466529846, 0.22215774655342102, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.016010280698537827, 0.0004190760082565248, 0.0016793122049421072, 0.002033163793385029, 0.001112602767534554, 0.002304120222106576, 0.0016414890997111797, 0.0020452288445085287, 0.0008826436242088675, 0.0035318138543516397, 0.004660747945308685, 0.0011461266549304128, 0.004025276750326157, 0.011729463003575802, 0.006906007416546345, 0.005978980101644993, 0.03413611650466919, 0.05391981825232506, 0.07536917924880981, 0.015544150024652481, 0.15307287871837616, 0.21672509610652924, 0.23267340660095215, 0.15245294570922852, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.016415515914559364, 0.0010880999034270644, 0.0013027010718360543, 0.0012335632927715778, 0.0010325222974643111, 0.0013605308486148715, 0.0011352741857990623, 0.0009713201434351504, 0.001758021884597838, 0.0023549962788820267, 0.0022677970118820667, 0.0026170078199356794, 0.0032849623821675777, 0.005564440041780472, 0.0072877416387200356, 0.0065826671198010445, 0.016911091282963753, 0.023348145186901093, 0.03336377441883087, 0.012060865759849548, 0.08410528302192688, 0.10776986181735992, 0.12741322815418243, 0.25009584426879883, 0.2886747717857361, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.031117742881178856, 0.0015063059981912374, 0.0010839332826435566, 0.002421523677185178, 0.0013826879439875484, 0.003793728072196245, 0.001633930136449635, 0.0031195227056741714, 0.001281264005228877, 0.0020685256458818913, 0.004760123323649168, 0.0008757332107052207, 0.008592124097049236, 0.009353642351925373, 0.011993260122835636, 0.005963006988167763, 0.022028174251317978, 0.03411326929926872, 0.009586770087480545, 0.013681815937161446, 0.08417055010795593, 0.08917813003063202, 0.10806846618652344, 0.1556078940629959, 0.37236839532852173, 0.020249493420124054, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.014838487841188908, 0.0005757315084338188, 0.004743656609207392, 0.00045677347225137055, 0.0007412281702272594, 0.0015000017592683434, 0.0008866065763868392, 0.0008452095207758248, 0.00010359254520153627, 0.000906514236703515, 0.0018096797866746783, 0.0602911040186882, 0.0015377553645521402, 0.0033079395070672035, 0.0013713664375245571, 0.0020826763939112425, 0.008643986657261848, 0.009088870137929916, 0.00776095874607563, 0.00580833712592721, 0.033865127712488174, 0.039871834218502045, 0.053745534271001816, 0.036947719752788544, 0.12259436398744583, 0.5718704462051392, 0.013804465532302856, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.018570011481642723, 0.0012143178610131145, 0.0012880434514954686, 0.001061256043612957, 0.0007490047719329596, 0.0010485639795660973, 0.0008687886293046176, 0.0005973865045234561, 0.0012938273139297962, 0.0014042500406503677, 0.001105510862544179, 0.0005003446713089943, 0.002026260830461979, 0.002146314363926649, 0.00287379277870059, 0.0026413730811327696, 0.005802985280752182, 0.008191363885998726, 0.008339081890881062, 0.005543306935578585, 0.026558665558695793, 0.03308923915028572, 0.03250737115740776, 0.09199852496385574, 0.10410481691360474, 0.16861768066883087, 0.20895418524742126, 0.2669035792350769, 0.0, 0.0, 0.0, 0.0, 0.0], [0.01665443740785122, 0.0007248668116517365, 0.0008980656857602298, 0.003161689033731818, 0.0005522827268578112, 0.0016607277793809772, 0.0007486122194677591, 0.0009652791195549071, 0.00038428022526204586, 0.0022577799391001463, 0.0015545637579634786, 0.0007037009345367551, 0.0014688180526718497, 0.0027998804580420256, 0.0030139798764139414, 0.0053690355271101, 0.006552338134497404, 0.008701560087502003, 0.007138869259506464, 0.006516331806778908, 0.026185570284724236, 0.03929201886057854, 0.031550075858831406, 0.024343032389879227, 0.10670755803585052, 0.15159793198108673, 0.13674214482307434, 0.32013964653015137, 0.09161487221717834, 0.0, 0.0, 0.0, 0.0], [0.037226852029561996, 0.0007442755741067231, 0.001918033347465098, 0.0014290648978203535, 0.002559738466516137, 0.003292838577181101, 0.0009007276967167854, 0.0015445105964317918, 0.00035572153865359724, 0.0004492737934924662, 0.002668820321559906, 0.00140466564334929, 0.001728102914057672, 0.004542732611298561, 0.0012941034510731697, 0.00467766635119915, 0.009138191118836403, 0.008992942981421947, 0.005343662574887276, 0.002031839219853282, 0.0309309009462595, 0.021215271204710007, 0.036399755626916885, 0.0567946583032608, 0.11195947974920273, 0.011458104476332664, 0.03353286162018776, 0.26588529348373413, 0.2469542920589447, 0.09262561053037643, 0.0, 0.0, 0.0], [0.04408878833055496, 0.0011082955170422792, 0.0033875920344144106, 0.0048531959764659405, 0.0028643226251006126, 0.004500862676650286, 0.0014518103562295437, 0.0021924953907728195, 0.0007902364595793188, 0.0006717380601912737, 0.0035771592520177364, 0.0005131773068569601, 0.012861719354987144, 0.005116851069033146, 0.0030142515897750854, 0.005887468811124563, 0.010453413240611553, 0.013818331062793732, 0.008691059425473213, 0.011229274794459343, 0.03140093386173248, 0.023181650787591934, 0.03044436313211918, 0.03520682454109192, 0.09999864548444748, 0.006090163718909025, 0.1471421718597412, 0.1639304906129837, 0.12749536335468292, 0.19357739388942719, 0.0004599905223585665, 0.0, 0.0], [0.03717399761080742, 0.005006891675293446, 0.0016112299636006355, 0.0028301465790718794, 0.0005118493572808802, 0.002707127947360277, 0.0020970318000763655, 0.0012328778393566608, 0.0006310883327387273, 0.0017632459057494998, 0.0017868791474029422, 0.00025283321156166494, 0.001072075916454196, 0.0026448359712958336, 0.001566158840432763, 0.003808408509939909, 0.005276744719594717, 0.006930255796760321, 0.013310836628079414, 0.0035816440358757973, 0.018304530531167984, 0.02668476104736328, 0.019971540197730064, 0.032155781984329224, 0.07432041317224503, 0.02392224594950676, 0.08761478960514069, 0.18007561564445496, 0.027492590248584747, 0.05972246080636978, 0.19122685492038727, 0.16271229088306427, 0.0], [0.00811693910509348, 0.0008723061182536185, 0.0003707293944898993, 0.00047348643420264125, 0.00017833005404099822, 0.0003994710568804294, 0.00029511720640584826, 0.00018311945314053446, 0.000167145932209678, 0.00023702479666098952, 0.0002533363294787705, 0.00012855073146056384, 0.00020213225798215717, 0.00039944934542290866, 0.0001651181373745203, 0.0004622875130735338, 0.0008780225180089474, 0.0011140464339405298, 0.0020708786323666573, 0.0019636773504316807, 0.003527855733409524, 0.0044752187095582485, 0.004463486839085817, 0.007312539964914322, 0.014446244575083256, 0.03503045067191124, 0.02001415751874447, 0.04388578608632088, 0.019436746835708618, 0.11325734853744507, 0.07277627289295197, 0.16196833550930023, 0.4804745018482208]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9473748207092285, 0.05262523144483566, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8785884380340576, 0.05539466068148613, 0.06601691246032715, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.727077066898346, 0.1370987892150879, 0.04866092652082443, 0.08716326951980591, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4651745557785034, 0.13429313898086548, 0.1535816192626953, 0.1747255027294159, 0.07222513854503632, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1703597605228424, 0.01184194628149271, 0.023650869727134705, 0.021745814010500908, 0.025856321677565575, 0.7465453147888184, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.14214575290679932, 0.04383273050189018, 0.05021181330084801, 0.045165032148361206, 0.05872126668691635, 0.5111534595489502, 0.14877000451087952, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.08473353087902069, 0.020369814708828926, 0.037461623549461365, 0.03195910155773163, 0.03419600799679756, 0.43500685691833496, 0.11894061416387558, 0.2373325079679489, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.342307984828949, 0.03593634068965912, 0.07259213924407959, 0.10352761298418045, 0.08196527510881424, 0.07694564014673233, 0.14196324348449707, 0.09896712005138397, 0.045794591307640076, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.37114858627319336, 0.06278738379478455, 0.058069515973329544, 0.05566278472542763, 0.1312483549118042, 0.07535628229379654, 0.10726629942655563, 0.07924022525548935, 0.030107339844107628, 0.029113231226801872, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.06430108845233917, 0.005169108510017395, 0.01101299561560154, 0.009054885245859623, 0.011748063378036022, 0.3188501298427582, 0.0368494838476181, 0.0831955224275589, 0.012068143114447594, 0.014676203951239586, 0.433074414730072, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.23777925968170166, 0.03812997788190842, 0.019743362441658974, 0.07508029043674469, 0.1442079246044159, 0.062449272722005844, 0.07018385082483292, 0.06523599475622177, 0.04883221164345741, 0.034600336104631424, 0.0643976703286171, 0.13935978710651398, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.29014477133750916, 0.04085767641663551, 0.06965630501508713, 0.06467735767364502, 0.11515594273805618, 0.07279439270496368, 0.05406039580702782, 0.04095998778939247, 0.0364612452685833, 0.03709696978330612, 0.08112157136201859, 0.06249444931745529, 0.034518904983997345, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.04191606864333153, 0.0033880709670484066, 0.007082364521920681, 0.005899207666516304, 0.007586183492094278, 0.20389792323112488, 0.023296771571040154, 0.05173071473836899, 0.007816805504262447, 0.009731377474963665, 0.2776019275188446, 0.008386767469346523, 0.016172707080841064, 0.3354931175708771, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.15129351615905762, 0.042407941073179245, 0.04383384436368942, 0.09706763178110123, 0.14943552017211914, 0.04439883306622505, 0.061745043843984604, 0.04199514538049698, 0.018608780577778816, 0.03141244128346443, 0.05092645436525345, 0.06660286337137222, 0.09416220337152481, 0.05761289596557617, 0.04849694296717644, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2995801866054535, 0.07432064414024353, 0.030061958357691765, 0.016736479476094246, 0.03856481984257698, 0.051068782806396484, 0.0940866693854332, 0.056067924946546555, 0.05458228662610054, 0.04522038623690605, 0.05638071522116661, 0.01537805050611496, 0.04082851856946945, 0.060846954584121704, 0.03081105835735798, 0.035464510321617126, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.03043997846543789, 0.0024933929089456797, 0.005298204720020294, 0.004223392345011234, 0.005517442710697651, 0.14508457481861115, 0.01603415049612522, 0.03598647937178612, 0.005758048500865698, 0.007398166693747044, 0.19613462686538696, 0.006090892944484949, 0.01146511361002922, 0.23737996816635132, 0.008031771518290043, 0.005861489102244377, 0.27680230140686035, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.015668945387005806, 0.0019133484456688166, 0.006747933570295572, 0.005610871594399214, 0.006710356567054987, 0.10858529061079025, 0.013436977751553059, 0.03067478910088539, 0.00869804061949253, 0.005958769004791975, 0.15696409344673157, 0.006401259917765856, 0.014357192441821098, 0.19220466911792755, 0.009938809089362621, 0.008154557086527348, 0.22861403226852417, 0.1793600618839264, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2751207649707794, 0.04635605588555336, 0.02578277699649334, 0.02037108689546585, 0.04519131779670715, 0.04741503670811653, 0.05800836160778999, 0.05449456349015236, 0.02185584232211113, 0.028674187138676643, 0.05054796114563942, 0.03578945994377136, 0.014343996532261372, 0.05505189299583435, 0.019970891997218132, 0.0250706747174263, 0.0598367340862751, 0.10591265559196472, 0.010205721482634544, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.12210460752248764, 0.029006360098719597, 0.027926113456487656, 0.030763691291213036, 0.06431956589221954, 0.05075869709253311, 0.05746713653206825, 0.038544539362192154, 0.028814472258090973, 0.036410342901945114, 0.05530693009495735, 0.02755570411682129, 0.05062383413314819, 0.06039684638381004, 0.03790910169482231, 0.03416259214282036, 0.06550326943397522, 0.0822460949420929, 0.08903136104345322, 0.01114883366972208, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.01992272399365902, 0.0015991262625902891, 0.0035362725611776114, 0.0027606100775301456, 0.003674747422337532, 0.09198576211929321, 0.009868199005723, 0.021762734279036522, 0.003674617502838373, 0.0048002987168729305, 0.12327178567647934, 0.0039482261054217815, 0.0077277058735489845, 0.14901940524578094, 0.005094496067613363, 0.0038495471235364676, 0.17433811724185944, 0.1450374871492386, 0.003139178967103362, 0.003901567542925477, 0.21708735823631287, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.025169143453240395, 0.0025891431141644716, 0.007904483005404472, 0.0028181765228509903, 0.008317484520375729, 0.06284766644239426, 0.016097377985715866, 0.024833567440509796, 0.00765804061666131, 0.011317078955471516, 0.08451006561517715, 0.012135407887399197, 0.022048380225896835, 0.1001725047826767, 0.015103278681635857, 0.02015225775539875, 0.11906816065311432, 0.14148962497711182, 0.006576652638614178, 0.007074058521538973, 0.14850656688213348, 0.1536109298467636, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.08679645508527756, 0.015818681567907333, 0.009913154877722263, 0.00594112416729331, 0.011749097146093845, 0.044022489339113235, 0.049411579966545105, 0.047211579978466034, 0.02244851179420948, 0.028144152835011482, 0.052493732422590256, 0.013664891012012959, 0.0380445159971714, 0.058564916253089905, 0.016008712351322174, 0.028531767427921295, 0.0675240010023117, 0.1000404879450798, 0.026074478402733803, 0.01816527359187603, 0.08061446994543076, 0.14588385820388794, 0.032932016998529434, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.12203323841094971, 0.026796922087669373, 0.03471273183822632, 0.016600852832198143, 0.05098596215248108, 0.03362346068024635, 0.033762916922569275, 0.03289441391825676, 0.022763587534427643, 0.03469543159008026, 0.03710823878645897, 0.02750304527580738, 0.030508054420351982, 0.040704917162656784, 0.019409827888011932, 0.033388108015060425, 0.04603789001703262, 0.08141942322254181, 0.02579292468726635, 0.017713351175189018, 0.05326375365257263, 0.06955216079950333, 0.07340100407600403, 0.03532779961824417, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.012632705271244049, 0.003196731209754944, 0.008999625220894814, 0.00378710706718266, 0.005590212065726519, 0.0601874515414238, 0.010173025541007519, 0.026063397526741028, 0.008280334062874317, 0.005998437292873859, 0.08480245620012283, 0.007755735889077187, 0.014807658270001411, 0.10079345107078552, 0.011636023409664631, 0.007885105907917023, 0.12061367928981781, 0.12819860875606537, 0.006487112957984209, 0.003230573609471321, 0.15047509968280792, 0.10557688027620316, 0.01548060029745102, 0.01902632601559162, 0.0783216655254364, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.11176054924726486, 0.018635567277669907, 0.056223757565021515, 0.046772804111242294, 0.037364911288022995, 0.02299341931939125, 0.031365279108285904, 0.026408882811665535, 0.04335922375321388, 0.05663558468222618, 0.0217863991856575, 0.02382213994860649, 0.03064168430864811, 0.023289261385798454, 0.05430489405989647, 0.06881189346313477, 0.02448936179280281, 0.047770872712135315, 0.03627175837755203, 0.02222253568470478, 0.026998937129974365, 0.021766116842627525, 0.03442490100860596, 0.028240256011486053, 0.058919232338666916, 0.024719836190342903, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.10639805346727371, 0.037107910960912704, 0.08273956924676895, 0.017856858670711517, 0.020949995145201683, 0.018305247649550438, 0.02262010984122753, 0.018192268908023834, 0.0218511875718832, 0.012518531642854214, 0.019214097410440445, 0.030340097844600677, 0.07187613844871521, 0.020787997171282768, 0.03963525593280792, 0.061515871435403824, 0.02317928895354271, 0.0439804345369339, 0.046192266047000885, 0.02066797763109207, 0.027080873027443886, 0.043865494430065155, 0.0327674075961113, 0.043690674006938934, 0.05080845206975937, 0.04029490426182747, 0.025563009083271027, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.015084553509950638, 0.003822383936494589, 0.005877267569303513, 0.004971853923052549, 0.005370147526264191, 0.05223644897341728, 0.016127675771713257, 0.03182988613843918, 0.008211127482354641, 0.011473814025521278, 0.06704684346914291, 0.010528383776545525, 0.01059822365641594, 0.07938899099826813, 0.0072117154486477375, 0.006271465681493282, 0.09142374992370605, 0.10866504907608032, 0.003973816521465778, 0.00562167027965188, 0.10983327031135559, 0.09237756580114365, 0.0229604784399271, 0.019314922392368317, 0.08864142745733261, 0.018464693799614906, 0.01102224551141262, 0.0916503444314003, 0.0, 0.0, 0.0, 0.0, 0.0], [0.09854131937026978, 0.03967057541012764, 0.05052143335342407, 0.047943901270627975, 0.01953185349702835, 0.015683408826589584, 0.025074757635593414, 0.014997916296124458, 0.027723459526896477, 0.01641818694770336, 0.016389019787311554, 0.026316560804843903, 0.03435926511883736, 0.017757995054125786, 0.023362677544355392, 0.03763514384627342, 0.019405612722039223, 0.034421686083078384, 0.04902298375964165, 0.030190549790859222, 0.02215908095240593, 0.03754065930843353, 0.03879313915967941, 0.040324144065380096, 0.0423126257956028, 0.06829197704792023, 0.025314131751656532, 0.043300729244947433, 0.036995261907577515, 0.0, 0.0, 0.0, 0.0], [0.10688817501068115, 0.03659576177597046, 0.005083094816654921, 0.010160427540540695, 0.013297352008521557, 0.04175207391381264, 0.02624681033194065, 0.03012854792177677, 0.013482392765581608, 0.01822318136692047, 0.04582624509930611, 0.025558779016137123, 0.015618832781910896, 0.050398923456668854, 0.011657011695206165, 0.011659123003482819, 0.055155206471681595, 0.05091661587357521, 0.019206780940294266, 0.013998415321111679, 0.06383471935987473, 0.02908891625702381, 0.01671043410897255, 0.02609526738524437, 0.05484984442591667, 0.03806670010089874, 0.038960713893175125, 0.05375231057405472, 0.02367917262017727, 0.05310812219977379, 0.0, 0.0, 0.0], [0.10871605575084686, 0.06286414712667465, 0.023045096546411514, 0.012493215501308441, 0.00968826375901699, 0.023720787838101387, 0.025617338716983795, 0.02828286960721016, 0.01952311024069786, 0.015187123790383339, 0.02461577206850052, 0.018855810165405273, 0.013071926310658455, 0.025697465986013412, 0.010639775544404984, 0.007336440961807966, 0.02848825231194496, 0.04087510332465172, 0.023693934082984924, 0.02846081182360649, 0.031781155616045, 0.03399213030934334, 0.016904516145586967, 0.046997517347335815, 0.05480922386050224, 0.0604817159473896, 0.021137842908501625, 0.051477689296007156, 0.015304354950785637, 0.07868867367506027, 0.037551939487457275, 0.0, 0.0], [0.16510620713233948, 0.013307318091392517, 0.022820336744189262, 0.03222496807575226, 0.028327802196145058, 0.011912119574844837, 0.02175913006067276, 0.012591320089995861, 0.025371339172124863, 0.015923479571938515, 0.011745060794055462, 0.02134014293551445, 0.022658511996269226, 0.012096996419131756, 0.05877390876412392, 0.041142962872982025, 0.012866131961345673, 0.021896706894040108, 0.027385758236050606, 0.015412723645567894, 0.014822256751358509, 0.013198774307966232, 0.029060114175081253, 0.04031305015087128, 0.023036934435367584, 0.050357915461063385, 0.04650068283081055, 0.03221072256565094, 0.04574136435985565, 0.011448172852396965, 0.05148480832576752, 0.047162242233753204, 0.0], [0.01986273191869259, 0.0006941384053789079, 0.0017670633969828486, 0.0019038212485611439, 0.0023115770891308784, 0.05924387276172638, 0.005164950620383024, 0.008714546449482441, 0.0024906685575842857, 0.0030579573940485716, 0.07585158944129944, 0.002390549285337329, 0.0031773503869771957, 0.08945121616125107, 0.003065293189138174, 0.0016209169989451766, 0.10312031954526901, 0.0625915452837944, 0.002058297861367464, 0.002232219558209181, 0.12742049992084503, 0.02470383793115616, 0.0035101906396448612, 0.004994175862520933, 0.028317134827375412, 0.005874201189726591, 0.006215328350663185, 0.03686564415693283, 0.005438121035695076, 0.004061868414282799, 0.004735523369163275, 0.004534380976110697, 0.2925584614276886]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9726406335830688, 0.027359364554286003, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8850566744804382, 0.08160645514726639, 0.033336855471134186, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7844979166984558, 0.09045999497175217, 0.10720972716808319, 0.01783234439790249, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6679065227508545, 0.10135097056627274, 0.10997920483350754, 0.0699087604880333, 0.050854478031396866, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.586279034614563, 0.06960929185152054, 0.06798022985458374, 0.06058962643146515, 0.08339764177799225, 0.13214409351348877, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5015710592269897, 0.06227874383330345, 0.07209988683462143, 0.05590919405221939, 0.08146880567073822, 0.12033168226480484, 0.10634062439203262, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.40016087889671326, 0.05525398254394531, 0.06347682327032089, 0.05413786694407463, 0.07119616121053696, 0.11230531334877014, 0.12489721924066544, 0.11857164651155472, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4018533229827881, 0.08579417318105698, 0.0564488023519516, 0.07181120663881302, 0.08318910747766495, 0.07845646888017654, 0.09191881865262985, 0.07768876105546951, 0.05283927172422409, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3827158808708191, 0.07976948469877243, 0.06207753345370293, 0.06360235810279846, 0.08211023360490799, 0.07804957032203674, 0.08597435802221298, 0.07506486773490906, 0.0632784515619278, 0.02735722064971924, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3404167592525482, 0.04535197094082832, 0.04658910632133484, 0.0403917022049427, 0.05489042401313782, 0.08179009705781937, 0.08906517177820206, 0.09645897150039673, 0.055649708956480026, 0.06398677080869675, 0.08540939539670944, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.31186190247535706, 0.09539998322725296, 0.07292014360427856, 0.0697687417268753, 0.07777827233076096, 0.06735039502382278, 0.06161405146121979, 0.05481073260307312, 0.05252012982964516, 0.050225209444761276, 0.07299349457025528, 0.012756961397826672, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.36652857065200806, 0.06308672577142715, 0.03947845846414566, 0.046095266938209534, 0.05740753933787346, 0.0634833499789238, 0.0523846372961998, 0.055016182363033295, 0.04584016278386116, 0.06228693574666977, 0.0658990666270256, 0.058063607662916183, 0.024429509416222572, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.28564441204071045, 0.03804026544094086, 0.03942390903830528, 0.03423862159252167, 0.0463939867913723, 0.06771664321422577, 0.07328074425458908, 0.07855431735515594, 0.047896649688482285, 0.055936530232429504, 0.07124947011470795, 0.035689253360033035, 0.04956043139100075, 0.07637479156255722, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.297754168510437, 0.05259549245238304, 0.043479401618242264, 0.058458637446165085, 0.04568730294704437, 0.05259407311677933, 0.04456199333071709, 0.04597471281886101, 0.06316149234771729, 0.0776875764131546, 0.054991476237773895, 0.03466471657156944, 0.050201017409563065, 0.058861423283815384, 0.019326545298099518, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.28853148221969604, 0.04616912454366684, 0.02823306806385517, 0.03824238479137421, 0.043306220322847366, 0.05174916610121727, 0.043182745575904846, 0.043931204825639725, 0.05616341531276703, 0.06773821264505386, 0.054901763796806335, 0.08139307051897049, 0.043256908655166626, 0.0590481273829937, 0.039899032562971115, 0.014254073612391949, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.23721370100975037, 0.031615812331438065, 0.03324565663933754, 0.02923194132745266, 0.03861811012029648, 0.05549168959259987, 0.05966496095061302, 0.06321781873703003, 0.04073698818683624, 0.04752674698829651, 0.05837821215391159, 0.03039967082440853, 0.042871564626693726, 0.06284616887569427, 0.05321290343999863, 0.047368984669446945, 0.06835904717445374, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2098696231842041, 0.027291256934404373, 0.031156612560153008, 0.02661500871181488, 0.03165113553404808, 0.05273226276040077, 0.052745018154382706, 0.05635901913046837, 0.04076547175645828, 0.04278237000107765, 0.05619123950600624, 0.03067827597260475, 0.04398961365222931, 0.060914747416973114, 0.05013696476817131, 0.041573163121938705, 0.06652864068746567, 0.07801955193281174, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2385382205247879, 0.04414580017328262, 0.046435046941041946, 0.0345127135515213, 0.0357217900454998, 0.04369329288601875, 0.04304974526166916, 0.03498825058341026, 0.043718066066503525, 0.0395219624042511, 0.04457852616906166, 0.024599449709057808, 0.0625118538737297, 0.04753482714295387, 0.04375607892870903, 0.04995930194854736, 0.05090808868408203, 0.052662443369627, 0.019164469093084335, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.17729146778583527, 0.04221459850668907, 0.030818725004792213, 0.030886096879839897, 0.033868491649627686, 0.04521186649799347, 0.04290102794766426, 0.032215580344200134, 0.04018864780664444, 0.04926895722746849, 0.04801623895764351, 0.03814243897795677, 0.05126515030860901, 0.05206843465566635, 0.04744115099310875, 0.03924533724784851, 0.056304771453142166, 0.05462943762540817, 0.0599185973405838, 0.0281029362231493, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.19048279523849487, 0.025203483179211617, 0.026787465438246727, 0.0236726813018322, 0.031104033812880516, 0.043453436344861984, 0.0464932955801487, 0.048206474632024765, 0.03323278948664665, 0.03892752155661583, 0.04549148678779602, 0.024442734196782112, 0.03570156916975975, 0.04907766729593277, 0.04303564876317978, 0.03905566409230232, 0.0537174716591835, 0.06658957898616791, 0.04320825636386871, 0.03176470473408699, 0.060351260006427765, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.149753600358963, 0.023474574089050293, 0.025508403778076172, 0.028942447155714035, 0.03517158702015877, 0.03880191221833229, 0.04594281315803528, 0.039627280086278915, 0.03708779439330101, 0.03872300311923027, 0.04190719500184059, 0.021688062697649002, 0.043282538652420044, 0.04592541232705116, 0.038939524441957474, 0.04007610306143761, 0.05060022324323654, 0.06083051860332489, 0.043721601366996765, 0.030235223472118378, 0.057286132127046585, 0.062474023550748825, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1751341074705124, 0.027519280090928078, 0.029514014720916748, 0.02071533165872097, 0.026873521506786346, 0.0345461368560791, 0.03853078559041023, 0.03303780406713486, 0.04181556776165962, 0.04010029137134552, 0.036968957632780075, 0.030468938872218132, 0.03995394706726074, 0.04023703187704086, 0.04482618719339371, 0.037082623690366745, 0.04420147091150284, 0.04931039363145828, 0.04125744104385376, 0.02861068584024906, 0.04997345060110092, 0.05269284546375275, 0.03662917762994766, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.13285991549491882, 0.040708061307668686, 0.04111679270863533, 0.03484426438808441, 0.040876053273677826, 0.027567217126488686, 0.02829369343817234, 0.02252042107284069, 0.0387541837990284, 0.040378037840127945, 0.029089415445923805, 0.029609227553009987, 0.0567011684179306, 0.03118186444044113, 0.03766117990016937, 0.05688638612627983, 0.033967096358537674, 0.037813056260347366, 0.04951411858201027, 0.03194558620452881, 0.037599027156829834, 0.04326637089252472, 0.043056681752204895, 0.033790234476327896, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.14709368348121643, 0.01821870543062687, 0.022143617272377014, 0.02162139117717743, 0.02707289531826973, 0.03385418653488159, 0.03787611424922943, 0.03801964968442917, 0.027932509779930115, 0.03090183436870575, 0.03606923669576645, 0.01902313157916069, 0.03465800732374191, 0.03916986286640167, 0.0337555855512619, 0.026136629283428192, 0.04297832027077675, 0.05313743278384209, 0.03463505208492279, 0.02014029212296009, 0.048783596605062485, 0.04990804195404053, 0.04624391719698906, 0.04715670645236969, 0.06346961855888367, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1760278195142746, 0.01488215196877718, 0.026751169934868813, 0.024088064208626747, 0.035667479038238525, 0.027094287797808647, 0.02498425543308258, 0.02147187665104866, 0.026359377428889275, 0.023845115676522255, 0.027566982433199883, 0.01686953380703926, 0.0777742937207222, 0.029109211638569832, 0.04799698293209076, 0.02900250256061554, 0.03132336959242821, 0.036156002432107925, 0.039595603942871094, 0.017008014023303986, 0.034839075058698654, 0.03443719446659088, 0.04149218648672104, 0.09124380350112915, 0.040522992610931396, 0.0038906026165932417, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1850174367427826, 0.027787018567323685, 0.025097636505961418, 0.027018995955586433, 0.029199201613664627, 0.030337009578943253, 0.03222177177667618, 0.023015066981315613, 0.026792852208018303, 0.02279384806752205, 0.030674846842885017, 0.021220846101641655, 0.05388807877898216, 0.03259299695491791, 0.030737636610865593, 0.025725241750478745, 0.03486606478691101, 0.03793582320213318, 0.02867201343178749, 0.026148969307541847, 0.03875334933400154, 0.04179506376385689, 0.038631562143564224, 0.05337154492735863, 0.03982071951031685, 0.025711610913276672, 0.010172730311751366, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.12446325272321701, 0.01676889881491661, 0.020105110481381416, 0.01926702819764614, 0.024457814171910286, 0.030203377828001976, 0.03127393499016762, 0.03254607319831848, 0.023186009377241135, 0.023508403450250626, 0.031733207404613495, 0.01708051934838295, 0.029082054272294044, 0.034282173961400986, 0.03579127788543701, 0.02582056261599064, 0.03753119334578514, 0.046182505786418915, 0.02950001135468483, 0.017913807183504105, 0.04274732246994972, 0.042434703558683395, 0.03900240734219551, 0.04141837731003761, 0.05949503183364868, 0.03595735505223274, 0.03098488040268421, 0.05726282671093941, 0.0, 0.0, 0.0, 0.0, 0.0], [0.14491021633148193, 0.025843990966677666, 0.031176971271634102, 0.01946275867521763, 0.012575722299516201, 0.025274597108364105, 0.022020693868398666, 0.021267279982566833, 0.03165539726614952, 0.02766416408121586, 0.026251569390296936, 0.02209104411303997, 0.03851794824004173, 0.02826688252389431, 0.028877615928649902, 0.03686537221074104, 0.03069998323917389, 0.03204502537846565, 0.034116268157958984, 0.02035541459918022, 0.03446313366293907, 0.035428643226623535, 0.0307284165173769, 0.04441893845796585, 0.03793597221374512, 0.05734866484999657, 0.038896992802619934, 0.04111205041408539, 0.019728200510144234, 0.0, 0.0, 0.0, 0.0], [0.13168424367904663, 0.025460107252001762, 0.02796240895986557, 0.02410985343158245, 0.016868816688656807, 0.031406790018081665, 0.023247338831424713, 0.02207168936729431, 0.027362510561943054, 0.026370452716946602, 0.032045334577560425, 0.028775813058018684, 0.04614203795790672, 0.03455977886915207, 0.03132109344005585, 0.029437730088829994, 0.037490714341402054, 0.03597421571612358, 0.0306710172444582, 0.026778321713209152, 0.041662365198135376, 0.03274398297071457, 0.03034878335893154, 0.032651983201503754, 0.03805651143193245, 0.03457561507821083, 0.022936128079891205, 0.03690327703952789, 0.02596619725227356, 0.014414895325899124, 0.0, 0.0, 0.0], [0.1656370908021927, 0.022809259593486786, 0.029107755050063133, 0.024944666773080826, 0.024352874606847763, 0.02503182925283909, 0.018486665561795235, 0.01857367716729641, 0.02844363823533058, 0.029199937358498573, 0.025318214669823647, 0.032204993069171906, 0.025753289461135864, 0.026890527456998825, 0.031273938715457916, 0.033051498234272, 0.028835462406277657, 0.029910407960414886, 0.0275588259100914, 0.024624643847346306, 0.0320536270737648, 0.02649376355111599, 0.02170960046350956, 0.03164014592766762, 0.037074774503707886, 0.047994695603847504, 0.02793216146528721, 0.034756116569042206, 0.03804944455623627, 0.02153567411005497, 0.008750852197408676, 0.0, 0.0], [0.16794216632843018, 0.025983473286032677, 0.03222338855266571, 0.019469382241368294, 0.023735279217362404, 0.02311573550105095, 0.019973622635006905, 0.016550227999687195, 0.029796769842505455, 0.028494669124484062, 0.023108839988708496, 0.022087078541517258, 0.04216555878520012, 0.02439018525183201, 0.020749138668179512, 0.03873587027192116, 0.026269815862178802, 0.027289101853966713, 0.019617386162281036, 0.020242854952812195, 0.02920321188867092, 0.03041336126625538, 0.025762619450688362, 0.04084981977939606, 0.0333266407251358, 0.021795298904180527, 0.026310525834560394, 0.031013479456305504, 0.036892641335725784, 0.019377153366804123, 0.043556053191423416, 0.009558658115565777, 0.0], [0.11396830528974533, 0.0177528765052557, 0.016061954200267792, 0.015585054643452168, 0.01839611493051052, 0.024367086589336395, 0.02605387382209301, 0.023999115452170372, 0.021919485181570053, 0.026251107454299927, 0.02473052777349949, 0.01532302051782608, 0.02561456896364689, 0.02633788250386715, 0.024982865899801254, 0.02464262954890728, 0.028590327128767967, 0.03295150399208069, 0.027568617835640907, 0.01848755218088627, 0.03220851719379425, 0.031914688646793365, 0.03630725294351578, 0.0341540202498436, 0.03678558021783829, 0.03297772631049156, 0.0262789037078619, 0.03809890151023865, 0.029801947996020317, 0.018183253705501556, 0.03632067143917084, 0.03568094223737717, 0.057703081518411636]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8058414459228516, 0.19415852427482605, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6373864412307739, 0.09672049432992935, 0.2658930718898773, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5870265364646912, 0.09922721982002258, 0.07913831621408463, 0.23460792005062103, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.41947367787361145, 0.06312593072652817, 0.08123064786195755, 0.08381500095129013, 0.35235461592674255, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5308531522750854, 0.0959072858095169, 0.07779338955879211, 0.06661548465490341, 0.07293295115232468, 0.15589767694473267, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.38503068685531616, 0.07478093355894089, 0.06978149712085724, 0.047606535255908966, 0.05144915729761124, 0.08776706457138062, 0.2835841476917267, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.29629573225975037, 0.05328269675374031, 0.06944749504327774, 0.04097547382116318, 0.06660830974578857, 0.1021856889128685, 0.10869501531124115, 0.26250961422920227, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3047499358654022, 0.06337985396385193, 0.05753423273563385, 0.040577180683612823, 0.0730014219880104, 0.07375828176736832, 0.07239887863397598, 0.05693604424595833, 0.25766411423683167, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.29880762100219727, 0.05552824214100838, 0.05443597212433815, 0.052853021770715714, 0.06568750739097595, 0.07554222643375397, 0.06968101859092712, 0.054113876074552536, 0.09120789915323257, 0.18214258551597595, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.26933014392852783, 0.06352430582046509, 0.05952122062444687, 0.05242469534277916, 0.06052156537771225, 0.12185831367969513, 0.07608654350042343, 0.09753072261810303, 0.04232606664299965, 0.05058327317237854, 0.10629311203956604, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.22074297070503235, 0.06960076093673706, 0.04872347041964531, 0.06675717234611511, 0.06954210251569748, 0.06483785808086395, 0.046523742377758026, 0.0393008291721344, 0.018016092479228973, 0.0358063168823719, 0.05302286893129349, 0.26712578535079956, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.15080073475837708, 0.04732475429773331, 0.12551115453243256, 0.06240082159638405, 0.05354631692171097, 0.05578393489122391, 0.04542611539363861, 0.03888600692152977, 0.0301998108625412, 0.03337055444717407, 0.04645953327417374, 0.023437919095158577, 0.2868523597717285, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.20448839664459229, 0.04972050338983536, 0.04838547483086586, 0.04385358467698097, 0.05115717276930809, 0.1007489338517189, 0.06420683860778809, 0.08302562683820724, 0.03880453109741211, 0.047957733273506165, 0.09582383185625076, 0.03239700570702553, 0.04441104084253311, 0.0950193703174591, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1623673290014267, 0.028519177809357643, 0.0478430911898613, 0.04135480895638466, 0.040284886956214905, 0.0520053505897522, 0.04226504638791084, 0.038211699575185776, 0.05986882373690605, 0.06849398463964462, 0.04734278842806816, 0.019715161994099617, 0.062022291123867035, 0.04572192206978798, 0.24398359656333923, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1312893182039261, 0.039628103375434875, 0.05951940640807152, 0.039663225412368774, 0.04406354948878288, 0.04348496347665787, 0.03726547583937645, 0.03240034729242325, 0.037205733358860016, 0.06481601297855377, 0.04047452658414841, 0.025914229452610016, 0.06507597863674164, 0.039225105196237564, 0.07744196057319641, 0.2225320190191269, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.15813341736793518, 0.03911251947283745, 0.038564957678318024, 0.03587968647480011, 0.04187794029712677, 0.08161001652479172, 0.05245806276798248, 0.0681268647313118, 0.034448061138391495, 0.04342750832438469, 0.08275996893644333, 0.02933339960873127, 0.041573792695999146, 0.08478685468435287, 0.04881598427891731, 0.03235284984111786, 0.08673813194036484, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.13890595734119415, 0.03169632330536842, 0.03251556307077408, 0.03538898006081581, 0.038000330328941345, 0.06974425166845322, 0.05942453816533089, 0.06768239289522171, 0.027843810617923737, 0.039054665714502335, 0.07273104041814804, 0.030109865590929985, 0.04163092002272606, 0.07565010339021683, 0.040188319981098175, 0.027483616024255753, 0.0779590755701065, 0.09399021416902542, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.09691289812326431, 0.03068731538951397, 0.030817963182926178, 0.044734321534633636, 0.04171942546963692, 0.036036767065525055, 0.04101703315973282, 0.03210476413369179, 0.04344062879681587, 0.04885552451014519, 0.03457901254296303, 0.016025086864829063, 0.04994165152311325, 0.0346352644264698, 0.06065686047077179, 0.03497787564992905, 0.034543417394161224, 0.03782792389392853, 0.25048622488975525, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1205921620130539, 0.04121065512299538, 0.050985172390937805, 0.05289151892066002, 0.02886129543185234, 0.04706199839711189, 0.02921283058822155, 0.038170017302036285, 0.021046487614512444, 0.029787803068757057, 0.04406721517443657, 0.02650333382189274, 0.04127003252506256, 0.04430735856294632, 0.030801555141806602, 0.04064902663230896, 0.044745106250047684, 0.042122457176446915, 0.028442280367016792, 0.1972716897726059, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.11388304829597473, 0.0282554030418396, 0.02835129387676716, 0.026958664879202843, 0.03131084889173508, 0.05977548286318779, 0.039182148873806, 0.050720397382974625, 0.027684014290571213, 0.035564225167036057, 0.06452134251594543, 0.024267088621854782, 0.03616495430469513, 0.06838167458772659, 0.04139300435781479, 0.0290946364402771, 0.0723005011677742, 0.07349380850791931, 0.03700020909309387, 0.0352863185107708, 0.07641094923019409, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.08453850448131561, 0.017416607588529587, 0.01894913986325264, 0.0165606327354908, 0.0222961213439703, 0.04174061119556427, 0.05894864723086357, 0.03893361985683441, 0.030214646831154823, 0.03464233875274658, 0.0483190156519413, 0.016358420252799988, 0.025674551725387573, 0.05309673771262169, 0.02054651640355587, 0.02046983502805233, 0.05704639479517937, 0.06604909896850586, 0.03774644806981087, 0.021413875743746758, 0.06129929795861244, 0.2077389359474182, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1124843955039978, 0.024394847452640533, 0.024523155763745308, 0.027489561587572098, 0.026104668155312538, 0.03731505200266838, 0.06748531758785248, 0.03890375792980194, 0.01798143796622753, 0.028454385697841644, 0.03756532073020935, 0.01832606829702854, 0.02008865587413311, 0.03865170478820801, 0.0232856422662735, 0.02422662265598774, 0.03960612043738365, 0.04833187907934189, 0.04500093683600426, 0.01736215315759182, 0.04009140655398369, 0.05208287015557289, 0.19024400413036346, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.08183355629444122, 0.019828451797366142, 0.02687338925898075, 0.0292525552213192, 0.02518443576991558, 0.03192772716283798, 0.029049789533019066, 0.024972517043352127, 0.03350625932216644, 0.040074288845062256, 0.03351731225848198, 0.01603599637746811, 0.03204454481601715, 0.034480638802051544, 0.028517089784145355, 0.03532731160521507, 0.03583228215575218, 0.040583960711956024, 0.029941102489829063, 0.02109791338443756, 0.03671329468488693, 0.039212584495544434, 0.03543241694569588, 0.2387605905532837, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.10145692527294159, 0.014237052761018276, 0.016984181478619576, 0.01863657310605049, 0.028536241501569748, 0.0365380235016346, 0.02957051433622837, 0.04198319464921951, 0.01416604220867157, 0.030081400647759438, 0.04016641527414322, 0.02007501944899559, 0.030370108783245087, 0.04353439435362816, 0.03039301373064518, 0.020717332139611244, 0.04677111282944679, 0.0549510233104229, 0.02880917116999626, 0.020043686032295227, 0.050925422459840775, 0.04084467142820358, 0.041858017444610596, 0.03848976641893387, 0.15986065566539764, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.07937923818826675, 0.020674321800470352, 0.020799752324819565, 0.027988232672214508, 0.04565475508570671, 0.02656259387731552, 0.02539670839905739, 0.021243257448077202, 0.01776379533112049, 0.02520064264535904, 0.027576463297009468, 0.030607089400291443, 0.034379992634058, 0.028568314388394356, 0.022726934403181076, 0.01605195552110672, 0.029712749645113945, 0.03276180848479271, 0.025702400133013725, 0.012878884561359882, 0.03062613308429718, 0.02036965638399124, 0.03741392120718956, 0.027850378304719925, 0.03571850806474686, 0.27639153599739075, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.09605433791875839, 0.02309289388358593, 0.024199655279517174, 0.024974146857857704, 0.0368296355009079, 0.030014395713806152, 0.021069224923849106, 0.018117524683475494, 0.022569265216588974, 0.02834322303533554, 0.030505135655403137, 0.021707672625780106, 0.02821178548038006, 0.03163941577076912, 0.03916611894965172, 0.03627365827560425, 0.03311571851372719, 0.03514396771788597, 0.02574523538351059, 0.015889013186097145, 0.034675467759370804, 0.026770086959004402, 0.0271434523165226, 0.040450796484947205, 0.03760385140776634, 0.03232335299253464, 0.17837098240852356, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.07476937770843506, 0.011021516285836697, 0.010706556960940361, 0.015325456857681274, 0.019903559237718582, 0.03285866230726242, 0.021936070173978806, 0.029454145580530167, 0.01642150804400444, 0.022476576268672943, 0.037223443388938904, 0.01758023165166378, 0.021954143419861794, 0.040462128818035126, 0.031415410339832306, 0.010417775250971317, 0.044297389686107635, 0.05118126422166824, 0.029565557837486267, 0.015394330024719238, 0.04906425625085831, 0.03202195465564728, 0.030905118212103844, 0.041320525109767914, 0.06578274071216583, 0.03978404775261879, 0.020499706268310547, 0.16625654697418213, 0.0, 0.0, 0.0, 0.0, 0.0], [0.05124205723404884, 0.011390028521418571, 0.02026580646634102, 0.02452964149415493, 0.12732438743114471, 0.020083913579583168, 0.017692744731903076, 0.02038198709487915, 0.018548615276813507, 0.023206060752272606, 0.021026061847805977, 0.02052123285830021, 0.025210734456777573, 0.021994242444634438, 0.0171904768794775, 0.02080591395497322, 0.023035308346152306, 0.026458054780960083, 0.031086130067706108, 0.011454466730356216, 0.024357995018363, 0.02252494916319847, 0.024600783362984657, 0.024588001891970634, 0.02838081493973732, 0.04660612717270851, 0.04362708330154419, 0.020300468429923058, 0.21156589686870575, 0.0, 0.0, 0.0, 0.0], [0.07929294556379318, 0.023537393659353256, 0.022847291082143784, 0.01993604376912117, 0.015462877228856087, 0.025110285729169846, 0.02142905257642269, 0.015073497779667377, 0.009924096055328846, 0.015724746510386467, 0.027188710868358612, 0.020747290924191475, 0.034976355731487274, 0.029102321714162827, 0.021219035610556602, 0.01814761944115162, 0.03105819784104824, 0.03380950540304184, 0.020137567073106766, 0.01232312060892582, 0.033692631870508194, 0.024336133152246475, 0.031084517017006874, 0.03377701714634895, 0.04355444759130478, 0.03296353295445442, 0.03314929082989693, 0.02536490373313427, 0.022163690999150276, 0.22286593914031982, 0.0, 0.0, 0.0], [0.10059654712677002, 0.03096376545727253, 0.02557850442826748, 0.020224064588546753, 0.02713298611342907, 0.0294907595962286, 0.0407448336482048, 0.021403620019555092, 0.016392603516578674, 0.022520696744322777, 0.027555175125598907, 0.013599209487438202, 0.027306703850626945, 0.027806580066680908, 0.011214178055524826, 0.023586543276906013, 0.02839917317032814, 0.030668914318084717, 0.021664202213287354, 0.017032310366630554, 0.029051590710878372, 0.026549920439720154, 0.03297552838921547, 0.0267903171479702, 0.0320606529712677, 0.027298327535390854, 0.017307180911302567, 0.018768813461065292, 0.028226522728800774, 0.017085105180740356, 0.18000465631484985, 0.0, 0.0], [0.08361605554819107, 0.01658189669251442, 0.015823300927877426, 0.02200516313314438, 0.02406255528330803, 0.021028298884630203, 0.022811297327280045, 0.014412392862141132, 0.015572086907923222, 0.015104828402400017, 0.0209177378565073, 0.021798154339194298, 0.02598598599433899, 0.022013207897543907, 0.02202506735920906, 0.018091220408678055, 0.023115109652280807, 0.025451797991991043, 0.025943519547581673, 0.01124188769608736, 0.024466171860694885, 0.022869890555739403, 0.03161345422267914, 0.029542669653892517, 0.02381790801882744, 0.02934901788830757, 0.02592264488339424, 0.01726817525923252, 0.0318446084856987, 0.01203772984445095, 0.027524927631020546, 0.2561412751674652, 0.0], [0.05258440971374512, 0.012508383020758629, 0.012737675569951534, 0.012144196778535843, 0.01446781400591135, 0.024812446907162666, 0.01710914634168148, 0.02516256831586361, 0.016298966482281685, 0.015160075388848782, 0.029820041730999947, 0.014290275052189827, 0.024094795808196068, 0.033742763102054596, 0.021632250398397446, 0.018924105912446976, 0.03819216787815094, 0.04115181416273117, 0.024165764451026917, 0.020635634660720825, 0.044185321778059006, 0.03793709725141525, 0.02963634766638279, 0.03152839466929436, 0.045423075556755066, 0.035963598638772964, 0.03048253245651722, 0.04609915241599083, 0.03206764906644821, 0.01766294240951538, 0.03169601783156395, 0.04462909698486328, 0.10305341333150864]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7707713842391968, 0.22922860085964203, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7813624739646912, 0.10978527367115021, 0.10885230451822281, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5350390076637268, 0.11194944381713867, 0.15013688802719116, 0.20287467539310455, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4180358350276947, 0.1603638082742691, 0.1074029803276062, 0.10625782608985901, 0.20793955028057098, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4349866509437561, 0.09579858183860779, 0.08251801878213882, 0.10028502345085144, 0.15332907438278198, 0.13308262825012207, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.44621357321739197, 0.05624214559793472, 0.05040299892425537, 0.07084295898675919, 0.09360909461975098, 0.11472620069980621, 0.16796308755874634, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3609195649623871, 0.07294466346502304, 0.05191003903746605, 0.07159043103456497, 0.09321669489145279, 0.09543666243553162, 0.14539919793605804, 0.10858277231454849, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.31714069843292236, 0.07683128118515015, 0.0555228516459465, 0.06445365399122238, 0.08586591482162476, 0.10643253475427628, 0.1452113389968872, 0.09439335763454437, 0.05414832755923271, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.19288603961467743, 0.11343871057033539, 0.04530505836009979, 0.08361202478408813, 0.057632725685834885, 0.11914194375276566, 0.11441227793693542, 0.12364514172077179, 0.07640956342220306, 0.07351640611886978, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2517409026622772, 0.060194116085767746, 0.049302101135253906, 0.059223245829343796, 0.08453334122896194, 0.07307681441307068, 0.12308556586503983, 0.08293969929218292, 0.06380274146795273, 0.07185835391283035, 0.08024312555789948, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.24793599545955658, 0.04855773597955704, 0.06171697378158569, 0.06616784632205963, 0.08788599073886871, 0.05920384079217911, 0.09128586947917938, 0.06866814196109772, 0.06062866002321243, 0.08399351686239243, 0.0656941831111908, 0.058261170983314514, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.15039603412151337, 0.07072300463914871, 0.03618801385164261, 0.03812884911894798, 0.05496574938297272, 0.09552795439958572, 0.1278020143508911, 0.09101752936840057, 0.04133947193622589, 0.06619426608085632, 0.11493085324764252, 0.035268161445856094, 0.0775180533528328, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.21730753779411316, 0.0522487573325634, 0.042796872556209564, 0.051309872418642044, 0.07021072506904602, 0.06084863841533661, 0.10094169527292252, 0.06729137897491455, 0.05347270518541336, 0.058032404631376266, 0.0638660117983818, 0.04143684357404709, 0.054298121482133865, 0.06593843549489975, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.14158987998962402, 0.08735614269971848, 0.0410962849855423, 0.07771317660808563, 0.0664159506559372, 0.06084612384438515, 0.07890868932008743, 0.06467185169458389, 0.04156753420829773, 0.05314024165272713, 0.060331955552101135, 0.04990346357226372, 0.06147689372301102, 0.06152055412530899, 0.05346132814884186, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.11277391016483307, 0.05140271037817001, 0.034800730645656586, 0.044109925627708435, 0.049271054565906525, 0.08066022396087646, 0.09371130168437958, 0.07634278386831284, 0.03460073098540306, 0.0555650070309639, 0.09000371396541595, 0.02795092575252056, 0.05808689072728157, 0.09759876132011414, 0.0585305392742157, 0.03459078073501587, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.19136787950992584, 0.04588799923658371, 0.03718419000506401, 0.04478846862912178, 0.05845541134476662, 0.0516231395304203, 0.0845179632306099, 0.05661728233098984, 0.04477923363447189, 0.04681585729122162, 0.05177522078156471, 0.034743111580610275, 0.04365590587258339, 0.05257751792669296, 0.04571911692619324, 0.05523938313126564, 0.05425223708152771, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.178098663687706, 0.03651316463947296, 0.03537802770733833, 0.046600591391325, 0.05606748163700104, 0.05542531609535217, 0.06580902636051178, 0.058695923537015915, 0.04460207000374794, 0.03845333680510521, 0.05522071197628975, 0.02812928520143032, 0.038876280188560486, 0.056352097541093826, 0.04307202994823456, 0.048592109233140945, 0.058013033121824265, 0.05610083043575287, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.11277125775814056, 0.04416341707110405, 0.01679084822535515, 0.03922898322343826, 0.03057022951543331, 0.08429380506277084, 0.05829832702875137, 0.07985574752092361, 0.027740230783820152, 0.024607937783002853, 0.0856802687048912, 0.012135536409914494, 0.02122361958026886, 0.08979953080415726, 0.02439562976360321, 0.018000084906816483, 0.0979786291718483, 0.08564858883619308, 0.04681730270385742, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.15648673474788666, 0.04359337314963341, 0.02946913056075573, 0.02338278479874134, 0.03989393636584282, 0.06601447612047195, 0.07239894568920135, 0.04959877207875252, 0.025720082223415375, 0.028729893267154694, 0.07268748432397842, 0.02010437846183777, 0.038949936628341675, 0.07793489098548889, 0.03185016289353371, 0.029572607949376106, 0.08162925392389297, 0.04983028024435043, 0.04757082834839821, 0.01458202674984932, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.16675153374671936, 0.04021674394607544, 0.031946271657943726, 0.039155539125204086, 0.048679765313863754, 0.04351935535669327, 0.07027734816074371, 0.04676977917551994, 0.03737044334411621, 0.037859514355659485, 0.04185349866747856, 0.029438789933919907, 0.03496701270341873, 0.04187152534723282, 0.03665958717465401, 0.04418949782848358, 0.04244701564311981, 0.043089985847473145, 0.05540825054049492, 0.02402997948229313, 0.04349850118160248, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.21311703324317932, 0.03452147915959358, 0.026512032374739647, 0.03728466108441353, 0.042002297937870026, 0.05378074571490288, 0.06410719454288483, 0.040195900946855545, 0.029513953253626823, 0.03056207112967968, 0.0481405146420002, 0.019645733758807182, 0.023855971172451973, 0.04712357744574547, 0.027805231511592865, 0.025632821023464203, 0.04690323397517204, 0.04211500659584999, 0.042453378438949585, 0.016209973022341728, 0.04720157012343407, 0.041315577924251556, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.16099102795124054, 0.031492117792367935, 0.02550600655376911, 0.032036274671554565, 0.0381193682551384, 0.05386465787887573, 0.052892010658979416, 0.06297369301319122, 0.03872942924499512, 0.03070301003754139, 0.04861500859260559, 0.01696414314210415, 0.020984873175621033, 0.04743489250540733, 0.02617855742573738, 0.03281703218817711, 0.04874102398753166, 0.03702305257320404, 0.05028446763753891, 0.014425937086343765, 0.04926920682191849, 0.027485143393278122, 0.05246910825371742, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.13924191892147064, 0.04732196778059006, 0.022920068353414536, 0.037826746702194214, 0.037331610918045044, 0.05628196895122528, 0.06773106753826141, 0.0638374537229538, 0.028824567794799805, 0.028368612751364708, 0.05008407309651375, 0.014775184914469719, 0.021058905869722366, 0.04819710925221443, 0.017685124650597572, 0.01545622292906046, 0.0484280027449131, 0.037099532783031464, 0.042473260313272476, 0.01842682436108589, 0.0486132986843586, 0.022673960775136948, 0.05998953431844711, 0.02535295858979225, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.19562353193759918, 0.03233326971530914, 0.022874077782034874, 0.038390759378671646, 0.03449878469109535, 0.04616906866431236, 0.05553748831152916, 0.03960668295621872, 0.023098396137356758, 0.024249287322163582, 0.04043306037783623, 0.016078555956482887, 0.02162494696676731, 0.03903055936098099, 0.026520883664488792, 0.028113434091210365, 0.03823631629347801, 0.03542610630393028, 0.041745737195014954, 0.021097129210829735, 0.03767954185605049, 0.037286922335624695, 0.04423919692635536, 0.022921502590179443, 0.03718467056751251, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0581965297460556, 0.03889740630984306, 0.02600524201989174, 0.023567894473671913, 0.022979987785220146, 0.05384151265025139, 0.05806104838848114, 0.06858771294355392, 0.037459846585989, 0.02915908396244049, 0.05474673584103584, 0.013592952862381935, 0.027647050097584724, 0.05575402453541756, 0.030779866501688957, 0.01613735780119896, 0.057454273104667664, 0.03968728333711624, 0.03406553715467453, 0.013110977597534657, 0.05977656692266464, 0.016043761745095253, 0.029699290171265602, 0.020566539838910103, 0.08347289264202118, 0.030708597972989082, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.15561483800411224, 0.030323192477226257, 0.02106757089495659, 0.03860042244195938, 0.025089256465435028, 0.047195207327604294, 0.04255649819970131, 0.05166257917881012, 0.03036811575293541, 0.020133620128035545, 0.042556971311569214, 0.018511777743697166, 0.01867172308266163, 0.041430290788412094, 0.022022129967808723, 0.02106103114783764, 0.041666179895401, 0.02724921703338623, 0.040481600910425186, 0.015536422841250896, 0.04219622537493706, 0.01700735278427601, 0.06220947951078415, 0.01570316217839718, 0.054431866854429245, 0.04092409461736679, 0.01572924479842186, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1521887630224228, 0.03232048451900482, 0.026277612894773483, 0.03215136006474495, 0.0370805449783802, 0.03843335062265396, 0.04218520224094391, 0.03440920636057854, 0.029296189546585083, 0.024752246215939522, 0.03461231291294098, 0.021795082837343216, 0.023419683799147606, 0.03386644646525383, 0.028580598533153534, 0.034403275698423386, 0.033156976103782654, 0.026710400357842445, 0.04213564842939377, 0.019021345302462578, 0.032785814255476, 0.026840003207325935, 0.03304455801844597, 0.02330264076590538, 0.03390035778284073, 0.03944924846291542, 0.02133425511419773, 0.04254644364118576, 0.0, 0.0, 0.0, 0.0, 0.0], [0.10210394114255905, 0.048305340111255646, 0.027957914397120476, 0.02813485823571682, 0.04368895664811134, 0.037659596651792526, 0.040121812373399734, 0.03589581325650215, 0.02449178695678711, 0.019768046215176582, 0.03467410057783127, 0.015431460924446583, 0.032616544514894485, 0.034143395721912384, 0.027461368590593338, 0.020323213189840317, 0.03445841744542122, 0.015827566385269165, 0.03070583939552307, 0.020360935479402542, 0.035580456256866455, 0.034790292382240295, 0.035181473940610886, 0.028572602197527885, 0.04333385452628136, 0.03896390274167061, 0.017587698996067047, 0.04553377628326416, 0.04632510989904404, 0.0, 0.0, 0.0, 0.0], [0.1184174120426178, 0.02668977715075016, 0.02854764647781849, 0.03516455739736557, 0.03519093990325928, 0.03070487268269062, 0.04254688322544098, 0.023103507235646248, 0.025463124737143517, 0.029678549617528915, 0.028395220637321472, 0.019178256392478943, 0.023833584040403366, 0.027640020474791527, 0.03381752967834473, 0.0396401509642601, 0.027574418112635612, 0.021856164559721947, 0.039667654782533646, 0.03941833972930908, 0.02711562067270279, 0.030498068779706955, 0.03493283689022064, 0.032320536673069, 0.027840549126267433, 0.03877578675746918, 0.021124795079231262, 0.03861142694950104, 0.032771822065114975, 0.019479982554912567, 0.0, 0.0, 0.0], [0.05433791130781174, 0.019247831776738167, 0.011686460115015507, 0.014118611812591553, 0.013909781351685524, 0.057368066161870956, 0.0345463752746582, 0.04665057733654976, 0.013026449829339981, 0.01327129639685154, 0.05952776223421097, 0.009063145145773888, 0.017364194616675377, 0.06135564669966698, 0.012634647078812122, 0.015145539306104183, 0.06425533443689346, 0.04627061262726784, 0.01955636404454708, 0.012543459422886372, 0.06913556903600693, 0.03482367843389511, 0.03000594861805439, 0.012261824682354927, 0.07985591888427734, 0.018996426835656166, 0.010722927749156952, 0.08654540777206421, 0.017174093052744865, 0.02214416116476059, 0.022453974932432175, 0.0, 0.0], [0.058496441692113876, 0.03437737002968788, 0.013603095896542072, 0.02417043223977089, 0.01900586113333702, 0.0654640793800354, 0.03062295913696289, 0.03573205694556236, 0.01885944791138172, 0.012241481803357601, 0.0628219023346901, 0.011835749261081219, 0.009552359580993652, 0.06431794911623001, 0.021589579060673714, 0.010912971571087837, 0.0666591078042984, 0.02399745211005211, 0.026596758514642715, 0.006153556052595377, 0.06984329968690872, 0.03723869100213051, 0.030046697705984116, 0.021686820313334465, 0.043640609830617905, 0.021209614351391792, 0.013490457087755203, 0.04632722958922386, 0.020434508100152016, 0.013362257741391659, 0.018568990752100945, 0.04714024439454079, 0.0], [0.1352868676185608, 0.029733380302786827, 0.02611132338643074, 0.03753575682640076, 0.0388815812766552, 0.0331667959690094, 0.048243895173072815, 0.03046831116080284, 0.026038208976387978, 0.024123696610331535, 0.027892742305994034, 0.02270994521677494, 0.024185286834836006, 0.02611454948782921, 0.023209668695926666, 0.025175290182232857, 0.024614788591861725, 0.02112315408885479, 0.02968505024909973, 0.018167471513152122, 0.023064397275447845, 0.02059807814657688, 0.03441140055656433, 0.021083395928144455, 0.022538835182785988, 0.0322815477848053, 0.013987251557409763, 0.02414492331445217, 0.02700231224298477, 0.012929442338645458, 0.03616539016366005, 0.026840243488550186, 0.032485030591487885]]]}\n",
       "    )\n",
       "    </script>"
      ],
      "text/plain": [
       "<circuitsvis.utils.render.RenderedHTML at 0x7fa322c4fbd0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Layer 0 Head Attention Patterns:\")\n",
    "cv.attention.attention_patterns(tokens=gpt2_str_tokens, attention=attention_pattern)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hooks: Intervening on Activations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the great things about interpreting neural networks is that we have *full control* over our system. From a computational perspective, we know exactly what operations are going on inside (even if we don't know what they mean!). And we can make precise, surgical edits and see how the model's behaviour and other internals change. This is an extremely powerful tool, because it can let us eg set up careful counterfactuals and causal intervention to easily understand model behaviour. \n",
    "\n",
    "Accordingly, being able to do this is a pretty core operation, and this is one of the main things TransformerLens supports! The key feature here is **hook points**. Every activation inside the transformer is surrounded by a hook point, which allows us to edit or intervene on it. \n",
    "\n",
    "We do this by adding a **hook function** to that activation. The hook function maps `current_activation_value, hook_point` to `new_activation_value`. As the model is run, it computes that activation as normal, and then the hook function is applied to compute a replacement, and that is substituted in for the activation. The hook function can be an arbitrary Python function, so long as it returns a tensor of the correct shape.\n",
    "\n",
    "<details><summary>Relationship to PyTorch hooks</summary>\n",
    "\n",
    "[PyTorch hooks](https://blog.paperspace.com/pytorch-hooks-gradient-clipping-debugging/) are a great and underrated, yet incredibly janky, feature. They can act on a layer, and edit the input or output of that layer, or the gradient when applying autodiff. The key difference is that **Hook points** act on *activations* not layers. This means that you can intervene within a layer on each activation, and don't need to care about the precise layer structure of the transformer. And it's immediately clear exactly how the hook's effect is applied. This adjustment was shamelessly inspired by [Garcon's use of ProbePoints](https://transformer-circuits.pub/2021/garcon/index.html).\n",
    "\n",
    "They also come with a range of other quality of life improvements, like the model having a `model.reset_hooks()` method to remove all hooks, or helper methods to temporarily add hooks for a single forward pass - it is *incredibly* easy to shoot yourself in the foot with standard PyTorch hooks!\n",
    "</details>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a basic example, let's [ablate](https://dynalist.io/d/n2ZWtnoYHrU1s4vnFSAQ519J#z=fh-HJyz1CgUVrXuoiban6bYx) head 7 in layer 0 on the text above. \n",
    "\n",
    "We define a `head_ablation_hook` function. This takes the value tensor for attention layer 0, and sets the component with `head_index==7` to zero and returns it (Note - we return by convention, but since we're editing the activation in-place, we don't strictly *need* to).\n",
    "\n",
    "We then use the `run_with_hooks` helper function to run the model and *temporarily* add in the hook for just this run. We enter in the hook as a tuple of the activation name (also the hook point name - found with `utils.get_act_name`) and the hook function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-08T19:27:30.489340Z",
     "iopub.status.busy": "2023-11-08T19:27:30.488995Z",
     "iopub.status.idle": "2023-11-08T19:27:30.728713Z",
     "shell.execute_reply": "2023-11-08T19:27:30.728127Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the value tensor: torch.Size([1, 33, 12, 64])\n",
      "Original Loss: 3.999\n",
      "Ablated Loss: 5.453\n"
     ]
    }
   ],
   "source": [
    "layer_to_ablate = 0\n",
    "head_index_to_ablate = 8\n",
    "\n",
    "# We define a head ablation hook\n",
    "# The type annotations are NOT necessary, they're just a useful guide to the reader\n",
    "# \n",
    "def head_ablation_hook(\n",
    "    value: Float[torch.Tensor, \"batch pos head_index d_head\"],\n",
    "    hook: HookPoint\n",
    ") -> Float[torch.Tensor, \"batch pos head_index d_head\"]:\n",
    "    print(f\"Shape of the value tensor: {value.shape}\")\n",
    "    value[:, :, head_index_to_ablate, :] = 0.\n",
    "    return value\n",
    "\n",
    "original_loss = model(gpt2_tokens, return_type=\"loss\")\n",
    "ablated_loss = model.run_with_hooks(\n",
    "    gpt2_tokens, \n",
    "    return_type=\"loss\", \n",
    "    fwd_hooks=[(\n",
    "        utils.get_act_name(\"v\", layer_to_ablate), \n",
    "        head_ablation_hook\n",
    "        )]\n",
    "    )\n",
    "print(f\"Original Loss: {original_loss.item():.3f}\")\n",
    "print(f\"Ablated Loss: {ablated_loss.item():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gotcha:** Hooks are global state - they're added in as part of the model, and stay there until removed. `run_with_hooks` tries to create an abstraction where these are local state, by removing all hooks at the end of the function. But you can easily shoot yourself in the foot if there's, eg, an error in one of your hooks so the function never finishes. If you start getting bugs, try `model.reset_hooks()` to clean things up. Further, if you *do* add hooks of your own that you want to keep, which you can do with `add_perma_hook` on the relevant HookPoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation Patching on the Indirect Object Identification Task"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a somewhat more involved example, let's use hooks to apply **[activation patching](https://dynalist.io/d/n2ZWtnoYHrU1s4vnFSAQ519J#z=qeWBvs-R-taFfcCq-S_hgMqx)** on the **[Indirect Object Identification](https://dynalist.io/d/n2ZWtnoYHrU1s4vnFSAQ519J#z=iWsV3s5Kdd2ca3zNgXr5UPHa)** (IOI) task. \n",
    "\n",
    "The IOI task is the task of identifying that a sentence like \"After John and Mary went to the store, Mary gave a bottle of milk to\" continues with \" John\" rather than \" Mary\" (ie, finding the indirect object), and Redwood Research have [an excellent paper studying the underlying circuit in GPT-2 Small](https://arxiv.org/abs/2211.00593).\n",
    "\n",
    "**[Activation patching](https://dynalist.io/d/n2ZWtnoYHrU1s4vnFSAQ519J#z=qeWBvs-R-taFfcCq-S_hgMqx)** is a technique from [Kevin Meng and David Bau's excellent ROME paper](https://rome.baulab.info/). The goal is to identify which model activations are important for completing a task. We do this by setting up a **clean prompt** and a **corrupted prompt** and a **metric** for performance on the task. We then pick a specific model activation, run the model on the corrupted prompt, but then *intervene* on that activation and patch in its value when run on the clean prompt. We then apply the metric, and see how much this patch has recovered the clean performance. \n",
    "(See [a more detailed demonstration of activation patching here](https://colab.research.google.com/github.com/neelnanda-io/TransformerLens/blob/main/demos/Exploratory_Analysis_Demo.ipynb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, our clean prompt is \"After John and Mary went to the store, **Mary** gave a bottle of milk to\", our corrupted prompt is \"After John and Mary went to the store, **John** gave a bottle of milk to\", and our metric is the difference between the correct logit ( John) and the incorrect logit ( Mary) on the final token. \n",
    "\n",
    "We see that the logit difference is significantly positive on the clean prompt, and significantly negative on the corrupted prompt, showing that the model is capable of doing the task!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-08T19:27:30.731183Z",
     "iopub.status.busy": "2023-11-08T19:27:30.730853Z",
     "iopub.status.idle": "2023-11-08T19:27:30.920490Z",
     "shell.execute_reply": "2023-11-08T19:27:30.919904Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean logit difference: 4.276\n",
      "Corrupted logit difference: -2.738\n"
     ]
    }
   ],
   "source": [
    "clean_prompt = \"After John and Mary went to the store, Mary gave a bottle of milk to\"\n",
    "corrupted_prompt = \"After John and Mary went to the store, John gave a bottle of milk to\"\n",
    "\n",
    "clean_tokens = model.to_tokens(clean_prompt)\n",
    "corrupted_tokens = model.to_tokens(corrupted_prompt)\n",
    "\n",
    "def logits_to_logit_diff(logits, correct_answer=\" John\", incorrect_answer=\" Mary\"):\n",
    "    # model.to_single_token maps a string value of a single token to the token index for that token\n",
    "    # If the string is not a single token, it raises an error.\n",
    "    correct_index = model.to_single_token(correct_answer)\n",
    "    incorrect_index = model.to_single_token(incorrect_answer)\n",
    "    return logits[0, -1, correct_index] - logits[0, -1, incorrect_index]\n",
    "\n",
    "# We run on the clean prompt with the cache so we store activations to patch in later.\n",
    "clean_logits, clean_cache = model.run_with_cache(clean_tokens)\n",
    "clean_logit_diff = logits_to_logit_diff(clean_logits)\n",
    "print(f\"Clean logit difference: {clean_logit_diff.item():.3f}\")\n",
    "\n",
    "# We don't need to cache on the corrupted prompt.\n",
    "corrupted_logits = model(corrupted_tokens)\n",
    "corrupted_logit_diff = logits_to_logit_diff(corrupted_logits)\n",
    "print(f\"Corrupted logit difference: {corrupted_logit_diff.item():.3f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now setup the hook function to do activation patching. Here, we'll patch in the [residual stream](https://dynalist.io/d/n2ZWtnoYHrU1s4vnFSAQ519J#z=DHp9vZ0h9lA9OCrzG2Y3rrzH) at the start of a specific layer and at a specific position. This will let us see how much the model is using the residual stream at that layer and position to represent the key information for the task. \n",
    "\n",
    "We want to iterate over all layers and positions, so we write the hook to take in an position parameter. Hook functions must have the input signature (activation, hook), but we can use `functools.partial` to set the position parameter before passing it to `run_with_hooks`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-08T19:27:30.922925Z",
     "iopub.status.busy": "2023-11-08T19:27:30.922595Z",
     "iopub.status.idle": "2023-11-08T19:27:49.627940Z",
     "shell.execute_reply": "2023-11-08T19:27:49.627318Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95576ca76dc84d61959c6213bc97fdc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We define a residual stream patching hook\n",
    "# We choose to act on the residual stream at the start of the layer, so we call it resid_pre\n",
    "# The type annotations are a guide to the reader and are not necessary\n",
    "def residual_stream_patching_hook(\n",
    "    resid_pre: Float[torch.Tensor, \"batch pos d_model\"],\n",
    "    hook: HookPoint,\n",
    "    position: int\n",
    ") -> Float[torch.Tensor, \"batch pos d_model\"]:\n",
    "    # Each HookPoint has a name attribute giving the name of the hook.\n",
    "    clean_resid_pre = clean_cache[hook.name]\n",
    "    resid_pre[:, position, :] = clean_resid_pre[:, position, :]\n",
    "    return resid_pre\n",
    "\n",
    "# We make a tensor to store the results for each patching run. We put it on the model's device to avoid needing to move things between the GPU and CPU, which can be slow.\n",
    "num_positions = len(clean_tokens[0])\n",
    "ioi_patching_result = torch.zeros((model.cfg.n_layers, num_positions), device=model.cfg.device)\n",
    "\n",
    "for layer in tqdm.tqdm(range(model.cfg.n_layers)):\n",
    "    for position in range(num_positions):\n",
    "        # Use functools.partial to create a temporary hook function with the position fixed\n",
    "        temp_hook_fn = partial(residual_stream_patching_hook, position=position)\n",
    "        # Run the model with the patching hook\n",
    "        patched_logits = model.run_with_hooks(corrupted_tokens, fwd_hooks=[\n",
    "            (utils.get_act_name(\"resid_pre\", layer), temp_hook_fn)\n",
    "        ])\n",
    "        # Calculate the logit difference\n",
    "        patched_logit_diff = logits_to_logit_diff(patched_logits).detach()\n",
    "        # Store the result, normalizing by the clean and corrupted logit difference so it's between 0 and 1 (ish)\n",
    "        ioi_patching_result[layer, position] = (patched_logit_diff - corrupted_logit_diff)/(clean_logit_diff - corrupted_logit_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now visualize the results, and see that this computation is extremely localised within the model. Initially, the second subject (Mary) token is all that matters (naturally, as it's the only different token), and all relevant information remains here until heads in layer 7 and 8 move this to the final token where it's used to predict the indirect object.\n",
    "(Note - the heads are in layer 7 and 8, not 8 and 9, because we patched in the residual stream at the *start* of each layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-08T19:27:49.630199Z",
     "iopub.status.busy": "2023-11-08T19:27:49.630025Z",
     "iopub.status.idle": "2023-11-08T19:27:49.933491Z",
     "shell.execute_reply": "2023-11-08T19:27:49.932890Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<html>\n",
       "<head><meta charset=\"utf-8\" /></head>\n",
       "<body>\n",
       "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
       "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.27.0.min.js\"></script>                <div id=\"9746d39f-1b4e-4669-9f03-5bbd8105a0f1\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"9746d39f-1b4e-4669-9f03-5bbd8105a0f1\")) {                    Plotly.newPlot(                        \"9746d39f-1b4e-4669-9f03-5bbd8105a0f1\",                        [{\"coloraxis\":\"coloraxis\",\"name\":\"0\",\"x\":[\"\\u003c|endoftext|\\u003e_0\",\"After_1\",\" John_2\",\" and_3\",\" Mary_4\",\" went_5\",\" to_6\",\" the_7\",\" store_8\",\",_9\",\" Mary_10\",\" gave_11\",\" a_12\",\" bottle_13\",\" of_14\",\" milk_15\",\" to_16\"],\"z\":[[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.9981481432914734,0.0016014177817851305,0.00015065129264257848,-0.00037146147224120796,-2.1754698536824435e-05,-0.0006281669484451413,-0.0005147705669514835],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.9980558156967163,0.002284515183418989,0.00018328333680983633,-0.0005044370773248374,-0.0002678547170944512,-5.112354119773954e-05,-0.0012816237285733223],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.9967371821403503,0.004082269035279751,0.0009737947257235646,4.459713090909645e-05,-0.00015935316332615912,-0.000335566233843565,-0.0019443262135609984],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.9905908107757568,0.01998712867498398,0.0018961939495056868,0.0010137689532712102,-6.716763164149597e-05,0.0009112499537877738,-0.0019000009633600712],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.9616513848304749,0.0853474885225296,0.0052042677998542786,0.0030521841254085302,0.000196608089026995,0.0011059545213356614,-0.002284243470057845],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.9630990028381348,0.08437152206897736,0.004122787155210972,0.0007181770051829517,0.00010306288459105417,0.001002347795292735,-0.004215244669467211],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.9359181523323059,0.11111647635698318,0.007705242373049259,0.000375540490495041,0.00036575086414813995,0.0013264927547425032,0.018745480105280876],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7701545357704163,0.037419985979795456,0.0020680560264736414,-8.266785152954981e-05,0.00013487912656273693,0.0017251475946977735,0.44990673661231995],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.09650683403015137,0.02592724934220314,0.0019715195521712303,0.000329855625750497,0.0004239447007421404,0.0018861324060708284,0.8994726538658142],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-0.023321308195590973,0.01853826642036438,0.0015878210542723536,0.0005275514558888972,0.00025344223831780255,0.0008734511793591082,0.9612756967544556],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-0.008558842353522778,0.006340406835079193,0.0005816662451252341,-0.00034209262230433524,0.00011040509707527235,0.0006491058156825602,0.9495820999145508]],\"type\":\"heatmap\",\"xaxis\":\"x\",\"yaxis\":\"y\",\"hovertemplate\":\"Position: %{x}\\u003cbr\\u003eLayer: %{y}\\u003cbr\\u003ecolor: %{z}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"scaleanchor\":\"y\",\"constrain\":\"domain\",\"title\":{\"text\":\"Position\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"autorange\":\"reversed\",\"constrain\":\"domain\",\"title\":{\"text\":\"Layer\"}},\"coloraxis\":{\"colorscale\":[[0.0,\"rgb(103,0,31)\"],[0.1,\"rgb(178,24,43)\"],[0.2,\"rgb(214,96,77)\"],[0.3,\"rgb(244,165,130)\"],[0.4,\"rgb(253,219,199)\"],[0.5,\"rgb(247,247,247)\"],[0.6,\"rgb(209,229,240)\"],[0.7,\"rgb(146,197,222)\"],[0.8,\"rgb(67,147,195)\"],[0.9,\"rgb(33,102,172)\"],[1.0,\"rgb(5,48,97)\"]],\"cmid\":0.0},\"title\":{\"text\":\"Normalized Logit Difference After Patching Residual Stream on the IOI Task\"}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('9746d39f-1b4e-4669-9f03-5bbd8105a0f1');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                            </script>        </div>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Add the index to the end of the label, because plotly doesn't like duplicate labels\n",
    "token_labels = [f\"{token}_{index}\" for index, token in enumerate(model.to_str_tokens(clean_tokens))]\n",
    "imshow(ioi_patching_result, x=token_labels, xaxis=\"Position\", yaxis=\"Layer\", title=\"Normalized Logit Difference After Patching Residual Stream on the IOI Task\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hooks: Accessing Activations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hooks can also be used to just **access** an activation - to run some function using that activation value, *without* changing the activation value. This can be achieved by just having the hook return nothing, and not editing the activation in place. \n",
    "\n",
    "This is useful for eg extracting activations for a specific task, or for doing some long-running calculation across many inputs, eg finding the text that most activates a specific neuron. (Note - everything this can do *could* be done with `run_with_cache` and post-processing, but this workflow can be more intuitive and memory efficient.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To demonstrate this, let's look for **[induction heads](https://transformer-circuits.pub/2022/in-context-learning-and-induction-heads/index.html)** in GPT-2 Small. \n",
    "\n",
    "Induction circuits are a very important circuit in generative language models, which are used to detect and continue repeated subsequences. They consist of two heads in separate layers that compose together, a **previous token head** which always attends to the previous token, and an **induction head** which attends to the token *after* an earlier copy of the current token. \n",
    "\n",
    "To see why this is important, let's say that the model is trying to predict the next token in a news article about Michael Jordan. The token \" Michael\", in general, could be followed by many surnames. But an induction head will look from that occurence of \" Michael\" to the token after previous occurences of \" Michael\", ie \" Jordan\" and can confidently predict that that will come next."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An interesting fact about induction heads is that they generalise to arbitrary sequences of repeated tokens. We can see this by generating sequences of 50 random tokens, repeated twice, and plotting the average loss at predicting the next token, by position. We see that the model goes from terrible to very good at the halfway point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-08T19:27:49.935796Z",
     "iopub.status.busy": "2023-11-08T19:27:49.935609Z",
     "iopub.status.idle": "2023-11-08T19:27:51.821699Z",
     "shell.execute_reply": "2023-11-08T19:27:51.821120Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<html>\n",
       "<head><meta charset=\"utf-8\" /></head>\n",
       "<body>\n",
       "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
       "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.27.0.min.js\"></script>                <div id=\"1d88c8c1-da5a-4a40-85a1-00d9941e9c93\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"1d88c8c1-da5a-4a40-85a1-00d9941e9c93\")) {                    Plotly.newPlot(                        \"1d88c8c1-da5a-4a40-85a1-00d9941e9c93\",                        [{\"hovertemplate\":\"variable=0\\u003cbr\\u003eindex=%{x}\\u003cbr\\u003evalue=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"0\",\"line\":{\"color\":\"#636efa\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"0\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98],\"xaxis\":\"x\",\"y\":[12.730462074279785,13.764925003051758,14.112274169921875,12.336832046508789,13.190664291381836,13.2698392868042,11.864253044128418,12.161999702453613,12.415262222290039,12.676797866821289,12.257417678833008,12.697195053100586,12.842803955078125,12.29205322265625,11.812948226928711,11.5677490234375,11.470380783081055,11.872190475463867,11.709054946899414,12.804742813110352,10.48235034942627,12.08299732208252,12.795917510986328,10.75924015045166,12.657038688659668,12.687896728515625,10.848310470581055,12.268604278564453,12.321916580200195,10.322389602661133,11.961702346801758,11.810809135437012,12.13437271118164,11.617806434631348,11.76750373840332,11.676104545593262,12.729379653930664,11.462433815002441,11.341532707214355,12.302268028259277,11.613665580749512,10.789351463317871,12.190001487731934,12.050442695617676,12.36815357208252,11.639376640319824,11.264471054077148,10.754213333129883,11.665790557861328,10.841596603393555,2.9107208251953125,1.0005608797073364,0.5383390188217163,0.5687149167060852,0.6876764297485352,0.3068907856941223,0.6690329313278198,0.15030373632907867,0.2676582634449005,0.10111141204833984,0.06530164182186127,0.15636423230171204,0.07076207548379898,0.22571583092212677,0.05147146061062813,0.09256303310394287,0.09263847023248672,0.03335556760430336,0.1754612922668457,0.3641909658908844,0.09954534471035004,0.05799862742424011,0.03472891077399254,0.056137897074222565,0.011925937607884407,0.10800810158252716,0.06123264506459236,0.13189606368541718,0.05753859877586365,0.03111434355378151,0.01943364366889,0.07023918628692627,0.028006304055452347,0.10580623149871826,0.0686173215508461,0.07463768869638443,0.07380674034357071,0.04163356497883797,0.13636097311973572,0.041568540036678314,0.07082106173038483,0.00825585052371025,0.05107048153877258,0.08605556935071945,0.006739770527929068,0.06868518888950348,0.011717095039784908,0.010872425511479378,0.012175322510302067],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"index\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"value\"}},\"legend\":{\"title\":{\"text\":\"variable\"},\"tracegroupgap\":0},\"title\":{\"text\":\"Loss by position on random repeated tokens\"}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('1d88c8c1-da5a-4a40-85a1-00d9941e9c93');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                            </script>        </div>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 10\n",
    "seq_len = 50\n",
    "size = (batch_size, seq_len)\n",
    "input_tensor = torch.randint(1000, 10000, size)\n",
    "\n",
    "random_tokens = input_tensor.to(model.cfg.device)\n",
    "repeated_tokens = einops.repeat(random_tokens, \"batch seq_len -> batch (2 seq_len)\")\n",
    "repeated_logits = model(repeated_tokens)\n",
    "correct_log_probs = model.loss_fn(repeated_logits, repeated_tokens, per_token=True)\n",
    "loss_by_position = einops.reduce(correct_log_probs, \"batch position -> position\", \"mean\")\n",
    "line(loss_by_position, xaxis=\"Position\", yaxis=\"Loss\", title=\"Loss by position on random repeated tokens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The induction heads will be attending from the second occurence of each token to the token *after* its first occurence, ie the token `50-1==49` places back. So by looking at the average attention paid 49 tokens back, we can identify induction heads! Let's define a hook to do this!\n",
    "\n",
    "<details><summary>Technical details</summary>\n",
    "\n",
    "* We attach the hook to the attention pattern activation. There's one big pattern activation per layer, stacked across all heads, so we need to do some tensor manipulation to get a per-head score. \n",
    "* Hook functions can access global state, so we make a big tensor to store the induction head score for each head, and then we just add the score for each head to the appropriate position in the tensor. \n",
    "* To get a single hook function that works for each layer, we use the `hook.layer()` method to get the layer index (internally this is just inferred from the hook names).\n",
    "* As we want to add this to *every* activation pattern hook point, rather than giving the string for an activation name, this time we give a **name filter**. This is a Boolean function on hook point names, and it adds the hook function to every hook point where the function evaluates as true. \n",
    "    * `run_with_hooks` allows us to enter a list of (act_name, hook_function) pairs to all be added at once, so we could also have done this by inputting a list with a hook for each layer.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-08T19:27:51.823880Z",
     "iopub.status.busy": "2023-11-08T19:27:51.823693Z",
     "iopub.status.idle": "2023-11-08T19:27:53.064718Z",
     "shell.execute_reply": "2023-11-08T19:27:53.064147Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<html>\n",
       "<head><meta charset=\"utf-8\" /></head>\n",
       "<body>\n",
       "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
       "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.27.0.min.js\"></script>                <div id=\"45a80876-72c4-4499-8dab-62929aa9fd43\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"45a80876-72c4-4499-8dab-62929aa9fd43\")) {                    Plotly.newPlot(                        \"45a80876-72c4-4499-8dab-62929aa9fd43\",                        [{\"coloraxis\":\"coloraxis\",\"name\":\"0\",\"z\":[[0.01004245039075613,0.00011994626402156428,0.01120863389223814,2.3006548417470185e-06,0.000168655053130351,0.00019989280554000288,0.00931890495121479,0.0007898639305494726,0.009349474683403969,0.009520203806459904,0.0068638804368674755,0.01534233707934618],[0.0006698948564007878,0.0005314804730005562,0.0020875297486782074,0.014409798197448254,0.004967809189110994,0.01052755769342184,0.015732189640402794,0.01307748444378376,0.012933564372360706,0.01559465192258358,0.006518846843391657,0.0005358640919439495],[0.004855594597756863,0.018267475068569183,0.0016904419753700495,0.0016364874318242073,0.01182436291128397,0.0021670996211469173,0.004806604236364365,0.008463673293590546,0.004350317642092705,0.0018217222532257438,0.000662601029034704,0.010482723824679852],[0.017291145399212837,0.007210870739072561,0.002100807847455144,0.01010353397578001,0.0223851278424263,0.011721701361238956,0.001107785850763321,0.0013284560991451144,0.005690969526767731,0.012540014460682869,0.00951681099832058,0.006296356674283743],[0.015692271292209625,0.01425457838922739,0.01448829099535942,0.006753286346793175,0.01834387518465519,0.01313046831637621,0.008700343780219555,0.0019017055165022612,0.015735359862446785,0.014689221978187561,0.01871410571038723,7.169663751582789e-10],[0.4589446187019348,0.9093074798583984,0.014931762591004372,0.007887422107160091,0.013648726977407932,0.932224690914154,0.01037001982331276,0.018417268991470337,0.02658863738179207,0.028121216222643852,0.01860755868256092,0.01803322322666645],[0.008980627171695232,0.016828900203108788,0.019496213644742966,0.014480644837021828,0.023051206022500992,0.011770150624215603,0.02974553592503071,0.011316252872347832,0.009070973843336105,0.9175302982330322,0.035499922931194305,0.014647168107330799],[0.009619069285690784,0.17654697597026825,0.8505546450614929,0.016720138490200043,0.01783796213567257,0.01763191819190979,0.04560495540499687,0.08892720937728882,0.014547215774655342,0.0184467826038599,0.9212338328361511,0.05728449299931526],[0.016781508922576904,0.4050188362598419,0.015084524638950825,0.0433812215924263,0.01746322028338909,0.011593908071517944,0.1502002626657486,0.013970807194709778,0.03099595569074154,0.029777461662888527,0.06529862433671951,0.0191472340375185],[0.25620579719543457,0.1721106767654419,0.10222849994897842,0.010722460225224495,0.0861995592713356,0.02688940428197384,0.47309744358062744,0.028700852766633034,0.05104471370577812,0.4818677306175232,0.016368065029382706,0.04182865470647812],[0.3533375859260559,0.5076125860214233,0.035694483667612076,0.14846962690353394,0.05880491062998772,0.014281087554991245,0.318394273519516,0.4729890823364258,0.049820251762866974,0.015013698488473892,0.1675345003604889,0.27110669016838074],[0.016534198075532913,0.05133860185742378,0.032540757209062576,0.00746220862492919,0.03334246575832367,0.1009703055024147,0.05168086290359497,0.06080252677202225,0.007946946658194065,0.3185330033302307,0.37632739543914795,0.02126930095255375]],\"type\":\"heatmap\",\"xaxis\":\"x\",\"yaxis\":\"y\",\"hovertemplate\":\"Head: %{x}\\u003cbr\\u003eLayer: %{y}\\u003cbr\\u003ecolor: %{z}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"scaleanchor\":\"y\",\"constrain\":\"domain\",\"title\":{\"text\":\"Head\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"autorange\":\"reversed\",\"constrain\":\"domain\",\"title\":{\"text\":\"Layer\"}},\"coloraxis\":{\"colorscale\":[[0.0,\"rgb(103,0,31)\"],[0.1,\"rgb(178,24,43)\"],[0.2,\"rgb(214,96,77)\"],[0.3,\"rgb(244,165,130)\"],[0.4,\"rgb(253,219,199)\"],[0.5,\"rgb(247,247,247)\"],[0.6,\"rgb(209,229,240)\"],[0.7,\"rgb(146,197,222)\"],[0.8,\"rgb(67,147,195)\"],[0.9,\"rgb(33,102,172)\"],[1.0,\"rgb(5,48,97)\"]],\"cmid\":0.0},\"title\":{\"text\":\"Induction Score by Head\"}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('45a80876-72c4-4499-8dab-62929aa9fd43');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                            </script>        </div>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We make a tensor to store the induction score for each head. We put it on the model's device to avoid needing to move things between the GPU and CPU, which can be slow.\n",
    "induction_score_store = torch.zeros((model.cfg.n_layers, model.cfg.n_heads), device=model.cfg.device)\n",
    "def induction_score_hook(\n",
    "    pattern: Float[torch.Tensor, \"batch head_index dest_pos source_pos\"],\n",
    "    hook: HookPoint,\n",
    "):\n",
    "    # We take the diagonal of attention paid from each destination position to source positions seq_len-1 tokens back\n",
    "    # (This only has entries for tokens with index>=seq_len)\n",
    "    induction_stripe = pattern.diagonal(dim1=-2, dim2=-1, offset=1-seq_len)\n",
    "    # Get an average score per head\n",
    "    induction_score = einops.reduce(induction_stripe, \"batch head_index position -> head_index\", \"mean\")\n",
    "    # Store the result.\n",
    "    induction_score_store[hook.layer(), :] = induction_score\n",
    "\n",
    "# We make a boolean filter on activation names, that's true only on attention pattern names.\n",
    "pattern_hook_names_filter = lambda name: name.endswith(\"pattern\")\n",
    "\n",
    "model.run_with_hooks(\n",
    "    repeated_tokens, \n",
    "    return_type=None, # For efficiency, we don't need to calculate the logits\n",
    "    fwd_hooks=[(\n",
    "        pattern_hook_names_filter,\n",
    "        induction_score_hook\n",
    "    )]\n",
    ")\n",
    "\n",
    "imshow(induction_score_store, xaxis=\"Head\", yaxis=\"Layer\", title=\"Induction Score by Head\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Head 5 in Layer 5 scores extremely highly on this score, and we can feed in a shorter repeated random sequence, visualize the attention pattern for it and see this directly - including the \"induction stripe\" at `seq_len-1` tokens back.\n",
    "\n",
    "This time we put in a hook on the attention pattern activation to visualize the pattern of the relevant head."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-08T19:27:53.066887Z",
     "iopub.status.busy": "2023-11-08T19:27:53.066551Z",
     "iopub.status.idle": "2023-11-08T19:27:53.283995Z",
     "shell.execute_reply": "2023-11-08T19:27:53.283339Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"circuits-vis-4ec38dce-6bfb\" style=\"margin: 15px 0;\"/>\n",
       "    <script crossorigin type=\"module\">\n",
       "    import { render, AttentionPatterns } from \"https://unpkg.com/circuitsvis@1.43.1/dist/cdn/esm.js\";\n",
       "    render(\n",
       "      \"circuits-vis-4ec38dce-6bfb\",\n",
       "      AttentionPatterns,\n",
       "      {\"tokens\": [\"use\", \" advice\", \" Social\", \"\\u00f6\", \"\\u00b7\", \" fought\", \" Le\", \" allegedly\", \" NO\", \"alth\", \"car\", \" prepared\", \"new\", \"rant\", \"roll\", \" hours\", \" published\", \"66\", \"ension\", \" 44\", \"use\", \" advice\", \" Social\", \"\\u00f6\", \"\\u00b7\", \" fought\", \" Le\", \" allegedly\", \" NO\", \"alth\", \"car\", \" prepared\", \"new\", \"rant\", \"roll\", \" hours\", \" published\", \"66\", \"ension\", \" 44\"], \"attention\": [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9737270474433899, 0.026272933930158615, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9820428490638733, 0.01702023483812809, 0.0009368443279527128, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9895542860031128, 0.008665821515023708, 0.0004119746736250818, 0.0013679955154657364, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8543054461479187, 0.07801828533411026, 0.0008415375486947596, 0.000135991329443641, 0.06669872254133224, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.937433660030365, 0.03300206735730171, 0.0015577399171888828, 2.5352790089527844e-06, 0.001092560007236898, 0.026911471039056778, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.976921021938324, 0.003843690035864711, 2.2340229406836443e-05, 3.521892358548939e-05, 0.0051834965124726295, 0.01217624731361866, 0.001817896030843258, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9473506212234497, 0.01317491102963686, 0.0013492174912244081, 1.1802459084719885e-05, 0.0009449480567127466, 0.011318984441459179, 0.018020981922745705, 0.0078285476192832, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9847128391265869, 0.0010781469754874706, 0.0021734496112912893, 5.482254437083611e-06, 0.000491426617372781, 0.0013570819282904267, 0.0001018582479446195, 0.0002853853511624038, 0.009794449433684349, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9915198683738708, 0.004483338911086321, 0.00012727164721582085, 0.00016702202265150845, 0.0016301852883771062, 0.0011521565029397607, 0.0003231279260944575, 0.00012646272080019116, 0.00039313756860792637, 7.735053804935887e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8908805847167969, 0.024311963468790054, 1.734130819386337e-05, 4.1577386582503095e-05, 0.0008967677713371813, 0.0733492448925972, 0.0009482789901085198, 0.004280863795429468, 0.005168668460100889, 7.83030736783985e-06, 9.69318498391658e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8170806765556335, 0.13517117500305176, 0.011989925056695938, 1.1421705494285561e-05, 0.0003511993563733995, 0.009450689889490604, 0.019463282078504562, 0.0006557483575306833, 0.000576103397179395, 2.9927139621577226e-05, 1.6589807273703627e-05, 0.005203104577958584, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9082695841789246, 0.006068165879696608, 0.0138718755915761, 0.000823706912342459, 0.01190832071006298, 0.015542060136795044, 0.008354808203876019, 0.002078162506222725, 0.001317329122684896, 0.0021398081444203854, 0.003944150172173977, 0.0012376607628539205, 0.024444350972771645, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9479591250419617, 0.002102671656757593, 0.011938502080738544, 0.00012338555825408548, 3.537522616170463e-06, 0.00014498841483145952, 0.000587546790484339, 2.5534563974360935e-05, 0.0013609015149995685, 0.0003395717067178339, 0.010076263919472694, 0.015790535137057304, 0.006346346810460091, 0.003201026702299714, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9393549561500549, 0.006392320618033409, 0.0018427305622026324, 6.116198164818343e-06, 0.0003358749963808805, 0.0020515176001936197, 0.0038015025202184916, 0.0012357983505353332, 0.0002194814442191273, 0.00038693423266522586, 5.012224573874846e-05, 0.008153212256729603, 0.02692468836903572, 0.002937993500381708, 0.006306749768555164, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9339621663093567, 0.001782808220013976, 0.005864632315933704, 0.00019950229034293443, 7.22721015335992e-05, 0.0014535370282828808, 0.0025924285873770714, 0.00048594013787806034, 0.002229835605248809, 0.00015120470197871327, 0.012292890809476376, 0.005057864356786013, 0.012368586845695972, 0.003944482188671827, 0.00627509830519557, 0.011266657151281834, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8931334614753723, 0.0015468199271708727, 0.013001683168113232, 7.966379598656204e-06, 5.8643763622967526e-05, 0.0008863396942615509, 0.0032020884100347757, 3.214768003090285e-05, 0.00018022512085735798, 1.1455701496743131e-05, 7.6000826084055e-05, 0.0004202734271530062, 0.0016126175178214908, 0.02853921428322792, 0.01053547766059637, 0.025431964546442032, 0.021323587745428085, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9847024083137512, 0.0004582440888043493, 0.00017220467270817608, 6.160951784295321e-07, 4.782819814863615e-06, 0.0005806126864627004, 0.0004461855278350413, 0.0004120130033697933, 0.0013038694160059094, 0.0003176052123308182, 6.9941277615726e-05, 0.0013941078213974833, 5.583037273027003e-05, 0.0009110365062952042, 0.0001955796469701454, 0.0003960265312343836, 0.0011691716499626637, 0.007409730460494757, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8922598958015442, 0.01028368715196848, 0.0075692832469940186, 0.015225795097649097, 0.0006035331171005964, 0.00143777288030833, 0.01839740388095379, 0.00018186656234320253, 0.0021135725546628237, 3.803661456913687e-05, 0.009962520562112331, 0.003998211584985256, 0.0012666877591982484, 0.002186270197853446, 0.003267065854743123, 0.0015871921787038445, 0.019133849069476128, 0.00877940934151411, 0.001708078314550221, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5637843608856201, 2.204171323683113e-05, 0.0003808308974839747, 1.3938013410097483e-07, 4.306950174282065e-08, 0.00012883286399301142, 5.202732791076414e-05, 4.098202225577552e-06, 0.0004382180923130363, 1.0102457963512279e-05, 2.0490015231189318e-05, 0.00021747566643171012, 2.52499903581338e-05, 2.1293833924573846e-05, 0.0022071986459195614, 5.8927646023221314e-05, 0.0024183825589716434, 0.0032775476574897766, 0.4260486662387848, 0.0008841015514917672, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.14634999632835388, 0.45109105110168457, 0.02720528282225132, 0.003008284606039524, 0.0007913809968158603, 0.08009319752454758, 0.005927636753767729, 0.0006846330943517387, 0.002126845298334956, 0.0027747375424951315, 0.00023907267313916236, 0.002550550037994981, 0.005493445787578821, 0.015832239761948586, 0.0003450005315244198, 0.0005726682138629258, 0.0021751681342720985, 0.03904329240322113, 0.16982696950435638, 0.04120749980211258, 0.0026610286440700293, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.15882991254329681, 0.0941384956240654, 0.6926905512809753, 4.7764129703864455e-05, 8.085449735517614e-06, 0.009355572983622551, 0.0008445500861853361, 2.4437758838757873e-06, 0.00013774035323876888, 1.1189690667379182e-06, 4.677335255109938e-06, 0.00034721221891231835, 0.002631483133882284, 0.000450413761427626, 0.006463170982897282, 0.0005723314243368804, 0.001266835955902934, 0.006402315106242895, 0.0018092982936650515, 0.006555385421961546, 0.00037915154825896025, 0.01706140860915184, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.05072375386953354, 0.004356098361313343, 0.00013167172437533736, 0.9396470785140991, 0.0005500915576703846, 0.0027711710426956415, 1.4556166206602938e-05, 5.01738713865052e-06, 1.5498595530516468e-05, 7.020687320391517e-08, 8.694868483871687e-06, 3.6541609006235376e-05, 3.607972075769794e-06, 2.594170109659899e-05, 7.590788754896494e-06, 7.100840093698935e-07, 4.6297886001411825e-05, 7.143482071114704e-05, 0.00012089101801393554, 0.0005609954823739827, 1.3380936252360698e-05, 0.0007342116441577673, 0.00015471104416064918, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.04466310888528824, 0.0028326644096523523, 7.648704922758043e-05, 0.00015513721155002713, 0.7502232789993286, 0.19195610284805298, 9.640481584938243e-05, 0.00016210121975746006, 0.000127694322145544, 1.1226533388253301e-05, 8.733258255233523e-06, 0.00028133264277130365, 5.207781941862777e-05, 0.008386555127799511, 4.340242412581574e-06, 6.482691242126748e-05, 3.8029469578759745e-05, 7.603649282827973e-05, 0.00012636417523026466, 9.227972623193637e-05, 4.030191576021025e-07, 0.00011281662591500208, 2.522401246096706e-06, 0.0004493824380915612, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.013606250286102295, 0.0069718193262815475, 3.1886105716694146e-05, 1.8455467625244637e-06, 0.0023010955192148685, 0.9711790084838867, 0.00036324496613815427, 8.459793025394902e-05, 0.00010611555626383051, 4.505667163812177e-07, 2.987582377045328e-07, 0.000859266787301749, 8.844877447700128e-05, 0.00034812037483789027, 9.285108717449475e-07, 3.16055775329005e-05, 1.28021820273716e-05, 5.8033951063407585e-05, 0.0001051755461958237, 6.438314449042082e-05, 1.8867485778173432e-06, 0.0009238758939318359, 4.6810419007670134e-06, 8.993160008685663e-06, 0.002845229348167777, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0196113009005785, 0.004386152606457472, 6.198717892402783e-05, 4.8857877743557765e-08, 4.25249854743015e-05, 0.0036122458986938, 0.9598401188850403, 0.005622261669486761, 0.0023445691913366318, 5.173955059945001e-07, 1.9621541014203103e-06, 0.0016548329731449485, 0.0005915368674322963, 0.0011695865541696548, 5.784221684734803e-06, 8.119027188513428e-05, 4.50031875516288e-05, 0.00018497853307053447, 5.086978126200847e-05, 0.00011132831423310563, 6.8484796429402195e-06, 3.853969610645436e-05, 4.8530541789659765e-06, 1.2763493373313395e-07, 3.953090072172927e-06, 0.000526951567735523, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.008729088120162487, 0.00017810733697842807, 2.880620684209134e-07, 4.138290421451529e-07, 6.865051545901224e-05, 0.0009331147302873433, 0.00014888252189848572, 0.984452486038208, 0.004786348436027765, 0.00011328891559969634, 7.255455898302898e-07, 7.424674549838528e-05, 1.4996331628935877e-05, 0.00019790638179983944, 2.995045917941752e-07, 4.872005320066819e-06, 5.296112703945255e-06, 4.536827418633038e-06, 0.0001126891584135592, 3.4170932394772535e-06, 8.272501872852445e-06, 1.2379839972709306e-05, 3.665505587946427e-08, 9.025101803672442e-07, 1.605309807928279e-05, 0.00011404316319385543, 1.8653590814210474e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.040821623057127, 0.003618423594161868, 4.821059701498598e-05, 1.9615821145180234e-07, 5.3803432820132e-05, 0.0021802415139973164, 0.0033272404689341784, 0.0018782162806019187, 0.9307870864868164, 0.004815374035388231, 1.4430223927774932e-05, 0.002828805474564433, 0.0001046408069669269, 0.0029309147503226995, 0.000951474707107991, 6.522190960822627e-05, 0.0002954133087769151, 0.00012317548680584878, 0.0015512369573116302, 0.0005327708786353469, 0.00022083590738475323, 0.0004432715068105608, 1.9391451132833026e-05, 5.82568759455171e-07, 1.6632830011076294e-05, 0.00047732252278365195, 0.0011258190497756004, 0.0007676906534470618, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.13800930976867676, 0.000338583457050845, 0.0001597269729245454, 3.422593763957593e-08, 1.2696473277173936e-05, 0.00024196706362999976, 3.821916106971912e-05, 3.75151212210767e-05, 0.004743287805467844, 0.8406776785850525, 0.00018875458044931293, 0.00015232681471388787, 1.2507526662375312e-05, 0.00022362935123965144, 0.00013282430882100016, 6.470827793236822e-05, 0.00013950459833722562, 9.763542038854212e-05, 0.0004387961816973984, 4.486089892452583e-05, 6.358895188895985e-05, 0.0003425588656682521, 5.2226594561943784e-05, 5.293456979416078e-07, 4.435886694409419e-06, 6.543439667439088e-05, 2.914496462835814e-06, 3.872648903779918e-06, 0.013709800317883492, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.007798763923346996, 0.00022834587434772402, 4.638495170183887e-07, 6.367751552716072e-07, 1.581695869390387e-05, 4.743899989989586e-05, 5.23908101968118e-06, 7.306607585633174e-06, 1.2522128599812277e-05, 3.330236779675033e-07, 0.9909056425094604, 0.0004522074304986745, 5.365378910937579e-06, 7.535902841482311e-05, 8.799955139693338e-06, 7.89501609688159e-06, 0.00023918168153613806, 2.256900643260451e-06, 7.641906995559111e-05, 5.5141681514214724e-05, 4.37830931332428e-06, 2.181077616114635e-05, 4.4351484262961094e-08, 1.2584339401655598e-06, 2.0698282696685055e-06, 1.2951734788657632e-05, 3.9528501361019153e-07, 1.120234287554922e-06, 7.981775524967816e-06, 2.9978652946738293e-06, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.04228431358933449, 0.011305327527225018, 7.640707622158516e-07, 2.2586116301681614e-06, 9.7864460258279e-05, 0.03826918080449104, 0.0002364078682148829, 0.0014555177185684443, 0.0029497784562408924, 1.2863364418080891e-06, 2.8271377232158557e-05, 0.8946185111999512, 0.0005234958371147513, 0.0011799597414210439, 0.0009106295183300972, 0.00036045987508259714, 0.00020461679378058761, 2.9102066037012264e-05, 0.0013425362994894385, 0.0003398236876819283, 0.0003325499128550291, 8.430355228483677e-05, 7.937668300428413e-08, 5.809842605231097e-06, 4.910861207463313e-06, 0.0023872717283666134, 2.6967063604388386e-05, 0.00020931477774865925, 0.0007688809419050813, 5.801360657642363e-06, 3.414767706999555e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.006102938205003738, 0.016550486907362938, 4.6485260099871084e-05, 8.233644166466547e-08, 7.3985620474559255e-06, 0.0005482275155372918, 0.0005931382765993476, 1.5738474758109078e-05, 3.503294283291325e-05, 3.350411361680017e-07, 1.8657613054529065e-07, 0.0004606691072694957, 0.8416222333908081, 0.12311315536499023, 0.006359195336699486, 0.002699509961530566, 0.00016676295490469784, 0.0012130788527429104, 0.0001319888251600787, 8.468214946333319e-05, 4.61595709566609e-06, 6.994947761995718e-05, 4.916088528261753e-06, 3.4761239930958254e-07, 3.711939484674076e-07, 6.107331137172878e-05, 6.728528387611732e-05, 2.275825863762293e-06, 2.0601521100616083e-05, 7.198157163657015e-07, 2.788131148179218e-08, 1.6529431377421133e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.040416911244392395, 0.0013464335352182388, 0.00028817105339840055, 4.343557975516887e-06, 0.000683746999129653, 0.002149260835722089, 0.0012713854666799307, 0.00021145769278518856, 0.00014913463382981718, 2.3681606762693264e-05, 9.255079930881038e-05, 7.460868073394522e-05, 0.0030381495598703623, 0.915346086025238, 0.0020634792745113373, 0.002670755609869957, 0.0006971395923756063, 0.022915076464414597, 0.0016386328497901559, 0.00029437473858706653, 8.301910384034272e-06, 0.0001194091237266548, 3.610841667978093e-05, 1.259376949747093e-05, 0.0003830744535662234, 0.0011952044442296028, 0.000184451972017996, 7.12581240804866e-05, 0.00012850583880208433, 6.0622252931352705e-05, 4.5176475396147e-05, 6.895728006384161e-07, 0.0023790784180164337, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.03775652125477791, 0.0016132259042933583, 0.00031778556876815856, 8.171189733729989e-07, 4.6315926738316193e-07, 7.222061685752124e-05, 0.0001249091437784955, 4.997595169697888e-06, 0.000306671776343137, 5.74938303543604e-06, 0.0002466135483700782, 0.0037777582183480263, 0.0013358108699321747, 0.00211318489164114, 0.8997161388397217, 0.04417843371629715, 0.00033094995887950063, 0.001384938252158463, 0.00039356076740659773, 0.002321053296327591, 0.00046422172454185784, 0.00019271692144684494, 0.0005703868810087442, 5.927732217969606e-06, 2.468730642135597e-08, 3.108331839030143e-06, 7.165992428781465e-06, 2.924018644989701e-07, 7.984158582985401e-05, 1.2546447578642983e-05, 0.00012651394354179502, 0.0002383790852036327, 0.0008907291339710355, 0.0014062355039641261, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.08771752566099167, 0.007821434177458286, 5.6624761782586575e-05, 1.4731194042383322e-08, 1.0490872227819636e-05, 0.001105872797779739, 0.00042911499622277915, 5.523023719433695e-05, 3.919866867363453e-05, 2.7502028387971222e-06, 2.546176801843103e-06, 0.0027552093379199505, 0.005722662899643183, 0.0011191837256774306, 0.001587632461450994, 0.8757361173629761, 0.001080043031834066, 0.003532147267833352, 0.0015019838465377688, 0.0006949508097022772, 4.334091499913484e-05, 0.00023435152252204716, 6.934274551895214e-06, 2.7577929273547852e-08, 9.912379255183623e-07, 0.00019156531197950244, 2.9515373171307147e-05, 5.468174094858114e-06, 2.4805667635519058e-06, 1.4659860880783526e-06, 7.256049343595805e-07, 8.567820623284206e-05, 0.0042638652957975864, 0.0007048685220070183, 0.003457949496805668, 0.0, 0.0, 0.0, 0.0, 0.0], [0.018741386011242867, 0.00013177517394069582, 0.00011519038525875658, 8.336373298334365e-07, 3.8734773966098146e-07, 4.0343798900721595e-05, 8.927313319873065e-05, 6.575971383426804e-06, 6.646571273449808e-05, 2.014518543091981e-07, 0.00012498433352448046, 0.00022737678955309093, 0.0003596775932237506, 4.087335037183948e-05, 8.6540101619903e-05, 0.0001706214970909059, 0.9720673561096191, 0.004511019214987755, 0.0017741491319611669, 0.0003342096460983157, 0.0006673677125945687, 8.272362720163073e-06, 8.590801007812843e-05, 4.4451923031374463e-07, 1.5395077213042896e-08, 3.9162018765637185e-06, 1.8561571778263897e-05, 1.7440301007809467e-06, 2.3064632841851562e-05, 6.561240297742188e-07, 5.53653335373383e-05, 1.0027742973761633e-05, 0.00011005577107425779, 2.0988110918551683e-05, 6.008594573359005e-05, 4.435584196471609e-05, 0.0, 0.0, 0.0, 0.0], [0.02161446213722229, 6.69997971272096e-05, 0.00023383130610454828, 1.9461027989109425e-07, 1.0568076049821684e-06, 2.5699633624753915e-05, 0.00021046715846750885, 1.7352572285744827e-06, 6.270182893786114e-06, 8.374802717980856e-08, 2.3547788714495255e-06, 1.8064714822685346e-05, 0.00023376620083581656, 0.001895326655358076, 0.0002040943072643131, 0.0004746896156575531, 0.0029953892808407545, 0.962553858757019, 0.006914269644767046, 0.00019762454030569643, 0.0001176124278572388, 1.7810394638217986e-05, 8.193766552722082e-05, 8.319953792579327e-08, 6.341063141235281e-08, 1.5034653415568755e-06, 1.5951727618812583e-05, 1.2851917574607796e-07, 7.93534070453461e-07, 1.2686584227594722e-07, 5.140194048181002e-07, 3.882933086174489e-08, 5.885353675694205e-05, 0.001102684298530221, 9.716697968542576e-05, 8.231336687458679e-05, 0.0007721185684204102, 0.0, 0.0, 0.0], [0.03668336942791939, 5.292128207656788e-06, 1.6796285535747302e-06, 3.2259306337323324e-10, 1.767925539297721e-08, 9.711822713143192e-06, 6.970077720325207e-06, 3.922060386685189e-06, 1.5272446034941822e-05, 6.423099989660841e-07, 3.0026015451767307e-07, 2.1527865101234056e-05, 8.620299354333838e-07, 2.37110707530519e-05, 1.1333936527080368e-06, 4.3700406422431115e-06, 2.1794803615193814e-05, 0.0007244828739203513, 0.956550121307373, 7.606104190926999e-05, 0.005361168645322323, 3.4097050956916064e-05, 1.478855665482115e-06, 1.9675807649832677e-09, 6.515244788118935e-09, 7.01611099884758e-07, 1.9081964808265184e-07, 3.605073857215757e-07, 3.9733699850330595e-06, 1.5304382259273552e-06, 1.0370983716256887e-07, 7.635122756255441e-07, 1.8985070937560522e-07, 6.164449587231502e-06, 2.6138040993828326e-06, 1.3529003126677708e-06, 1.0274146916344762e-05, 0.0004238302353769541, 0.0, 0.0], [0.039370156824588776, 0.0003585806116461754, 7.419259782182053e-05, 4.9509686505189165e-05, 4.653114046959672e-06, 4.697614349424839e-05, 0.00022992292360868305, 1.250448349310318e-06, 3.723302506841719e-05, 8.911857207749563e-08, 7.931947038741782e-05, 0.00013509151176549494, 1.8374767023487948e-05, 0.00010297392145730555, 8.208450162783265e-05, 2.7536349080037326e-05, 0.0005808349815197289, 0.001175027689896524, 0.0009059886215254664, 0.9545682072639465, 7.41759140510112e-05, 0.0005086685996502638, 0.00019448206876404583, 8.633093966636807e-05, 8.952690677688224e-07, 1.429001713404432e-05, 3.445206311880611e-05, 2.1258604476770415e-07, 1.695069659035653e-05, 4.816170076082926e-07, 3.185392779414542e-05, 1.3589543414127547e-05, 2.5087558242375962e-05, 5.981937647447921e-05, 0.00011690137762343511, 1.134204285335727e-05, 0.00027131877141073346, 0.0002638357982505113, 0.00042732167639769614, 0.0], [0.025401175022125244, 7.441653906425927e-07, 1.083010920410743e-05, 2.249717967472975e-09, 9.222053676261055e-10, 8.208572580770124e-06, 2.5448041469644522e-06, 1.0004308848010623e-07, 3.1608818972017616e-05, 2.427832441753708e-07, 5.289145974529674e-07, 1.426299331797054e-05, 1.534571993033751e-06, 1.877791987681121e-06, 0.00020286838116589934, 2.141227923857514e-06, 0.00010114473843714222, 0.000930983864236623, 0.10166110098361969, 5.551500362344086e-05, 0.8627557754516602, 2.250253828606219e-06, 3.0665665690321475e-05, 5.196929997453026e-09, 3.1991929938524066e-11, 8.736421364119451e-08, 1.2241717683991737e-07, 1.2374246072255346e-09, 1.250754576176405e-05, 4.635776349459775e-07, 1.6297892102556943e-07, 2.719453107147274e-07, 1.1941887123612105e-07, 1.4462533215464646e-07, 5.5279004300246015e-05, 3.5639581597024517e-07, 4.9333561037201434e-05, 0.0001694792736088857, 0.008456716313958168, 3.8713751564500853e-05]]]}\n",
       "    )\n",
       "    </script>"
      ],
      "text/plain": [
       "<circuitsvis.utils.render.RenderedHTML at 0x7fa229323810>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if IN_GITHUB:\n",
    "    torch.manual_seed(50)\n",
    "    \n",
    "induction_head_layer = 5\n",
    "induction_head_index = 5\n",
    "size = (1, 20)\n",
    "input_tensor = torch.randint(1000, 10000, size)\n",
    "\n",
    "single_random_sequence = input_tensor.to(model.cfg.device)\n",
    "repeated_random_sequence = einops.repeat(single_random_sequence, \"batch seq_len -> batch (2 seq_len)\")\n",
    "def visualize_pattern_hook(\n",
    "    pattern: Float[torch.Tensor, \"batch head_index dest_pos source_pos\"],\n",
    "    hook: HookPoint,\n",
    "):\n",
    "    display(\n",
    "        cv.attention.attention_patterns(\n",
    "            tokens=model.to_str_tokens(repeated_random_sequence), \n",
    "            attention=pattern[0, induction_head_index, :, :][None, :, :] # Add a dummy axis, as CircuitsVis expects 3D patterns.\n",
    "        )\n",
    "    )\n",
    "\n",
    "model.run_with_hooks(\n",
    "    repeated_random_sequence, \n",
    "    return_type=None, \n",
    "    fwd_hooks=[(\n",
    "        utils.get_act_name(\"pattern\", induction_head_layer), \n",
    "        visualize_pattern_hook\n",
    "    )]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Available Models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TransformerLens comes with over 40 open source models available, all of which can be loaded into a consistent(-ish) architecture by just changing the name in `from_pretrained`. The open source models available are [documented here](https://dynalist.io/d/n2ZWtnoYHrU1s4vnFSAQ519J#z=jHj79Pj58cgJKdq4t-ygK-4h), and a set of interpretability friendly models I've trained are [documented here](https://dynalist.io/d/n2ZWtnoYHrU1s4vnFSAQ519J#z=NCJ6zH_Okw_mUYAwGnMKsj2m), including a set of toy language models (tiny one to four layer models) and a set of [SoLU models](https://dynalist.io/d/n2ZWtnoYHrU1s4vnFSAQ519J#z=FZ5W6GGcy6OitPEaO733JLqf) up to GPT-2 Medium size (300M parameters). You can see [a table of the official alias and hyper-parameters of available models here](https://github.com/neelnanda-io/TransformerLens/blob/main/transformer_lens/model_properties_table.md).\n",
    "\n",
    "**Note:** TransformerLens does not currently support multi-GPU models (which you want for models above eg 7B parameters), but this feature is coming soon!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Notably, this means that analysis can be near immediately re-run on a different model by just changing the name - to see this, let's load in DistilGPT-2 (a distilled version of GPT-2, with half as many layers) and copy the code from above to see the induction heads in that model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-08T19:27:53.286637Z",
     "iopub.status.busy": "2023-11-08T19:27:53.286302Z",
     "iopub.status.idle": "2023-11-08T19:27:58.798669Z",
     "shell.execute_reply": "2023-11-08T19:27:58.798070Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "889c5a207cf84320901b82d7bd112f15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/353M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b63f83f988a497f88b2b8db0ef47f37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)neration_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c1336468ece475bb714c80840747c1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93a4cf0cf9a24174a497e5db90fbdc46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68770aabff654204bd6d7979864840e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model distilgpt2 into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "# NBVAL_IGNORE_OUTPUT\n",
    "distilgpt2 = HookedTransformer.from_pretrained(\"distilgpt2\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-08T19:27:58.800941Z",
     "iopub.status.busy": "2023-11-08T19:27:58.800746Z",
     "iopub.status.idle": "2023-11-08T19:27:59.432739Z",
     "shell.execute_reply": "2023-11-08T19:27:59.432161Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<html>\n",
       "<head><meta charset=\"utf-8\" /></head>\n",
       "<body>\n",
       "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
       "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.27.0.min.js\"></script>                <div id=\"0dc5f9a1-25cd-4dc7-af30-ff1cd6143c93\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"0dc5f9a1-25cd-4dc7-af30-ff1cd6143c93\")) {                    Plotly.newPlot(                        \"0dc5f9a1-25cd-4dc7-af30-ff1cd6143c93\",                        [{\"coloraxis\":\"coloraxis\",\"name\":\"0\",\"z\":[[0.00998459942638874,0.00014555981033481658,0.012300093658268452,9.96930702967802e-06,0.0007246987079270184,4.2035553633468226e-06,0.008510122075676918,0.0014515439979732037,0.008438280783593655,0.009648575447499752,0.009056072682142258,0.01591639779508114],[0.0029697734862565994,0.017574621364474297,0.0024383484851568937,0.0004495510074775666,0.01094857882708311,0.0024267849512398243,0.004788636229932308,0.015967920422554016,0.003931479994207621,0.0001406195806339383,0.003920864313840866,0.014955424703657627],[0.009679251350462437,0.006199609022587538,0.01178062055259943,0.0005207734648138285,0.0197052750736475,0.004671586211770773,0.00936899334192276,0.0014363249065354466,0.018905017524957657,0.010959959588944912,0.022099163383245468,8.394606759937542e-14],[0.005788436159491539,0.23364385962486267,0.8722413778305054,0.014305605553090572,0.015083324164152145,0.013674774207174778,0.01962290331721306,0.19541732966899872,0.012265807949006557,0.01505474653095007,0.9431197643280029,0.5002055168151855],[0.2943033277988434,0.22552555799484253,0.08934114873409271,0.010008173994719982,0.08585895597934723,0.024682041257619858,0.6557498574256897,0.023417195305228233,0.06784666329622269,0.6663640141487122,0.015886250883340836,0.05631893128156662],[0.0199909545481205,0.08244994282722473,0.052617836743593216,0.009173732250928879,0.03011278249323368,0.18509402871131897,0.07582318037748337,0.0987425148487091,0.007136003579944372,0.4698672294616699,0.1839050054550171,0.027220269665122032]],\"type\":\"heatmap\",\"xaxis\":\"x\",\"yaxis\":\"y\",\"hovertemplate\":\"Head: %{x}\\u003cbr\\u003eLayer: %{y}\\u003cbr\\u003ecolor: %{z}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"scaleanchor\":\"y\",\"constrain\":\"domain\",\"title\":{\"text\":\"Head\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"autorange\":\"reversed\",\"constrain\":\"domain\",\"title\":{\"text\":\"Layer\"}},\"coloraxis\":{\"colorscale\":[[0.0,\"rgb(103,0,31)\"],[0.1,\"rgb(178,24,43)\"],[0.2,\"rgb(214,96,77)\"],[0.3,\"rgb(244,165,130)\"],[0.4,\"rgb(253,219,199)\"],[0.5,\"rgb(247,247,247)\"],[0.6,\"rgb(209,229,240)\"],[0.7,\"rgb(146,197,222)\"],[0.8,\"rgb(67,147,195)\"],[0.9,\"rgb(33,102,172)\"],[1.0,\"rgb(5,48,97)\"]],\"cmid\":0.0},\"title\":{\"text\":\"Induction Score by Head in Distil GPT-2\"}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('0dc5f9a1-25cd-4dc7-af30-ff1cd6143c93');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                            </script>        </div>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# We make a tensor to store the induction score for each head. We put it on the model's device to avoid needing to move things between the GPU and CPU, which can be slow.\n",
    "distilgpt2_induction_score_store = torch.zeros((distilgpt2.cfg.n_layers, distilgpt2.cfg.n_heads), device=distilgpt2.cfg.device)\n",
    "def induction_score_hook(\n",
    "    pattern: Float[torch.Tensor, \"batch head_index dest_pos source_pos\"],\n",
    "    hook: HookPoint,\n",
    "):\n",
    "    # We take the diagonal of attention paid from each destination position to source positions seq_len-1 tokens back\n",
    "    # (This only has entries for tokens with index>=seq_len)\n",
    "    induction_stripe = pattern.diagonal(dim1=-2, dim2=-1, offset=1-seq_len)\n",
    "    # Get an average score per head\n",
    "    induction_score = einops.reduce(induction_stripe, \"batch head_index position -> head_index\", \"mean\")\n",
    "    # Store the result.\n",
    "    distilgpt2_induction_score_store[hook.layer(), :] = induction_score\n",
    "\n",
    "# We make a boolean filter on activation names, that's true only on attention pattern names.\n",
    "pattern_hook_names_filter = lambda name: name.endswith(\"pattern\")\n",
    "\n",
    "distilgpt2.run_with_hooks(\n",
    "    repeated_tokens, \n",
    "    return_type=None, # For efficiency, we don't need to calculate the logits\n",
    "    fwd_hooks=[(\n",
    "        pattern_hook_names_filter,\n",
    "        induction_score_hook\n",
    "    )]\n",
    ")\n",
    "\n",
    "imshow(distilgpt2_induction_score_store, xaxis=\"Head\", yaxis=\"Layer\", title=\"Induction Score by Head in Distil GPT-2\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### An overview of the important open source models in the library\n",
    "\n",
    "* **GPT-2** - the classic generative pre-trained models from OpenAI\n",
    "    * Sizes Small (85M), Medium (300M), Large (700M) and XL (1.5B).\n",
    "    * Trained on ~22B tokens of internet text. ([Open source replication](https://huggingface.co/datasets/openwebtext))\n",
    "* **GPT-Neo** - Eleuther's replication of GPT-2\n",
    "    * Sizes 125M, 1.3B, 2.7B\n",
    "    * Trained on 300B(ish?) tokens of [the Pile](https://pile.eleuther.ai/) a large and diverse dataset including a bunch of code (and weird stuff)\n",
    "* **[OPT](https://ai.facebook.com/blog/democratizing-access-to-large-scale-language-models-with-opt-175b/)** - Meta AI's series of open source models\n",
    "    * Trained on 180B tokens of diverse text.\n",
    "    * 125M, 1.3B, 2.7B, 6.7B, 13B, 30B, 66B\n",
    "* **GPT-J** - Eleuther's 6B parameter model, trained on the Pile\n",
    "* **GPT-NeoX** - Eleuther's 20B parameter model, trained on the Pile\n",
    "* **StableLM** - Stability AI's 3B and 7B models, with and without chat and instruction fine-tuning\n",
    "* **Stanford CRFM models** - a replication of GPT-2 Small and GPT-2 Medium, trained on 5 different random seeds.\n",
    "    * Notably, 600 checkpoints were taken during training per model, and these are available in the library with eg `HookedTransformer.from_pretrained(\"stanford-gpt2-small-a\", checkpoint_index=265)`.\n",
    "- **BERT** - Google's bidirectional encoder-only transformer.\n",
    "    - Size Base (108M), trained on English Wikipedia and BooksCorpus.\n",
    " \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### An overview of some interpretability-friendly models I've trained and included\n",
    "\n",
    "(Feel free to [reach out](mailto:neelnanda27@gmail.com) if you want more details on any of these models)\n",
    "\n",
    "Each of these models has about ~200 checkpoints taken during training that can also be loaded from TransformerLens, with the `checkpoint_index` argument to `from_pretrained`.\n",
    "\n",
    "Note that all models are trained with a Beginning of Sequence token, and will likely break if given inputs without that! \n",
    "\n",
    "* **Toy Models**: Inspired by [A Mathematical Framework](https://transformer-circuits.pub/2021/framework/index.html), I've trained 12 tiny language models, of 1-4L and each of width 512. I think that interpreting these is likely to be far more tractable than larger models, and both serve as good practice and will likely contain motifs and circuits that generalise to far larger models (like induction heads):\n",
    "    * Attention-Only models (ie without MLPs): attn-only-1l, attn-only-2l, attn-only-3l, attn-only-4l\n",
    "    * GELU models (ie with MLP, and the standard GELU activations): gelu-1l, gelu-2l, gelu-3l, gelu-4l\n",
    "    * SoLU models (ie with MLP, and [Anthropic's SoLU activation](https://transformer-circuits.pub/2022/solu/index.html), designed to make MLP neurons more interpretable): solu-1l, solu-2l, solu-3l, solu-4l\n",
    "    * All models are trained on 22B tokens of data, 80% from C4 (web text) and 20% from Python Code\n",
    "    * Models of the same layer size were trained with the same weight initialization and data shuffle, to more directly compare the effect of different activation functions.\n",
    "* **SoLU** models: A larger scan of models trained with [Anthropic's SoLU activation](https://transformer-circuits.pub/2022/solu/index.html), in the hopes that it makes the MLP neuron interpretability easier. \n",
    "    * A scan up to GPT-2 Medium size, trained on 30B tokens of the same data as toy models, 80% from C4 and 20% from Python code. \n",
    "        * solu-6l (40M), solu-8l (100M), solu-10l (200M), solu-12l (340M)\n",
    "    * An older scan up to GPT-2 Medium size, trained on 15B tokens of [the Pile](https://pile.eleuther.ai/)\n",
    "        * solu-1l-pile (13M), solu-2l-pile (13M), solu-4l-pile (13M), solu-6l-pile (40M), solu-8l-pile (100M), solu-10l-pile (200M), solu-12l-pile (340M)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Resources:\n",
    "\n",
    "* [Concrete Steps to Get Started in Mechanistic Interpretability](https://neelnanda.io/getting-started): A guide I wrote for how to get involved in mechanistic interpretability, and how to learn the basic skills\n",
    "* [A Comprehensive Mechanistic Interpretability Explainer](https://neelnanda.io/glossary): An overview of concepts in the field and surrounding ideas in ML and transformers, with long digressions to give context and build intuitions.\n",
    "* [Concrete Open Problems in Mechanistic Interpretability](https://neelnanda.io/concrete-open-problems), a doc I wrote giving a long list of open problems in mechanistic interpretability, and thoughts on how to get started on trying to work on them. \n",
    "    * There's a lot of low-hanging fruit in the field, and I expect that many people reading this could use TransformerLens to usefully make progress on some of these!\n",
    "* Other demos:\n",
    "    * **[Exploratory Analysis Demo](https://neelnanda.io/exploratory-analysis-demo)**, a demonstration of my standard toolkit for how to use TransformerLens to explore a mysterious behaviour in a language model.\n",
    "    * [Interpretability in the Wild](https://github.com/redwoodresearch/Easy-Transformer) a codebase from Arthur Conmy and Alex Variengien at Redwood research using this library to do a detailed and rigorous reverse engineering of the Indirect Object Identification circuit, to accompany their paper\n",
    "        * Note - this was based on an earlier version of this library, called EasyTransformer. It's pretty similar, but several breaking changes have been made since. \n",
    "    * A [recorded walkthrough](https://www.youtube.com/watch?v=yo4QvDn-vsU) of me doing research with TransformerLens on whether a tiny model can re-derive positional information, with [an accompanying Colab](https://colab.research.google.com/github/neelnanda-io/TransformerLens/blob/main/No_Position_Experiment.ipynb)\n",
    "* [Neuroscope](https://neuroscope.io), a website showing the text in the dataset that most activates each neuron in some selected models. Good to explore to get a sense for what kind of features the model tends to represent, and as a \"wiki\" to get some info\n",
    "    * A tutorial on how to make an [Interactive Neuroscope](https://github.com/neelnanda-io/TransformerLens/blob/main/Hacky-Interactive-Lexoscope.ipynb), where you type in text and see the neuron activations over the text update live."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformer architecture\n",
    "\n",
    "HookedTransformer is a somewhat adapted GPT-2 architecture, but is computationally identical. The most significant changes are to the internal structure of the attention heads: \n",
    "* The weights (W_K, W_Q, W_V) mapping the residual stream to queries, keys and values are 3 separate matrices, rather than big concatenated one.\n",
    "* The weight matrices (W_K, W_Q, W_V, W_O) and activations (keys, queries, values, z (values mixed by attention pattern)) have separate head_index and d_head axes, rather than flattening them into one big axis.\n",
    "    * The activations all have shape `[batch, position, head_index, d_head]`\n",
    "    * W_K, W_Q, W_V have shape `[head_index, d_model, d_head]` and W_O has shape `[head_index, d_head, d_model]`\n",
    "\n",
    "The actual code is a bit of a mess, as there's a variety of Boolean flags to make it consistent with the various different model families in TransformerLens - to understand it and the internal structure, I instead recommend reading the code in [CleanTransformerDemo](https://colab.research.google.com/github/neelnanda-io/TransformerLens/blob/clean-transformer-demo/Clean_Transformer_Demo.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter Names\n",
    "\n",
    "Here is a list of the parameters and shapes in the model. By convention, all weight matrices multiply on the right (ie `new_activation = old_activation @ weights + bias`). \n",
    "\n",
    "Reminder of the key hyper-params:\n",
    "* `n_layers`: 12. The number of transformer blocks in the model (a block contains an attention layer and an MLP layer)\n",
    "* `n_heads`: 12. The number of attention heads per attention layer\n",
    "* `d_model`: 768. The residual stream width.\n",
    "* `d_head`: 64. The internal dimension of an attention head activation.\n",
    "* `d_mlp`: 3072. The internal dimension of the MLP layers (ie the number of neurons).\n",
    "* `d_vocab`: 50267. The number of tokens in the vocabulary.\n",
    "* `n_ctx`: 1024. The maximum number of tokens in an input prompt.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Transformer Block parameters:** \n",
    "Replace 0 with the relevant layer index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-08T19:27:59.435145Z",
     "iopub.status.busy": "2023-11-08T19:27:59.434806Z",
     "iopub.status.idle": "2023-11-08T19:27:59.438461Z",
     "shell.execute_reply": "2023-11-08T19:27:59.438000Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blocks.0.attn.W_Q torch.Size([12, 768, 64])\n",
      "blocks.0.attn.W_K torch.Size([12, 768, 64])\n",
      "blocks.0.attn.W_V torch.Size([12, 768, 64])\n",
      "blocks.0.attn.W_O torch.Size([12, 64, 768])\n",
      "blocks.0.attn.b_Q torch.Size([12, 64])\n",
      "blocks.0.attn.b_K torch.Size([12, 64])\n",
      "blocks.0.attn.b_V torch.Size([12, 64])\n",
      "blocks.0.attn.b_O torch.Size([768])\n",
      "blocks.0.mlp.W_in torch.Size([768, 3072])\n",
      "blocks.0.mlp.b_in torch.Size([3072])\n",
      "blocks.0.mlp.W_out torch.Size([3072, 768])\n",
      "blocks.0.mlp.b_out torch.Size([768])\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if name.startswith(\"blocks.0.\"):\n",
    "        print(name, param.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Embedding & Unembedding parameters:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-08T19:27:59.440524Z",
     "iopub.status.busy": "2023-11-08T19:27:59.440181Z",
     "iopub.status.idle": "2023-11-08T19:27:59.443916Z",
     "shell.execute_reply": "2023-11-08T19:27:59.443451Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embed.W_E torch.Size([50257, 768])\n",
      "pos_embed.W_pos torch.Size([1024, 768])\n",
      "unembed.W_U torch.Size([768, 50257])\n",
      "unembed.b_U torch.Size([50257])\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if not name.startswith(\"blocks\"):\n",
    "        print(name, param.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation + Hook Names\n",
    "\n",
    "Lets get out a list of the activation/hook names in the model and their shapes. In practice, I recommend using the `utils.get_act_name` function to get the names, but this is a useful fallback, and necessary to eg write a name filter function.\n",
    "\n",
    "Let's do this by entering in a short, 10 token prompt, and add a hook function to each activations to print its name and shape. To avoid spam, let's just add this to activations in the first block or not in a block.\n",
    "\n",
    "Note 1: Each LayerNorm has a hook for the scale factor (ie the standard deviation of the input activations for each token position & batch element) and for the normalized output (ie the input activation with mean 0 and standard deviation 1, but *before* applying scaling or translating with learned weights). LayerNorm is applied every time a layer reads from the residual stream: `ln1` is the LayerNorm before the attention layer in a block, `ln2` the one before the MLP layer, and `ln_final` is the LayerNorm before the unembed. \n",
    "\n",
    "Note 2: *Every* activation apart from the attention pattern and attention scores has shape beginning with `[batch, position]`. The attention pattern and scores have shape `[batch, head_index, dest_position, source_position]` (the numbers are the same, unless we're using caching)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-08T19:27:59.445912Z",
     "iopub.status.busy": "2023-11-08T19:27:59.445549Z",
     "iopub.status.idle": "2023-11-08T19:27:59.511696Z",
     "shell.execute_reply": "2023-11-08T19:27:59.511097Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num tokens: 10\n",
      "hook_embed torch.Size([1, 10, 768])\n",
      "hook_pos_embed torch.Size([1, 10, 768])\n",
      "blocks.0.hook_resid_pre torch.Size([1, 10, 768])\n",
      "blocks.0.ln1.hook_scale torch.Size([1, 10, 1])\n",
      "blocks.0.ln1.hook_normalized torch.Size([1, 10, 768])\n",
      "blocks.0.ln1.hook_scale torch.Size([1, 10, 1])\n",
      "blocks.0.ln1.hook_normalized torch.Size([1, 10, 768])\n",
      "blocks.0.ln1.hook_scale torch.Size([1, 10, 1])\n",
      "blocks.0.ln1.hook_normalized torch.Size([1, 10, 768])\n",
      "blocks.0.attn.hook_q torch.Size([1, 10, 12, 64])\n",
      "blocks.0.attn.hook_k torch.Size([1, 10, 12, 64])\n",
      "blocks.0.attn.hook_v torch.Size([1, 10, 12, 64])\n",
      "blocks.0.attn.hook_attn_scores torch.Size([1, 12, 10, 10])\n",
      "blocks.0.attn.hook_pattern torch.Size([1, 12, 10, 10])\n",
      "blocks.0.attn.hook_z torch.Size([1, 10, 12, 64])\n",
      "blocks.0.hook_attn_out torch.Size([1, 10, 768])\n",
      "blocks.0.hook_resid_mid torch.Size([1, 10, 768])\n",
      "blocks.0.ln2.hook_scale torch.Size([1, 10, 1])\n",
      "blocks.0.ln2.hook_normalized torch.Size([1, 10, 768])\n",
      "blocks.0.mlp.hook_pre torch.Size([1, 10, 3072])\n",
      "blocks.0.mlp.hook_post torch.Size([1, 10, 3072])\n",
      "blocks.0.hook_mlp_out torch.Size([1, 10, 768])\n",
      "blocks.0.hook_resid_post torch.Size([1, 10, 768])\n",
      "ln_final.hook_scale torch.Size([1, 10, 1])\n",
      "ln_final.hook_normalized torch.Size([1, 10, 768])\n"
     ]
    }
   ],
   "source": [
    "test_prompt = \"The quick brown fox jumped over the lazy dog\"\n",
    "print(\"Num tokens:\", len(model.to_tokens(test_prompt)[0]))\n",
    "\n",
    "def print_name_shape_hook_function(activation, hook):\n",
    "    print(hook.name, activation.shape)\n",
    "\n",
    "not_in_late_block_filter = lambda name: name.startswith(\"blocks.0.\") or not name.startswith(\"blocks\")\n",
    "\n",
    "model.run_with_hooks(\n",
    "    test_prompt,\n",
    "    return_type=None,\n",
    "    fwd_hooks=[(not_in_late_block_filter, print_name_shape_hook_function)],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Folding LayerNorm (For the Curious)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(For the curious - this is an important technical detail that's worth understanding, especially if you have preconceptions about how transformers work, but not necessary to use TransformerLens)\n",
    "\n",
    "LayerNorm is a normalization technique used by transformers, analogous to BatchNorm but more friendly to massive parallelisation. No one *really* knows why it works, but it seems to improve model numerical stability. Unlike BatchNorm, LayerNorm actually changes the functional form of the model, which makes it a massive pain for interpretability! \n",
    "\n",
    "Folding LayerNorm is a technique to make it lower overhead to deal with, and the flags `center_writing_weights` and `fold_ln` in `HookedTransformer.from_pretrained` apply this automatically (they default to True). These simplify the internal structure without changing the weights.\n",
    "\n",
    "Intuitively, LayerNorm acts on each residual stream vector (ie for each batch element and token position) independently, sets their mean to 0 (centering) and standard deviation to 1 (normalizing) (*across* the residual stream dimension - very weird!), and then applies a learned elementwise scaling and translation to each vector.\n",
    "\n",
    "Mathematically, centering is a linear map, normalizing is *not* a linear map, and scaling and translation are linear maps. \n",
    "* **Centering:** LayerNorm is applied every time a layer reads from the residual stream, so the mean of any residual stream vector can never matter - `center_writing_weights` set every weight matrix writing to the residual to have zero mean. \n",
    "* **Normalizing:** Normalizing is not a linear map, and cannot be factored out. The `hook_scale` hook point lets you access and control for this.\n",
    "* **Scaling and Translation:** Scaling and translation are linear maps, and are always followed by another linear map. The composition of two linear maps is another linear map, so we can *fold* the scaling and translation weights into the weights of the subsequent layer, and simplify things without changing the underlying computation. \n",
    "\n",
    "[See the docs for more details](https://github.com/neelnanda-io/TransformerLens/blob/main/further_comments.md#what-is-layernorm-folding-fold_ln)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A fun consequence of LayerNorm folding is that it creates a bias across the unembed, a `d_vocab` length vector that is added to the output logits - GPT-2 is not trained with this, but it *is* trained with a final LayerNorm that contains a bias. \n",
    "\n",
    "Turns out, this LayerNorm bias learns structure of the data that we can only see after folding! In particular, it essentially learns **unigram statistics** - rare tokens get suppressed, common tokens get boosted, by pretty dramatic degrees! Let's list the top and bottom 20 - at the top we see common punctuation and words like \" the\" and \" and\", at the bottom we see weird-ass tokens like \" RandomRedditor\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-08T19:27:59.514103Z",
     "iopub.status.busy": "2023-11-08T19:27:59.513710Z",
     "iopub.status.idle": "2023-11-08T19:27:59.521198Z",
     "shell.execute_reply": "2023-11-08T19:27:59.520653Z"
    }
   },
   "outputs": [],
   "source": [
    "unembed_bias = model.unembed.b_U\n",
    "bias_values, bias_indices = unembed_bias.sort(descending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-08T19:27:59.523223Z",
     "iopub.status.busy": "2023-11-08T19:27:59.522996Z",
     "iopub.status.idle": "2023-11-08T19:27:59.529599Z",
     "shell.execute_reply": "2023-11-08T19:27:59.529050Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 values\n",
      "7.03 ','\n",
      "6.98 ' the'\n",
      "6.68 ' and'\n",
      "6.49 '.'\n",
      "6.48 '\\n'\n",
      "6.47 ' a'\n",
      "6.41 ' in'\n",
      "6.25 ' to'\n",
      "6.16 ' of'\n",
      "6.04 '-'\n",
      "6.03 ' ('\n",
      "5.88 ' \"'\n",
      "5.80 ' for'\n",
      "5.72 ' that'\n",
      "5.64 ' on'\n",
      "5.59 ' is'\n",
      "5.52 ' as'\n",
      "5.49 ' at'\n",
      "5.45 ' with'\n",
      "5.44 ' or'\n",
      "...\n",
      "Bottom 20 values\n",
      "-3.82 ' サーティ'\n",
      "-3.83 '\\x18'\n",
      "-3.83 '\\x14'\n",
      "-3.83 ' RandomRedditor'\n",
      "-3.83 '龍�'\n",
      "-3.83 '�'\n",
      "-3.83 '\\x1b'\n",
      "-3.83 '�'\n",
      "-3.83 '\\x05'\n",
      "-3.83 '\\x00'\n",
      "-3.83 '\\x06'\n",
      "-3.83 '\\x07'\n",
      "-3.83 '\\x0c'\n",
      "-3.83 '\\x02'\n",
      "-3.83 'oreAndOnline'\n",
      "-3.84 '\\x11'\n",
      "-3.84 '�'\n",
      "-3.84 '\\x10'\n",
      "-3.84 '�'\n",
      "-3.84 '�'\n"
     ]
    }
   ],
   "source": [
    "top_k = 20\n",
    "print(f\"Top {top_k} values\")\n",
    "for i in range(top_k):\n",
    "    print(f\"{bias_values[i].item():.2f} {repr(model.to_string(bias_indices[i]))}\")\n",
    "\n",
    "print(\"...\")\n",
    "print(f\"Bottom {top_k} values\")\n",
    "for i in range(top_k, 0, -1):\n",
    "    print(f\"{bias_values[-i].item():.2f} {repr(model.to_string(bias_indices[-i]))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can have real consequences for interpretability - for example, this bias favours \" John\" over \" Mary\" by about 1.2, about 1/3 of the effect size of the Indirect Object Identification Circuit! All other things being the same, this makes the John token 3.6x times more likely than the Mary token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-08T19:27:59.531808Z",
     "iopub.status.busy": "2023-11-08T19:27:59.531485Z",
     "iopub.status.idle": "2023-11-08T19:27:59.535707Z",
     "shell.execute_reply": "2023-11-08T19:27:59.535139Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "John bias: 2.8995\n",
      "Mary bias: 1.6034\n",
      "Prob ratio bias: 3.6550x\n"
     ]
    }
   ],
   "source": [
    "john_bias = model.unembed.b_U[model.to_single_token(' John')]\n",
    "mary_bias = model.unembed.b_U[model.to_single_token(' Mary')]\n",
    "\n",
    "print(f\"John bias: {john_bias.item():.4f}\")\n",
    "print(f\"Mary bias: {mary_bias.item():.4f}\")\n",
    "print(f\"Prob ratio bias: {torch.exp(john_bias - mary_bias).item():.4f}x\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features\n",
    "\n",
    "An overview of some other important features of the library. I recommend checking out the [Exploratory Analysis Demo](https://colab.research.google.com/github/neelnanda-io/Easy-Transformer/blob/main/Exploratory_Analysis_Demo.ipynb) for some other important features not mentioned here, and for a demo of what using the library in practice looks like."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with tokens\n",
    "\n",
    "**Tokenization** is one of the most annoying features of studying language models. We want language models to be able to take in arbitrary text as input, but the transformer architecture needs the inputs to be elements of a fixed, finite vocabulary. The solution to this is **tokens**, a fixed vocabulary of \"sub-words\", that any natural language can be broken down into with a **tokenizer**. This is invertible, and we can recover the original text, called **de-tokenization**. \n",
    "\n",
    "TransformerLens comes with a range of utility functions to deal with tokenization. Different models can have different tokenizers, so these are all methods on the model.\n",
    "\n",
    "get_token_position, to_tokens, to_string, to_str_tokens, prepend_bos, to_single_token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing you need to figure out is *how* things are tokenized. `model.to_str_tokens` splits a string into the tokens *as a list of substrings*, and so lets you explore what the text looks like. To demonstrate this, let's use it on this paragraph.\n",
    "\n",
    "Some observations - there are a lot of arbitrary-ish details in here!\n",
    "* The tokenizer splits on spaces, so no token contains two words.\n",
    "* Tokens include the preceding space, and whether the first token is a capital letter. `how` and ` how` are different tokens!\n",
    "* Common words are single tokens, even if fairly long (` paragraph`) while uncommon words are split into multiple tokens (` token|ized`).\n",
    "* Tokens *mostly* split on punctuation characters (eg `*` and `.`), but eg `'s` is a single token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-08T19:27:59.537832Z",
     "iopub.status.busy": "2023-11-08T19:27:59.537443Z",
     "iopub.status.idle": "2023-11-08T19:27:59.541543Z",
     "shell.execute_reply": "2023-11-08T19:27:59.541004Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<|endoftext|>', 'The', ' first', ' thing', ' you', ' need', ' to', ' figure', ' out', ' is', ' *', 'how', '*', ' things', ' are', ' token', 'ized', '.', ' `', 'model', '.', 'to', '_', 'str', '_', 't', 'ok', 'ens', '`', ' splits', ' a', ' string', ' into', ' the', ' tokens', ' *', 'as', ' a', ' list', ' of', ' sub', 'strings', '*,', ' and', ' so', ' lets', ' you', ' explore', ' what', ' the', ' text', ' looks', ' like', '.', ' To', ' demonstrate', ' this', ',', ' let', \"'s\", ' use', ' it', ' on', ' this', ' paragraph', '.']\n"
     ]
    }
   ],
   "source": [
    "example_text = \"The first thing you need to figure out is *how* things are tokenized. `model.to_str_tokens` splits a string into the tokens *as a list of substrings*, and so lets you explore what the text looks like. To demonstrate this, let's use it on this paragraph.\"\n",
    "example_text_str_tokens = model.to_str_tokens(example_text)\n",
    "print(example_text_str_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The transformer needs to take in a sequence of integers, not strings, so we need to convert these tokens into integers. `model.to_tokens` does this, and returns a tensor of integers on the model's device (shape `[batch, position]`). It maps a string to a batch of size 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-08T19:27:59.543513Z",
     "iopub.status.busy": "2023-11-08T19:27:59.543196Z",
     "iopub.status.idle": "2023-11-08T19:27:59.546764Z",
     "shell.execute_reply": "2023-11-08T19:27:59.546199Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[50256,   464,   717,  1517,   345,   761,   284,  3785,   503,   318,\n",
      "          1635,  4919,     9,  1243,   389, 11241,  1143,    13,  4600, 19849,\n",
      "            13,  1462,    62,  2536,    62,    83,   482,   641,    63, 30778,\n",
      "           257,  4731,   656,   262, 16326,  1635,   292,   257,  1351,   286,\n",
      "           850, 37336, 25666,   290,   523,  8781,   345,  7301,   644,   262,\n",
      "          2420,  3073,   588,    13,  1675, 10176,   428,    11,  1309,   338,\n",
      "           779,   340,   319,   428,  7322,    13]])\n"
     ]
    }
   ],
   "source": [
    "example_text_tokens = model.to_tokens(example_text)\n",
    "print(example_text_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`to_tokens` can also take in a list of strings, and return a batch of size `len(strings)`. If the strings are different numbers of tokens, it adds a PAD token to the end of the shorter strings to make them the same length.\n",
    "\n",
    "(Note: In GPT-2, 50256 signifies both the beginning of sequence, end of sequence and padding token - see the `prepend_bos` section for details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-08T19:27:59.548825Z",
     "iopub.status.busy": "2023-11-08T19:27:59.548441Z",
     "iopub.status.idle": "2023-11-08T19:27:59.552043Z",
     "shell.execute_reply": "2023-11-08T19:27:59.551497Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[50256,   464,  3797,  3332,   319,   262,  2603,    13, 50256, 50256],\n",
      "        [50256,   464,  3797,  3332,   319,   262,  2603,  1107,  1327,    13]])\n"
     ]
    }
   ],
   "source": [
    "example_multi_text = [\"The cat sat on the mat.\", \"The cat sat on the mat really hard.\"]\n",
    "example_multi_text_tokens = model.to_tokens(example_multi_text)\n",
    "print(example_multi_text_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`model.to_single_token` is a convenience function that takes in a string corresponding to a *single* token and returns the corresponding integer. This is useful for eg looking up the logit corresponding to a single token. \n",
    "\n",
    "For example, let's input `The cat sat on the mat.` to GPT-2, and look at the log prob predicting that the next token is ` The`. \n",
    "\n",
    "<details><summary>Technical notes</summary>\n",
    "\n",
    "Note that if we input a string to the model, it's implicitly converted to a string with `to_tokens`. \n",
    "\n",
    "Note further that the log probs have shape `[batch, position, d_vocab]==[1, 8, 50257]`, with a vector of log probs predicting the next token for *every* token position. GPT-2 uses causal attention which means heads can only look backwards (equivalently, information can only move forwards in the model.), so the log probs at position k are only a function of the first k tokens, and it can't just cheat and look at the k+1 th token. This structure lets it generate text more efficiently, and lets it treat every *token* as a training example, rather than every *sequence*.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-08T19:27:59.553969Z",
     "iopub.status.busy": "2023-11-08T19:27:59.553804Z",
     "iopub.status.idle": "2023-11-08T19:27:59.632587Z",
     "shell.execute_reply": "2023-11-08T19:27:59.632070Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability tensor shape [batch, position, d_vocab] == torch.Size([1, 8, 50257])\n",
      "| The| probability: 11.98%\n"
     ]
    }
   ],
   "source": [
    "cat_text = \"The cat sat on the mat.\"\n",
    "cat_logits = model(cat_text)\n",
    "cat_probs = cat_logits.softmax(dim=-1)\n",
    "print(f\"Probability tensor shape [batch, position, d_vocab] == {cat_probs.shape}\")\n",
    "\n",
    "capital_the_token_index = model.to_single_token(\" The\")\n",
    "print(f\"| The| probability: {cat_probs[0, -1, capital_the_token_index].item():.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`model.to_string` is the inverse of `to_tokens` and maps a tensor of integers to a string or list of strings. It also works on integers and lists of integers.\n",
    "\n",
    "For example, let's look up token 256 (due to technical details of tokenization, this will be the most common pair of ASCII characters!), and also verify that our tokens above map back to a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-08T19:27:59.635019Z",
     "iopub.status.busy": "2023-11-08T19:27:59.634602Z",
     "iopub.status.idle": "2023-11-08T19:27:59.638311Z",
     "shell.execute_reply": "2023-11-08T19:27:59.637851Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token 256 - the most common pair of ASCII characters: | t|\n",
      "De-Tokenizing the example tokens: <|endoftext|>The first thing you need to figure out is *how* things are tokenized. `model.to_str_tokens` splits a string into the tokens *as a list of substrings*, and so lets you explore what the text looks like. To demonstrate this, let's use it on this paragraph.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Token 256 - the most common pair of ASCII characters: |{model.to_string(256)}|\")\n",
    "# Squeeze means to remove dimensions of length 1. \n",
    "# Here, that removes the dummy batch dimension so it's a rank 1 tensor and returns a string\n",
    "# Rank 2 tensors map to a list of strings\n",
    "print(f\"De-Tokenizing the example tokens: {model.to_string(example_text_tokens.squeeze())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A related annoyance of tokenization is that it's hard to figure out how many tokens a string will break into. `model.get_token_position(single_token, tokens)` returns the position of `single_token` in `tokens`. `tokens` can be either a string or a tensor of tokens. \n",
    "\n",
    "Note that position is zero-indexed, it's two (ie third) because there's a beginning of sequence token automatically prepended (see the next section for details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-08T19:27:59.640153Z",
     "iopub.status.busy": "2023-11-08T19:27:59.639990Z",
     "iopub.status.idle": "2023-11-08T19:27:59.644775Z",
     "shell.execute_reply": "2023-11-08T19:27:59.644211Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With BOS: 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without BOS: 1\n"
     ]
    }
   ],
   "source": [
    "print(\"With BOS:\", model.get_token_position(\" cat\", \"The cat sat on the mat\"))\n",
    "print(\"Without BOS:\", model.get_token_position(\" cat\", \"The cat sat on the mat\", prepend_bos=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If there are multiple copies of the token, we can set `mode=\"first\"` to find the first occurence's position and `mode=\"last\"` to find the last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-08T19:27:59.646648Z",
     "iopub.status.busy": "2023-11-08T19:27:59.646487Z",
     "iopub.status.idle": "2023-11-08T19:27:59.651238Z",
     "shell.execute_reply": "2023-11-08T19:27:59.650782Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First occurence 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final occurence 13\n"
     ]
    }
   ],
   "source": [
    "print(\"First occurence\", model.get_token_position(\n",
    "    \" cat\", \n",
    "    \"The cat sat on the mat. The mat sat on the cat.\", \n",
    "    mode=\"first\"))\n",
    "print(\"Final occurence\", model.get_token_position(\n",
    "    \" cat\", \n",
    "    \"The cat sat on the mat. The mat sat on the cat.\", \n",
    "    mode=\"last\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, tokenization is a pain, and full of gotchas. I highly recommend just playing around with different inputs and their tokenization and getting a feel for it. As another \"fun\" example, let's look at the tokenization of arithmetic expressions - tokens do *not* contain consistent numbers of digits. (This makes it even more impressive that GPT-3 can do arithmetic!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-08T19:27:59.653193Z",
     "iopub.status.busy": "2023-11-08T19:27:59.652876Z",
     "iopub.status.idle": "2023-11-08T19:27:59.656609Z",
     "shell.execute_reply": "2023-11-08T19:27:59.656139Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<|endoftext|>', '23', '42', '+', '2017', '=', '214', '45']\n",
      "['<|endoftext|>', '1000', '+', '1', '000000', '=', '9999', '99']\n"
     ]
    }
   ],
   "source": [
    "print(model.to_str_tokens(\"2342+2017=21445\"))\n",
    "print(model.to_str_tokens(\"1000+1000000=999999\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I also *highly* recommend investigating prompts with easy tokenization when starting out - ideally key words should form a single token, be in the same position in different prompts, have the same total length, etc. Eg study Indirect Object Identification with common English names like ` Tim` rather than ` Ne|el`. Transformers need to spend some parameters in early layers converting multi-token words to a single feature, and then de-converting this in the late layers, and unless this is what you're explicitly investigating, this will make the behaviour you're investigating be messier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gotcha: `prepend_bos`\n",
    "\n",
    "Key Takeaway: **If you get weird off-by-one errors, check whether there's an unexpected `prepend_bos`!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A weirdness you may have noticed in the above is that `to_tokens` and `to_str_tokens` added a weird `<|endoftext|>` to the start of each prompt. TransformerLens does this by default, and it can easily trip up new users. Notably, **this includes `model.forward`** (which is what's implicitly used when you do eg `model(\"Hello World\")`). This is called a **Beginning of Sequence (BOS)** token, and it's a special token used to mark the beginning of the sequence. Confusingly, in GPT-2, the End of Sequence (EOS), Beginning of Sequence (BOS) and Padding (PAD) tokens are all the same, `<|endoftext|>` with index `50256`.\n",
    "\n",
    "**Gotcha:** You only want to prepend a BOS token at the *start* of a prompt. If you, eg, want to input a question followed by an answer, and want to tokenize these separately, you do *not* want to prepend_bos on the answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-08T19:27:59.658584Z",
     "iopub.status.busy": "2023-11-08T19:27:59.658266Z",
     "iopub.status.idle": "2023-11-08T19:27:59.857173Z",
     "shell.execute_reply": "2023-11-08T19:27:59.856543Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits shape by default (with BOS) torch.Size([1, 3, 50257])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits shape with BOS torch.Size([1, 3, 50257])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits shape without BOS - only 2 positions! torch.Size([1, 2, 50257])\n"
     ]
    }
   ],
   "source": [
    "print(\"Logits shape by default (with BOS)\", model(\"Hello World\").shape)\n",
    "print(\"Logits shape with BOS\", model(\"Hello World\", prepend_bos=True).shape)\n",
    "print(\"Logits shape without BOS - only 2 positions!\", model(\"Hello World\", prepend_bos=False).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`prepend_bos` is a bit of a hack, and I've gone back and forth on what the correct default here is. The reason I do this is that transformers tend to treat the first token weirdly - this doesn't really matter in training (where all inputs are >1000 tokens), but this can be a big issue when investigating short prompts! The reason for this is that attention patterns are a probability distribution and so need to add up to one, so to simulate being \"off\" they normally look at the first token. Giving them a BOS token lets the heads rest by looking at that, preserving the information in the first \"real\" token.\n",
    "\n",
    "Further, *some* models are trained to need a BOS token (OPT and my interpretability-friendly models are, GPT-2 and GPT-Neo are not). But despite GPT-2 not being trained with this, empirically it seems to make interpretability easier.\n",
    "\n",
    "(However, if you want to change the default behaviour to *not* prepending a BOS token, pass `default_prepend_bos=False` when you instantiate the model, e.g., `model = HookedTransformer.from_pretrained('gpt2', default_prepend_bos=False)`.)\n",
    "\n",
    "For example, the model can get much worse at Indirect Object Identification without a BOS (and with a name as the first token):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-08T19:27:59.859799Z",
     "iopub.status.busy": "2023-11-08T19:27:59.859421Z",
     "iopub.status.idle": "2023-11-08T19:28:00.043874Z",
     "shell.execute_reply": "2023-11-08T19:28:00.043261Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logit difference with BOS: 6.754\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logit difference without BOS: 2.782\n"
     ]
    }
   ],
   "source": [
    "ioi_logits_with_bos = model(\"Claire and Mary went to the shops, then Mary gave a bottle of milk to\", prepend_bos=True)\n",
    "mary_logit_with_bos = ioi_logits_with_bos[0, -1, model.to_single_token(\" Mary\")].item()\n",
    "claire_logit_with_bos = ioi_logits_with_bos[0, -1, model.to_single_token(\" Claire\")].item()\n",
    "print(f\"Logit difference with BOS: {(claire_logit_with_bos - mary_logit_with_bos):.3f}\")\n",
    "\n",
    "ioi_logits_without_bos = model(\"Claire and Mary went to the shops, then Mary gave a bottle of milk to\", prepend_bos=False)\n",
    "mary_logit_without_bos = ioi_logits_without_bos[0, -1, model.to_single_token(\" Mary\")].item()\n",
    "claire_logit_without_bos = ioi_logits_without_bos[0, -1, model.to_single_token(\" Claire\")].item()\n",
    "print(f\"Logit difference without BOS: {(claire_logit_without_bos - mary_logit_without_bos):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Though, note that this also illustrates another gotcha - when `Claire` is at the start of a sentence (no preceding space), it's actually *two* tokens, not one, which probably confuses the relevant circuit. (Note - in this test we put `prepend_bos=False`, because we want to analyse the tokenization of a specific string, not to give an input to the model!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-08T19:28:00.046356Z",
     "iopub.status.busy": "2023-11-08T19:28:00.045951Z",
     "iopub.status.idle": "2023-11-08T19:28:00.050024Z",
     "shell.execute_reply": "2023-11-08T19:28:00.049475Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Claire| -> [' Claire']\n",
      "|Claire| -> ['Cl', 'aire']\n"
     ]
    }
   ],
   "source": [
    "print(f\"| Claire| -> {model.to_str_tokens(' Claire', prepend_bos=False)}\")\n",
    "print(f\"|Claire| -> {model.to_str_tokens('Claire', prepend_bos=False)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Factored Matrix Class\n",
    "\n",
    "In transformer interpretability, we often need to analyse low rank factorized matrices - a matrix $M = AB$, where M is `[large, large]`, but A is `[large, small]` and B is `[small, large]`. This is a common structure in transformers, and the `FactoredMatrix` class is a convenient way to work with these. It implements efficient algorithms for various operations on these, such as computing the trace, eigenvalues, Frobenius norm, singular value decomposition, and products with other matrices. It can (approximately) act as a drop-in replacement for the original matrix, and supports leading batch dimensions to the factored matrix. \n",
    "\n",
    "<details><summary>Why are low-rank factorized matrices useful for transformer interpretability?</summary>\n",
    "\n",
    "As argued in [A Mathematical Framework](https://transformer-circuits.pub/2021/framework/index.html), an unexpected fact about transformer attention heads is that rather than being best understood as keys, queries and values (and the requisite weight matrices), they're actually best understood as two low rank factorized matrices. \n",
    "* **Where to move information from:** $W_QK = W_Q W_K^T$, used for determining the attention pattern - what source positions to move information from and what destination positions to move them to.\n",
    "    * Intuitively, residual stream -> query and residual stream -> key are linear maps, *and* `attention_score = query @ key.T` is a linear map, so the whole thing can be factored into one big bilinear form `residual @ W_QK @ residual.T`\n",
    "* **What information to move:** $W_OV = W_V W_O$, used to determine what information to copy from the source position to the destination position (weighted by the attention pattern weight from that destination to that source). \n",
    "    * Intuitively, the residual stream is a `[position, d_model]` tensor (ignoring batch). The attention pattern acts on the *position* dimension (where to move information from and to) and the value and output weights act on the *d_model* dimension - ie *what* information is contained at that source position. So we can factor it all into `attention_pattern @ residual @ W_V @ W_O`, and so only need to care about `W_OV = W_V @ W_O`\n",
    "* Note - the internal head dimension is smaller than the residual stream dimension, so the factorization is low rank. (here, `d_model=768` and `d_head=64`)\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the basic class directly - let's make a factored matrix directly and look at the basic operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-08T19:28:00.052027Z",
     "iopub.status.busy": "2023-11-08T19:28:00.051863Z",
     "iopub.status.idle": "2023-11-08T19:28:00.058014Z",
     "shell.execute_reply": "2023-11-08T19:28:00.057574Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norms:\n",
      "tensor(9.9105)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(9.9105)\n",
      "Right dimension: 5, Left dimension: 5, Hidden dimension: 2\n"
     ]
    }
   ],
   "source": [
    "if IN_GITHUB:\n",
    "    torch.manual_seed(50)\n",
    "A = torch.randn(5, 2)\n",
    "B = torch.randn(2, 5)\n",
    "\n",
    "AB = A @ B\n",
    "AB_factor = FactoredMatrix(A, B)\n",
    "print(\"Norms:\")\n",
    "print(AB.norm())\n",
    "print(AB_factor.norm())\n",
    "\n",
    "print(f\"Right dimension: {AB_factor.rdim}, Left dimension: {AB_factor.ldim}, Hidden dimension: {AB_factor.mdim}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also look at the eigenvalues and singular values of the matrix. Note that, because the matrix is rank 2 but 5 by 5, the final 3 eigenvalues and singular values are zero - the factored class omits the zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-08T19:28:00.060026Z",
     "iopub.status.busy": "2023-11-08T19:28:00.059725Z",
     "iopub.status.idle": "2023-11-08T19:28:00.064612Z",
     "shell.execute_reply": "2023-11-08T19:28:00.064075Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eigenvalues:\n",
      "tensor([-6.2877e+00+0.j,  1.8626e-09+0.j,  2.3121e+00+0.j, -8.9038e-08+0.j,\n",
      "        -4.1527e-07+0.j])\n",
      "tensor([-6.2877+0.j,  2.3121+0.j])\n",
      "\n",
      "Singular Values:\n",
      "tensor([8.3126e+00, 5.3963e+00, 2.2029e-07, 5.7690e-08, 1.2164e-08])\n",
      "tensor([8.3126, 5.3963])\n"
     ]
    }
   ],
   "source": [
    "# NBVAL_IGNORE_OUTPUT\n",
    "print(\"Eigenvalues:\")\n",
    "print(torch.linalg.eig(AB).eigenvalues)\n",
    "print(AB_factor.eigenvalues)\n",
    "print()\n",
    "print(\"Singular Values:\")\n",
    "print(torch.linalg.svd(AB).S)\n",
    "print(AB_factor.S)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can multiply with other matrices - it automatically chooses the smallest possible dimension to factor along (here it's 2, rather than 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-08T19:28:00.066587Z",
     "iopub.status.busy": "2023-11-08T19:28:00.066287Z",
     "iopub.status.idle": "2023-11-08T19:28:00.071742Z",
     "shell.execute_reply": "2023-11-08T19:28:00.071243Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unfactored: torch.Size([5, 300]) tensor(160.0830)\n",
      "Factored: torch.Size([5, 300]) tensor(160.0830)\n",
      "Right dimension: 300, Left dimension: 5, Hidden dimension: 2\n"
     ]
    }
   ],
   "source": [
    "if IN_GITHUB:\n",
    "    torch.manual_seed(50)\n",
    "    \n",
    "C = torch.randn(5, 300)\n",
    "\n",
    "ABC = AB @ C\n",
    "ABC_factor = AB_factor @ C\n",
    "print(\"Unfactored:\", ABC.shape, ABC.norm().round(decimals=3))\n",
    "print(\"Factored:\", ABC_factor.shape, ABC_factor.norm().round(decimals=3))\n",
    "print(f\"Right dimension: {ABC_factor.rdim}, Left dimension: {ABC_factor.ldim}, Hidden dimension: {ABC_factor.mdim}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to collapse this back to an unfactored matrix, we can use the AB property to get the product:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-08T19:28:00.073860Z",
     "iopub.status.busy": "2023-11-08T19:28:00.073504Z",
     "iopub.status.idle": "2023-11-08T19:28:00.077015Z",
     "shell.execute_reply": "2023-11-08T19:28:00.076482Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(True)\n"
     ]
    }
   ],
   "source": [
    "AB_unfactored = AB_factor.AB\n",
    "print(torch.isclose(AB_unfactored, AB).all())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Medium Example: Eigenvalue Copying Scores\n",
    "\n",
    "(This is a more involved example of how to use the factored matrix class, skip it if you aren't following)\n",
    "\n",
    "For a more involved example, let's look at the eigenvalue copying score from [A Mathematical Framework](https://transformer-circuits.pub/2021/framework/index.html) of the OV circuit for various heads. The OV Circuit for a head (the factorised matrix $W_OV = W_V W_O$) is a linear map that determines what information is moved from the source position to the destination position. Because this is low rank, it can be thought of as *reading in* some low rank subspace of the source residual stream and *writing to* some low rank subspace of the destination residual stream (with maybe some processing happening in the middle).\n",
    "\n",
    "A common operation for this will just be to *copy*, ie to have the same reading and writing subspace, and to do minimal processing in the middle. Empirically, this tends to coincide with the OV Circuit having (approximately) positive real eigenvalues. I mostly assert this as an empirical fact, but intuitively, operations that involve mapping eigenvectors to different directions (eg rotations) tend to have complex eigenvalues. And operations that preserve eigenvector direction but negate it tend to have negative real eigenvalues. And \"what happens to the eigenvectors\" is a decent proxy for what happens to an arbitrary vector.\n",
    "\n",
    "We can get a score for \"how positive real the OV circuit eigenvalues are\" with $\\frac{\\sum \\lambda_i}{\\sum |\\lambda_i|}$, where $\\lambda_i$ are the eigenvalues of the OV circuit. This is a bit of a hack, but it seems to work well in practice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use FactoredMatrix to compute this for every head in the model! We use the helper `model.OV` to get the concatenated OV circuits for all heads across all layers in the model. This has the shape `[n_layers, n_heads, d_model, d_model]`, where `n_layers` and `n_heads` are batch dimensions and the final two dimensions are factorised as `[n_layers, n_heads, d_model, d_head]` and `[n_layers, n_heads, d_head, d_model]` matrices.\n",
    "\n",
    "We can then get the eigenvalues for this, where there are separate eigenvalues for each element of the batch (a `[n_layers, n_heads, d_head]` tensor of complex numbers), and calculate the copying score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-08T19:28:00.079244Z",
     "iopub.status.busy": "2023-11-08T19:28:00.078857Z",
     "iopub.status.idle": "2023-11-08T19:28:00.085632Z",
     "shell.execute_reply": "2023-11-08T19:28:00.085033Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FactoredMatrix: Shape(torch.Size([12, 12, 768, 768])), Hidden Dim(64)\n"
     ]
    }
   ],
   "source": [
    "OV_circuit_all_heads = model.OV\n",
    "print(OV_circuit_all_heads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-08T19:28:00.088009Z",
     "iopub.status.busy": "2023-11-08T19:28:00.087664Z",
     "iopub.status.idle": "2023-11-08T19:28:00.198644Z",
     "shell.execute_reply": "2023-11-08T19:28:00.198040Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12, 12, 64])\n",
      "torch.complex64\n"
     ]
    }
   ],
   "source": [
    "OV_circuit_all_heads_eigenvalues = OV_circuit_all_heads.eigenvalues \n",
    "print(OV_circuit_all_heads_eigenvalues.shape)\n",
    "print(OV_circuit_all_heads_eigenvalues.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-08T19:28:00.201226Z",
     "iopub.status.busy": "2023-11-08T19:28:00.200793Z",
     "iopub.status.idle": "2023-11-08T19:28:00.230795Z",
     "shell.execute_reply": "2023-11-08T19:28:00.230235Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<html>\n",
       "<head><meta charset=\"utf-8\" /></head>\n",
       "<body>\n",
       "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
       "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.27.0.min.js\"></script>                <div id=\"787bc121-88da-418b-bece-764f177bdfda\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"787bc121-88da-418b-bece-764f177bdfda\")) {                    Plotly.newPlot(                        \"787bc121-88da-418b-bece-764f177bdfda\",                        [{\"coloraxis\":\"coloraxis\",\"name\":\"0\",\"z\":[[0.7775008678436279,0.35272663831710815,0.25961872935295105,0.6670258045196533,0.838425874710083,0.5584433078765869,0.844474732875824,0.41379114985466003,0.244889497756958,0.02815753035247326,0.3584096431732178,0.16288283467292786],[-0.4541913866996765,-0.6529324650764465,-0.5484569668769836,-0.7990368604660034,-0.7736426591873169,-0.8522582650184631,0.977432370185852,0.6626251935958862,-0.7303223609924316,-0.7007019519805908,-0.6946623921394348,-0.9996723532676697],[-0.7837162613868713,0.8967758417129517,0.4750956892967224,-0.6671973466873169,0.7881463170051575,-0.8547748923301697,-0.9054183959960938,-0.5749384760856628,-0.321751207113266,-0.0285941194742918,-0.9247617125511169,-0.9699268937110901],[0.5864036083221436,-0.76143479347229,0.5971695184707642,0.7854391932487488,-0.8788884878158569,0.3908745348453522,0.0447387658059597,0.1102800965309143,-0.8169987201690674,0.2212953418493271,-0.9939578771591187,0.5774401426315308],[0.5254791378974915,0.30490121245384216,-0.10729170590639114,0.9433152675628662,-0.9314427971839905,0.5273631811141968,-0.4264712929725647,-0.9984429478645325,0.5296757817268372,0.8604294657707214,-0.8895052075386047,0.9556970000267029],[0.6629188656806946,0.4295697808265686,0.9736858010292053,0.655548095703125,0.12201863527297974,0.7442769408226013,0.5037954449653625,0.95253586769104,-0.6507166624069214,-0.9316278100013733,0.9791510701179504,-0.9972586035728455],[0.9613031148910522,0.7501779794692993,-0.3806658983230591,0.6429785490036011,0.9557769298553467,-0.9428837895393372,-0.9948079586029053,0.7852989435195923,0.9657301306724548,0.7073014974594116,0.36872273683547974,0.8128010034561157],[0.9659482836723328,0.9730120301246643,0.31900620460510254,-0.30290529131889343,0.9790952801704407,0.9357922673225403,-0.5550314784049988,-0.0054661668837070465,0.986777663230896,0.8249568343162537,0.5664296746253967,0.1000528484582901],[-0.9464486837387085,-0.25471991300582886,0.6522327065467834,0.14152583479881287,0.9884141683578491,0.9860584735870361,0.6949271559715271,0.9901811480522156,0.9791203141212463,-0.23595543205738068,-0.982071042060852,0.6506688594818115],[0.9895945191383362,-0.291781485080719,0.9714024662971497,0.9951602220535278,0.18783727288246155,-0.9460937976837158,0.4780191481113434,-0.2489192634820938,0.9437099099159241,0.11866225302219391,0.9941242933273315,-0.38088199496269226],[0.9564487338066101,0.5542722344398499,0.42118069529533386,0.6628788113594055,0.8659593462944031,0.9937117695808411,0.9069075584411621,0.3981107473373413,-0.4134218096733093,0.9971914887428284,0.3459664583206177,0.9938657283782959],[0.5891268253326416,0.9313738942146301,0.9268401861190796,0.9993563890457153,0.6227542161941528,0.8463947772979736,0.6584343910217285,0.8423123955726624,0.2978499233722687,0.8728678822517395,0.9963143467903137,0.9867526292800903]],\"type\":\"heatmap\",\"xaxis\":\"x\",\"yaxis\":\"y\",\"hovertemplate\":\"Head: %{x}\\u003cbr\\u003eLayer: %{y}\\u003cbr\\u003ecolor: %{z}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"scaleanchor\":\"y\",\"constrain\":\"domain\",\"title\":{\"text\":\"Head\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"autorange\":\"reversed\",\"constrain\":\"domain\",\"title\":{\"text\":\"Layer\"}},\"coloraxis\":{\"colorscale\":[[0.0,\"rgb(103,0,31)\"],[0.1,\"rgb(178,24,43)\"],[0.2,\"rgb(214,96,77)\"],[0.3,\"rgb(244,165,130)\"],[0.4,\"rgb(253,219,199)\"],[0.5,\"rgb(247,247,247)\"],[0.6,\"rgb(209,229,240)\"],[0.7,\"rgb(146,197,222)\"],[0.8,\"rgb(67,147,195)\"],[0.9,\"rgb(33,102,172)\"],[1.0,\"rgb(5,48,97)\"]],\"cmid\":0.0,\"cmin\":-1.0,\"cmax\":1.0},\"title\":{\"text\":\"OV Copying Score for each head in GPT-2 Small\"}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('787bc121-88da-418b-bece-764f177bdfda');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                            </script>        </div>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "OV_copying_score = OV_circuit_all_heads_eigenvalues.sum(dim=-1).real / OV_circuit_all_heads_eigenvalues.abs().sum(dim=-1)\n",
    "imshow(utils.to_numpy(OV_copying_score), xaxis=\"Head\", yaxis=\"Layer\", title=\"OV Copying Score for each head in GPT-2 Small\", zmax=1.0, zmin=-1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Head 11 in Layer 11 (L11H11) has a high copying score, and if we plot the eigenvalues they look approximately as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-08T19:28:00.232898Z",
     "iopub.status.busy": "2023-11-08T19:28:00.232584Z",
     "iopub.status.idle": "2023-11-08T19:28:00.263929Z",
     "shell.execute_reply": "2023-11-08T19:28:00.263411Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<html>\n",
       "<head><meta charset=\"utf-8\" /></head>\n",
       "<body>\n",
       "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
       "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.27.0.min.js\"></script>                <div id=\"1914e04f-9b44-403c-a764-6fe482be9fc2\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"1914e04f-9b44-403c-a764-6fe482be9fc2\")) {                    Plotly.newPlot(                        \"1914e04f-9b44-403c-a764-6fe482be9fc2\",                        [{\"hovertemplate\":\"Real=%{x}\\u003cbr\\u003eImaginary=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"marker\":{\"color\":\"#636efa\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"x\":[-2.139726161956787,1.4152659177780151,3.4444546699523926,4.0276689529418945,8.882657051086426,4.866776943206787,4.866776943206787,4.843708038330078,4.843708038330078,8.477534294128418,8.21679973602295,8.21679973602295,5.078621864318848,7.855459213256836,7.855459213256836,5.365771770477295,5.365771770477295,5.563427448272705,5.563427448272705,5.421727657318115,7.769131660461426,7.769131660461426,7.042290210723877,7.042290210723877,5.675149917602539,5.675149917602539,7.6785993576049805,7.6785993576049805,6.573331356048584,6.573331356048584,7.67292594909668,7.172202110290527,7.172202110290527,7.423615455627441,7.423615455627441,7.4708147048950195,6.08908748626709,6.08908748626709,6.306832313537598,6.306832313537598,6.511747360229492,6.511747360229492,5.955250263214111,5.955250263214111,5.858802795410156,5.858802795410156,7.147878170013428,7.147878170013428,7.185699939727783,7.185699939727783,6.6706037521362305,6.6706037521362305,6.7359819412231445,6.7359819412231445,6.149754524230957,6.149754524230957,6.288780212402344,6.288780212402344,6.344789028167725,6.625576972961426,6.625576972961426,6.899187088012695,6.899187088012695,6.856410026550293],\"xaxis\":\"x\",\"y\":[0.0,0.0,0.0,0.0,0.0,0.41851967573165894,-0.41851967573165894,0.09079498052597046,-0.09079498052597046,0.0,0.40868431329727173,-0.40868431329727173,0.0,0.7007191777229309,-0.7007191777229309,0.46421778202056885,-0.46421778202056885,0.5558270215988159,-0.5558270215988159,0.0,0.47056713700294495,-0.47056713700294495,1.029872179031372,-1.029872179031372,0.48252731561660767,-0.48252731561660767,0.33564886450767517,-0.33564886450767517,0.9988701343536377,-0.9988701343536377,0.0,0.7531797885894775,-0.7531797885894775,0.425758957862854,-0.425758957862854,0.0,0.6436269283294678,-0.6436269283294678,0.7701666951179504,-0.7701666951179504,0.7558029294013977,-0.7558029294013977,0.2591177523136139,-0.2591177523136139,0.013043581508100033,-0.013043581508100033,0.40166139602661133,-0.40166139602661133,0.28192487359046936,-0.28192487359046936,0.6146230697631836,-0.6146230697631836,0.5391324758529663,-0.5391324758529663,0.2823374569416046,-0.2823374569416046,0.35283783078193665,-0.35283783078193665,0.0,0.24868342280387878,-0.24868342280387878,0.15545885264873505,-0.15545885264873505,0.0],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Real\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Imaginary\"}},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"Eigenvalues of Head L11H11 of GPT-2 Small\"}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('1914e04f-9b44-403c-a764-6fe482be9fc2');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                            </script>        </div>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scatter(x=OV_circuit_all_heads_eigenvalues[-1, -1, :].real, y=OV_circuit_all_heads_eigenvalues[-1, -1, :].imag, title=\"Eigenvalues of Head L11H11 of GPT-2 Small\", xaxis=\"Real\", yaxis=\"Imaginary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can even look at the full OV circuit, from the input tokens to output tokens: $W_E W_V W_O W_U$. This is a `[d_vocab, d_vocab]==[50257, 50257]` matrix, so absolutely enormous, even for a single head. But with the FactoredMatrix class, we can compute the full eigenvalue copying score of every head in a few seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-08T19:28:00.266210Z",
     "iopub.status.busy": "2023-11-08T19:28:00.265829Z",
     "iopub.status.idle": "2023-11-08T19:28:11.642010Z",
     "shell.execute_reply": "2023-11-08T19:28:11.641414Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FactoredMatrix: Shape(torch.Size([12, 12, 50257, 50257])), Hidden Dim(64)\n"
     ]
    }
   ],
   "source": [
    "full_OV_circuit = model.embed.W_E @ OV_circuit_all_heads @ model.unembed.W_U\n",
    "print(full_OV_circuit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-08T19:28:11.644406Z",
     "iopub.status.busy": "2023-11-08T19:28:11.644211Z",
     "iopub.status.idle": "2023-11-08T19:28:12.175594Z",
     "shell.execute_reply": "2023-11-08T19:28:12.174970Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12, 12, 64])\n",
      "torch.complex64\n"
     ]
    }
   ],
   "source": [
    "full_OV_circuit_eigenvalues = full_OV_circuit.eigenvalues\n",
    "print(full_OV_circuit_eigenvalues.shape)\n",
    "print(full_OV_circuit_eigenvalues.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-08T19:28:12.177789Z",
     "iopub.status.busy": "2023-11-08T19:28:12.177620Z",
     "iopub.status.idle": "2023-11-08T19:28:12.208067Z",
     "shell.execute_reply": "2023-11-08T19:28:12.207501Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<html>\n",
       "<head><meta charset=\"utf-8\" /></head>\n",
       "<body>\n",
       "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
       "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.27.0.min.js\"></script>                <div id=\"c8ec0c1b-e79f-423d-afc6-c1b2a8f2e4f1\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"c8ec0c1b-e79f-423d-afc6-c1b2a8f2e4f1\")) {                    Plotly.newPlot(                        \"c8ec0c1b-e79f-423d-afc6-c1b2a8f2e4f1\",                        [{\"coloraxis\":\"coloraxis\",\"name\":\"0\",\"z\":[[0.8356367349624634,0.5853534936904907,0.5105841159820557,0.7843377590179443,0.8644161224365234,0.7026589512825012,0.8969924449920654,0.5868823528289795,0.42486509680747986,-0.16337518393993378,0.46268585324287415,0.276053786277771],[-0.052920110523700714,-0.31773144006729126,-0.4810579717159271,-0.7838066220283508,-0.6360211968421936,-0.77586829662323,0.9681803584098816,0.8119116425514221,-0.7510464787483215,-0.6878445744514465,-0.6429887413978577,-0.9985856413841248],[-0.6598325967788696,0.9152501821517944,0.5461500883102417,-0.48743969202041626,0.7720563411712646,-0.7541061639785767,-0.8472450971603394,-0.6948987245559692,-0.1557510495185852,0.2444225549697876,-0.9106622338294983,-0.9439151287078857],[0.648689866065979,-0.5592910647392273,0.5935593247413635,0.7843040823936462,-0.8150346279144287,0.613004744052887,0.16785882413387299,0.35195910930633545,-0.6837262511253357,0.2223764955997467,-0.9929219484329224,0.6535818576812744],[0.5740953087806702,0.3640134036540985,0.09609051048755646,0.9359624981880188,-0.9228776097297668,0.6191076636314392,-0.33572638034820557,-0.998464822769165,0.6448632478713989,0.8468661308288574,-0.7557656764984131,0.9527971744537354],[0.7326544523239136,0.5324169397354126,0.9732670187950134,0.7239246964454651,0.2553895115852356,0.8158416152000427,0.665579080581665,0.9287100434303284,-0.5660436153411865,-0.8908745050430298,0.9834234118461609,-0.9981179237365723],[0.9698692560195923,0.7439671754837036,-0.35639333724975586,0.6022987365722656,0.9708116054534912,-0.9278275966644287,-0.9962316155433655,0.834520697593689,0.9714328050613403,0.8158544898033142,0.5902575850486755,0.8199343681335449],[0.9820227026939392,0.9859329462051392,0.5152460932731628,-0.5610517263412476,0.9663666486740112,0.9495157599449158,-0.5204814076423645,0.3104752004146576,0.9859083890914917,0.7797460556030273,0.6738530397415161,0.39197394251823425],[-0.906204104423523,0.11750960350036621,0.8077874779701233,0.416930615901947,0.9829014539718628,0.9902300834655762,0.7847104668617249,0.9945629835128784,0.9868024587631226,-0.26804426312446594,-0.9908867478370667,0.745792806148529],[0.9906190633773804,-0.18231146037578583,0.9757838249206543,0.9986750483512878,0.2544330954551697,-0.954406201839447,0.586924135684967,-0.23537978529930115,0.9550502896308899,0.2551196813583374,0.9929869771003723,0.0905260294675827],[0.9707273244857788,0.6956090927124023,0.6280022263526917,0.7902868390083313,0.9343841671943665,0.9895793795585632,0.9436282515525818,-0.10834990441799164,-0.3431110680103302,0.9986709952354431,0.508673906326294,0.9949509501457214],[0.8283132910728455,0.9432437419891357,0.9491764903068542,0.9995353817939758,0.5712320804595947,0.8055236339569092,0.6781865954399109,0.8272573351860046,0.8314797282218933,0.8778655529022217,0.9944959282875061,0.997386634349823]],\"type\":\"heatmap\",\"xaxis\":\"x\",\"yaxis\":\"y\",\"hovertemplate\":\"Head: %{x}\\u003cbr\\u003eLayer: %{y}\\u003cbr\\u003ecolor: %{z}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"scaleanchor\":\"y\",\"constrain\":\"domain\",\"title\":{\"text\":\"Head\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"autorange\":\"reversed\",\"constrain\":\"domain\",\"title\":{\"text\":\"Layer\"}},\"coloraxis\":{\"colorscale\":[[0.0,\"rgb(103,0,31)\"],[0.1,\"rgb(178,24,43)\"],[0.2,\"rgb(214,96,77)\"],[0.3,\"rgb(244,165,130)\"],[0.4,\"rgb(253,219,199)\"],[0.5,\"rgb(247,247,247)\"],[0.6,\"rgb(209,229,240)\"],[0.7,\"rgb(146,197,222)\"],[0.8,\"rgb(67,147,195)\"],[0.9,\"rgb(33,102,172)\"],[1.0,\"rgb(5,48,97)\"]],\"cmid\":0.0,\"cmin\":-1.0,\"cmax\":1.0},\"title\":{\"text\":\"OV Copying Score for each head in GPT-2 Small\"}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('c8ec0c1b-e79f-423d-afc6-c1b2a8f2e4f1');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                            </script>        </div>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "full_OV_copying_score = full_OV_circuit_eigenvalues.sum(dim=-1).real / full_OV_circuit_eigenvalues.abs().sum(dim=-1)\n",
    "imshow(utils.to_numpy(full_OV_copying_score), xaxis=\"Head\", yaxis=\"Layer\", title=\"OV Copying Score for each head in GPT-2 Small\", zmax=1.0, zmin=-1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, these are highly (but not perfectly!) correlated. I'm not sure what to read from this, or what's up with the weird outlier heads!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-08T19:28:12.210266Z",
     "iopub.status.busy": "2023-11-08T19:28:12.210087Z",
     "iopub.status.idle": "2023-11-08T19:28:12.242132Z",
     "shell.execute_reply": "2023-11-08T19:28:12.241598Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<html>\n",
       "<head><meta charset=\"utf-8\" /></head>\n",
       "<body>\n",
       "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
       "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.27.0.min.js\"></script>                <div id=\"693859fc-4fc8-41f4-8e0c-f23f5c1d3868\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"693859fc-4fc8-41f4-8e0c-f23f5c1d3868\")) {                    Plotly.newPlot(                        \"693859fc-4fc8-41f4-8e0c-f23f5c1d3868\",                        [{\"hovertemplate\":\"\\u003cb\\u003e%{hovertext}\\u003c\\u002fb\\u003e\\u003cbr\\u003e\\u003cbr\\u003eFull OV Copying Score=%{x}\\u003cbr\\u003eOV Copying Score=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"hovertext\":[\"L0H0\",\"L0H1\",\"L0H2\",\"L0H3\",\"L0H4\",\"L0H5\",\"L0H6\",\"L0H7\",\"L0H8\",\"L0H9\",\"L0H10\",\"L0H11\",\"L1H0\",\"L1H1\",\"L1H2\",\"L1H3\",\"L1H4\",\"L1H5\",\"L1H6\",\"L1H7\",\"L1H8\",\"L1H9\",\"L1H10\",\"L1H11\",\"L2H0\",\"L2H1\",\"L2H2\",\"L2H3\",\"L2H4\",\"L2H5\",\"L2H6\",\"L2H7\",\"L2H8\",\"L2H9\",\"L2H10\",\"L2H11\",\"L3H0\",\"L3H1\",\"L3H2\",\"L3H3\",\"L3H4\",\"L3H5\",\"L3H6\",\"L3H7\",\"L3H8\",\"L3H9\",\"L3H10\",\"L3H11\",\"L4H0\",\"L4H1\",\"L4H2\",\"L4H3\",\"L4H4\",\"L4H5\",\"L4H6\",\"L4H7\",\"L4H8\",\"L4H9\",\"L4H10\",\"L4H11\",\"L5H0\",\"L5H1\",\"L5H2\",\"L5H3\",\"L5H4\",\"L5H5\",\"L5H6\",\"L5H7\",\"L5H8\",\"L5H9\",\"L5H10\",\"L5H11\",\"L6H0\",\"L6H1\",\"L6H2\",\"L6H3\",\"L6H4\",\"L6H5\",\"L6H6\",\"L6H7\",\"L6H8\",\"L6H9\",\"L6H10\",\"L6H11\",\"L7H0\",\"L7H1\",\"L7H2\",\"L7H3\",\"L7H4\",\"L7H5\",\"L7H6\",\"L7H7\",\"L7H8\",\"L7H9\",\"L7H10\",\"L7H11\",\"L8H0\",\"L8H1\",\"L8H2\",\"L8H3\",\"L8H4\",\"L8H5\",\"L8H6\",\"L8H7\",\"L8H8\",\"L8H9\",\"L8H10\",\"L8H11\",\"L9H0\",\"L9H1\",\"L9H2\",\"L9H3\",\"L9H4\",\"L9H5\",\"L9H6\",\"L9H7\",\"L9H8\",\"L9H9\",\"L9H10\",\"L9H11\",\"L10H0\",\"L10H1\",\"L10H2\",\"L10H3\",\"L10H4\",\"L10H5\",\"L10H6\",\"L10H7\",\"L10H8\",\"L10H9\",\"L10H10\",\"L10H11\",\"L11H0\",\"L11H1\",\"L11H2\",\"L11H3\",\"L11H4\",\"L11H5\",\"L11H6\",\"L11H7\",\"L11H8\",\"L11H9\",\"L11H10\",\"L11H11\"],\"legendgroup\":\"\",\"marker\":{\"color\":\"#636efa\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"x\":[0.8356367349624634,0.5853534936904907,0.5105841159820557,0.7843377590179443,0.8644161224365234,0.7026589512825012,0.8969924449920654,0.5868823528289795,0.42486509680747986,-0.16337518393993378,0.46268585324287415,0.276053786277771,-0.052920110523700714,-0.31773144006729126,-0.4810579717159271,-0.7838066220283508,-0.6360211968421936,-0.77586829662323,0.9681803584098816,0.8119116425514221,-0.7510464787483215,-0.6878445744514465,-0.6429887413978577,-0.9985856413841248,-0.6598325967788696,0.9152501821517944,0.5461500883102417,-0.48743969202041626,0.7720563411712646,-0.7541061639785767,-0.8472450971603394,-0.6948987245559692,-0.1557510495185852,0.2444225549697876,-0.9106622338294983,-0.9439151287078857,0.648689866065979,-0.5592910647392273,0.5935593247413635,0.7843040823936462,-0.8150346279144287,0.613004744052887,0.16785882413387299,0.35195910930633545,-0.6837262511253357,0.2223764955997467,-0.9929219484329224,0.6535818576812744,0.5740953087806702,0.3640134036540985,0.09609051048755646,0.9359624981880188,-0.9228776097297668,0.6191076636314392,-0.33572638034820557,-0.998464822769165,0.6448632478713989,0.8468661308288574,-0.7557656764984131,0.9527971744537354,0.7326544523239136,0.5324169397354126,0.9732670187950134,0.7239246964454651,0.2553895115852356,0.8158416152000427,0.665579080581665,0.9287100434303284,-0.5660436153411865,-0.8908745050430298,0.9834234118461609,-0.9981179237365723,0.9698692560195923,0.7439671754837036,-0.35639333724975586,0.6022987365722656,0.9708116054534912,-0.9278275966644287,-0.9962316155433655,0.834520697593689,0.9714328050613403,0.8158544898033142,0.5902575850486755,0.8199343681335449,0.9820227026939392,0.9859329462051392,0.5152460932731628,-0.5610517263412476,0.9663666486740112,0.9495157599449158,-0.5204814076423645,0.3104752004146576,0.9859083890914917,0.7797460556030273,0.6738530397415161,0.39197394251823425,-0.906204104423523,0.11750960350036621,0.8077874779701233,0.416930615901947,0.9829014539718628,0.9902300834655762,0.7847104668617249,0.9945629835128784,0.9868024587631226,-0.26804426312446594,-0.9908867478370667,0.745792806148529,0.9906190633773804,-0.18231146037578583,0.9757838249206543,0.9986750483512878,0.2544330954551697,-0.954406201839447,0.586924135684967,-0.23537978529930115,0.9550502896308899,0.2551196813583374,0.9929869771003723,0.0905260294675827,0.9707273244857788,0.6956090927124023,0.6280022263526917,0.7902868390083313,0.9343841671943665,0.9895793795585632,0.9436282515525818,-0.10834990441799164,-0.3431110680103302,0.9986709952354431,0.508673906326294,0.9949509501457214,0.8283132910728455,0.9432437419891357,0.9491764903068542,0.9995353817939758,0.5712320804595947,0.8055236339569092,0.6781865954399109,0.8272573351860046,0.8314797282218933,0.8778655529022217,0.9944959282875061,0.997386634349823],\"xaxis\":\"x\",\"y\":[0.7775008678436279,0.35272663831710815,0.25961872935295105,0.6670258045196533,0.838425874710083,0.5584433078765869,0.844474732875824,0.41379114985466003,0.244889497756958,0.02815753035247326,0.3584096431732178,0.16288283467292786,-0.4541913866996765,-0.6529324650764465,-0.5484569668769836,-0.7990368604660034,-0.7736426591873169,-0.8522582650184631,0.977432370185852,0.6626251935958862,-0.7303223609924316,-0.7007019519805908,-0.6946623921394348,-0.9996723532676697,-0.7837162613868713,0.8967758417129517,0.4750956892967224,-0.6671973466873169,0.7881463170051575,-0.8547748923301697,-0.9054183959960938,-0.5749384760856628,-0.321751207113266,-0.0285941194742918,-0.9247617125511169,-0.9699268937110901,0.5864036083221436,-0.76143479347229,0.5971695184707642,0.7854391932487488,-0.8788884878158569,0.3908745348453522,0.0447387658059597,0.1102800965309143,-0.8169987201690674,0.2212953418493271,-0.9939578771591187,0.5774401426315308,0.5254791378974915,0.30490121245384216,-0.10729170590639114,0.9433152675628662,-0.9314427971839905,0.5273631811141968,-0.4264712929725647,-0.9984429478645325,0.5296757817268372,0.8604294657707214,-0.8895052075386047,0.9556970000267029,0.6629188656806946,0.4295697808265686,0.9736858010292053,0.655548095703125,0.12201863527297974,0.7442769408226013,0.5037954449653625,0.95253586769104,-0.6507166624069214,-0.9316278100013733,0.9791510701179504,-0.9972586035728455,0.9613031148910522,0.7501779794692993,-0.3806658983230591,0.6429785490036011,0.9557769298553467,-0.9428837895393372,-0.9948079586029053,0.7852989435195923,0.9657301306724548,0.7073014974594116,0.36872273683547974,0.8128010034561157,0.9659482836723328,0.9730120301246643,0.31900620460510254,-0.30290529131889343,0.9790952801704407,0.9357922673225403,-0.5550314784049988,-0.0054661668837070465,0.986777663230896,0.8249568343162537,0.5664296746253967,0.1000528484582901,-0.9464486837387085,-0.25471991300582886,0.6522327065467834,0.14152583479881287,0.9884141683578491,0.9860584735870361,0.6949271559715271,0.9901811480522156,0.9791203141212463,-0.23595543205738068,-0.982071042060852,0.6506688594818115,0.9895945191383362,-0.291781485080719,0.9714024662971497,0.9951602220535278,0.18783727288246155,-0.9460937976837158,0.4780191481113434,-0.2489192634820938,0.9437099099159241,0.11866225302219391,0.9941242933273315,-0.38088199496269226,0.9564487338066101,0.5542722344398499,0.42118069529533386,0.6628788113594055,0.8659593462944031,0.9937117695808411,0.9069075584411621,0.3981107473373413,-0.4134218096733093,0.9971914887428284,0.3459664583206177,0.9938657283782959,0.5891268253326416,0.9313738942146301,0.9268401861190796,0.9993563890457153,0.6227542161941528,0.8463947772979736,0.6584343910217285,0.8423123955726624,0.2978499233722687,0.8728678822517395,0.9963143467903137,0.9867526292800903],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Full OV Copying Score\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"OV Copying Score\"}},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"OV Copying Score for each head in GPT-2 Small\"}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('693859fc-4fc8-41f4-8e0c-f23f5c1d3868');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                            </script>        </div>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scatter(x=full_OV_copying_score.flatten(), y=OV_copying_score.flatten(), hover_name=[f\"L{layer}H{head}\" for layer in range(12) for head in range(12)], title=\"OV Copying Score for each head in GPT-2 Small\", xaxis=\"Full OV Copying Score\", yaxis=\"OV Copying Score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-08T19:28:12.244344Z",
     "iopub.status.busy": "2023-11-08T19:28:12.244025Z",
     "iopub.status.idle": "2023-11-08T19:28:12.247770Z",
     "shell.execute_reply": "2023-11-08T19:28:12.247198Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token 256 - the most common pair of ASCII characters: | t|\n",
      "De-Tokenizing the example tokens: <|endoftext|>The first thing you need to figure out is *how* things are tokenized. `model.to_str_tokens` splits a string into the tokens *as a list of substrings*, and so lets you explore what the text looks like. To demonstrate this, let's use it on this paragraph.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Token 256 - the most common pair of ASCII characters: |{model.to_string(256)}|\")\n",
    "# Squeeze means to remove dimensions of length 1. \n",
    "# Here, that removes the dummy batch dimension so it's a rank 1 tensor and returns a string\n",
    "# Rank 2 tensors map to a list of strings\n",
    "print(f\"De-Tokenizing the example tokens: {model.to_string(example_text_tokens.squeeze())}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TransformerLens also has basic text generation functionality, which can be useful for generally exploring what the model is capable of (thanks to Ansh Radhakrishnan for adding this!). This is pretty rough functionality, and where possible I recommend using more established libraries like HuggingFace for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-08T19:28:12.249756Z",
     "iopub.status.busy": "2023-11-08T19:28:12.249589Z",
     "iopub.status.idle": "2023-11-08T19:28:14.344378Z",
     "shell.execute_reply": "2023-11-08T19:28:14.343798Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b195d2f5abca4a85ac28a2331fb32435",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'(CNN) President Barack Obama caught in embarrassing new scandal\\n\\nThe president, in an interview with the Financial Times, said that he did not know when he was caught on video talking about his wife, Chelsea, but he did know that she was a \"young woman\" and that he had been using her'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NBVAL_IGNORE_OUTPUT\n",
    "model.generate(\"(CNN) President Barack Obama caught in embarrassing new scandal\\n\", max_new_tokens=50, temperature=0.7, prepend_bos=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hook Points\n",
    "\n",
    "The key part of TransformerLens that lets us access and edit intermediate activations are the HookPoints around every model activation. Importantly, this technique will work for *any* model architecture, not just transformers, so long as you're able to edit the model code to add in HookPoints! This is essentially a lightweight library bundled with TransformerLens that should let you take an arbitrary model and make it easier to study. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is implemented by having a HookPoint layer. Each transformer component has a HookPoint for every activation, which wraps around that activation. The HookPoint acts as an identity function, but has a variety of helper functions that allows us to put PyTorch hooks in to edit and access the relevant activation. \n",
    "\n",
    "There is also a `HookedRootModule` class - this is a utility class that the root module should inherit from (root module = the model we run) - it has several utility functions for using hooks well, notably `reset_hooks`, `run_with_cache` and `run_with_hooks`. \n",
    "\n",
    "The default interface is the `run_with_hooks` function on the root module, which lets us run a forwards pass on the model, and pass on a list of hooks paired with layer names to run on that pass. \n",
    "\n",
    "The syntax for a hook is `function(activation, hook)` where `activation` is the activation the hook is wrapped around, and `hook` is the `HookPoint` class the function is attached to. If the function returns a new activation or edits the activation in-place, that replaces the old one, if it returns None then the activation remains as is.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Toy Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Here's a simple example of defining a small network with HookPoints:\n",
    "\n",
    "We define a basic network with two layers that each take a scalar input $x$, square it, and add a constant:\n",
    "$x_0=x$, $x_1=x_0^2+3$, $x_2=x_1^2-4$.\n",
    "\n",
    "We wrap the input, each layer's output, and the intermediate value of each layer (the square) in a hook point.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-08T19:28:14.346665Z",
     "iopub.status.busy": "2023-11-08T19:28:14.346493Z",
     "iopub.status.idle": "2023-11-08T19:28:14.352065Z",
     "shell.execute_reply": "2023-11-08T19:28:14.351620Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from transformer_lens.hook_points import HookedRootModule, HookPoint\n",
    "\n",
    "\n",
    "class SquareThenAdd(nn.Module):\n",
    "    def __init__(self, offset):\n",
    "        super().__init__()\n",
    "        self.offset = nn.Parameter(torch.tensor(offset))\n",
    "        self.hook_square = HookPoint()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # The hook_square doesn't change the value, but lets us access it\n",
    "        square = self.hook_square(x * x)\n",
    "        return self.offset + square\n",
    "\n",
    "\n",
    "class TwoLayerModel(HookedRootModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = SquareThenAdd(3.0)\n",
    "        self.layer2 = SquareThenAdd(-4.0)\n",
    "        self.hook_in = HookPoint()\n",
    "        self.hook_mid = HookPoint()\n",
    "        self.hook_out = HookPoint()\n",
    "\n",
    "        # We need to call the setup function of HookedRootModule to build an\n",
    "        # internal dictionary of modules and hooks, and to give each hook a name\n",
    "        super().setup()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # We wrap the input and each layer's output in a hook - they leave the\n",
    "        # value unchanged (unless there's a hook added to explicitly change it),\n",
    "        # but allow us to access it.\n",
    "        x_in = self.hook_in(x)\n",
    "        x_mid = self.hook_mid(self.layer1(x_in))\n",
    "        x_out = self.hook_out(self.layer2(x_mid))\n",
    "        return x_out\n",
    "\n",
    "\n",
    "model = TwoLayerModel()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We can add a cache, to save the activation at each hook point\n",
    "\n",
    "(There's a custom `run_with_cache` function on the root module as a convenience, which is a wrapper around model.forward that return model_out, cache_object - we could also manually add hooks with `run_with_hooks` that store activations in a global caching dictionary. This is often useful if we only want to store, eg, subsets or functions of some activations.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-08T19:28:14.353907Z",
     "iopub.status.busy": "2023-11-08T19:28:14.353741Z",
     "iopub.status.idle": "2023-11-08T19:28:14.357913Z",
     "shell.execute_reply": "2023-11-08T19:28:14.357374Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model output: 780.0\n",
      "Value cached at hook hook_in 5.0\n",
      "Value cached at hook layer1.hook_square 25.0\n",
      "Value cached at hook hook_mid 28.0\n",
      "Value cached at hook layer2.hook_square 784.0\n",
      "Value cached at hook hook_out 780.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "out, cache = model.run_with_cache(torch.tensor(5.0))\n",
    "print(\"Model output:\", out.item())\n",
    "for key in cache:\n",
    "    print(f\"Value cached at hook {key}\", cache[key].item())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We can also use hooks to intervene on activations - eg, we can set the intermediate value in layer 2 to zero to change the output to -5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-08T19:28:14.360018Z",
     "iopub.status.busy": "2023-11-08T19:28:14.359714Z",
     "iopub.status.idle": "2023-11-08T19:28:14.363605Z",
     "shell.execute_reply": "2023-11-08T19:28:14.363053Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer2.hook_square\n",
      "Output after intervening on layer2.hook_scaled -4.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def set_to_zero_hook(tensor, hook):\n",
    "    print(hook.name)\n",
    "    return torch.tensor(0.0)\n",
    "\n",
    "\n",
    "print(\n",
    "    \"Output after intervening on layer2.hook_scaled\",\n",
    "    model.run_with_hooks(\n",
    "        torch.tensor(5.0), fwd_hooks=[(\"layer2.hook_square\", set_to_zero_hook)]\n",
    "    ).item(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Pre-Trained Checkpoints\n",
    "\n",
    "There are a lot of interesting questions combining mechanistic interpretability and training dynamics - analysing model capabilities and the underlying circuits that make them possible, and how these change as we train the model. \n",
    "\n",
    "TransformerLens supports these by having several model families with checkpoints throughout training. `HookedTransformer.from_pretrained` can load a checkpoint of a model with the `checkpoint_index` (the label 0 to `num_checkpoints-1`) or `checkpoint_value` (the step or token number, depending on how the checkpoints were labelled)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Available models:\n",
    "* All of my interpretability-friendly models have checkpoints available, including:\n",
    "    * The toy models - `attn-only`, `solu`, `gelu` 1L to 4L\n",
    "        * These have ~200 checkpoints, taken on a piecewise linear schedule (more checkpoints near the start of training), up to 22B tokens. Labelled by number of tokens seen.\n",
    "    * The SoLU models trained on 80% Web Text and 20% Python Code (`solu-6l` to `solu-12l`)\n",
    "        * Same checkpoint schedule as the toy models, this time up to 30B tokens\n",
    "    * The SoLU models trained on the pile (`solu-1l-pile` to `solu-12l-pile`)\n",
    "        * These have ~100 checkpoints, taken on a linear schedule, up to 15B tokens. Labelled by number of steps.\n",
    "        * The 12L training crashed around 11B tokens, so is truncated.\n",
    "* The Stanford Centre for Research of Foundation Models trained 5 GPT-2 Small sized and 5 GPT-2 Medium sized models (`stanford-gpt2-small-a` to `e` and `stanford-gpt2-medium-a` to `e`)\n",
    "    * 600 checkpoints, taken on a piecewise linear schedule, labelled by the number of steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The checkpoint structure and labels is somewhat messy and ad-hoc, so I mostly recommend using the `checkpoint_index` syntax (where you can just count from 0 to the number of checkpoints) rather than `checkpoint_value` syntax (where you need to know the checkpoint schedule, and whether it was labelled with the number of tokens or steps). The helper function `get_checkpoint_labels` tells you the checkpoint schedule for a given model - ie what point was each checkpoint taken at, and what type of label was used.\n",
    "\n",
    "Here are graphs of the schedules for several checkpointed models: (note that the first 3 use a log scale, latter 2 use a linear scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-08T19:28:14.365641Z",
     "iopub.status.busy": "2023-11-08T19:28:14.365476Z",
     "iopub.status.idle": "2023-11-08T19:28:15.039092Z",
     "shell.execute_reply": "2023-11-08T19:28:15.038595Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<html>\n",
       "<head><meta charset=\"utf-8\" /></head>\n",
       "<body>\n",
       "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
       "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.27.0.min.js\"></script>                <div id=\"541fcd65-8075-402b-a488-55ff478f85ca\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"541fcd65-8075-402b-a488-55ff478f85ca\")) {                    Plotly.newPlot(                        \"541fcd65-8075-402b-a488-55ff478f85ca\",                        [{\"hovertemplate\":\"variable=0\\u003cbr\\u003eindex=%{x}\\u003cbr\\u003evalue=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"0\",\"line\":{\"color\":\"#636efa\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines+markers\",\"name\":\"0\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162],\"xaxis\":\"x\",\"y\":[262144,2621440,4718592,7077888,9175040,11272192,13631488,15728640,18087936,20185088,22282240,33292288,44302336,55312384,66322432,77332480,88342528,99352576,110362624,121372672,132382720,143392768,154402816,165412864,176422912,187432960,198443008,209453056,220463104,264503296,308281344,352321536,396361728,440401920,484442112,528482304,572522496,616300544,660340736,704380928,748421120,792461312,836501504,880279552,924319744,968359936,1012400128,1056440320,1100480512,1144520704,1188298752,1232338944,1276379136,1320419328,1364459520,1408499712,1452277760,1496317952,1540358144,1584398336,1628438528,1672478720,1716518912,1760296960,1804337152,1848377344,1892417536,1936457728,1980497920,2024275968,2068316160,2112356352,2156396544,2200436736,2420375552,2640314368,2860515328,3080454144,3300392960,3520331776,3740270592,3960471552,4180410368,4400349184,4620288000,4840488960,5060427776,5280366592,5500305408,5720506368,5940445184,6160384000,6380322816,6600523776,6820462592,7040401408,7260340224,7480279040,7700480000,7920418816,8140357632,8360296448,8580497408,8800436224,9020375040,9240313856,9460514816,9680453632,9900392448,10120331264,10340270080,10560471040,10780409856,11000348672,11220287488,11440488448,11660427264,11880366080,12100304896,12320505856,12540444672,12760383488,12980322304,13200523264,13420462080,13640400896,13860339712,14080278528,14300479488,14520418304,14740357120,14960295936,15180496896,15400435712,15620374528,15840313344,16060514304,16280453120,16500391936,16720330752,16940269568,17160470528,17380409344,17600348160,17820286976,18040487936,18260426752,18480365568,18700304384,18920505344,19140444160,19360382976,19580321792,19800522752,20020461568,20240400384,20460339200,20680278016,20900478976,21120417792,21340356608,21560295424,21780496384],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"index\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"value\"},\"type\":\"log\"},\"legend\":{\"title\":{\"text\":\"variable\"},\"tracegroupgap\":0},\"title\":{\"text\":\"Checkpoint Values for attn-only-2l (Log scale)\"}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('541fcd65-8075-402b-a488-55ff478f85ca');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                            </script>        </div>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<html>\n",
       "<head><meta charset=\"utf-8\" /></head>\n",
       "<body>\n",
       "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
       "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.27.0.min.js\"></script>                <div id=\"e8618691-ae6c-4942-850b-43de33fdd743\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"e8618691-ae6c-4942-850b-43de33fdd743\")) {                    Plotly.newPlot(                        \"e8618691-ae6c-4942-850b-43de33fdd743\",                        [{\"hovertemplate\":\"variable=0\\u003cbr\\u003eindex=%{x}\\u003cbr\\u003evalue=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"0\",\"line\":{\"color\":\"#636efa\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines+markers\",\"name\":\"0\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162],\"xaxis\":\"x\",\"y\":[196608,3342336,6291456,9240576,12386304,15335424,18284544,21233664,24379392,27328512,30277632,45219840,60358656,75300864,90243072,105381888,120324096,135266304,150208512,165347328,180289536,195231744,210370560,225312768,240254976,255197184,270336000,285278208,300220416,360382464,420347904,480313344,540278784,600244224,660209664,720371712,780337152,840302592,900268032,960233472,1020198912,1080360960,1140326400,1200291840,1260257280,1320222720,1380384768,1440350208,1500315648,1560281088,1620246528,1680211968,1740374016,1800339456,1860304896,1920270336,1980235776,2040201216,2100363264,2160328704,2220294144,2280259584,2340225024,2400387072,2460352512,2520317952,2580283392,2640248832,2700214272,2760376320,2820341760,2880307200,2940272640,3000238080,3300261888,3600285696,3900309504,4200333312,4500357120,4800380928,5100208128,5400231936,5700255744,6000279552,6300303360,6600327168,6900350976,7200374784,7500201984,7800225792,8100249600,8400273408,8700297216,9000321024,9300344832,9600368640,9900392448,10200219648,10500243456,10800267264,11100291072,11400314880,11700338688,12000362496,12300386304,12600213504,12900237312,13200261120,13500284928,13800308736,14100332544,14400356352,14700380160,15000207360,15300231168,15600254976,15900278784,16200302592,16500326400,16800350208,17100374016,17400201216,17700225024,18000248832,18300272640,18600296448,18900320256,19200344064,19500367872,19800391680,20100218880,20400242688,20700266496,21000290304,21300314112,21600337920,21900361728,22200385536,22500212736,22800236544,23100260352,23400284160,23700307968,24000331776,24300355584,24600379392,24900206592,25200230400,25500254208,25800278016,26100301824,26400325632,26700349440,27000373248,27300200448,27600224256,27900248064,28200271872,28500295680,28800319488,29100343296,29400367104,29700390912],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"index\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"value\"},\"type\":\"log\"},\"legend\":{\"title\":{\"text\":\"variable\"},\"tracegroupgap\":0},\"title\":{\"text\":\"Checkpoint Values for solu-12l (Log scale)\"}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('e8618691-ae6c-4942-850b-43de33fdd743');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                            </script>        </div>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<html>\n",
       "<head><meta charset=\"utf-8\" /></head>\n",
       "<body>\n",
       "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
       "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.27.0.min.js\"></script>                <div id=\"e322aaf3-5b5d-480a-b077-d0c17f7329d0\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"e322aaf3-5b5d-480a-b077-d0c17f7329d0\")) {                    Plotly.newPlot(                        \"e322aaf3-5b5d-480a-b077-d0c17f7329d0\",                        [{\"hovertemplate\":\"variable=0\\u003cbr\\u003eindex=%{x}\\u003cbr\\u003evalue=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"0\",\"line\":{\"color\":\"#636efa\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines+markers\",\"name\":\"0\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567,568,569,570,571,572,573,574,575,576,577,578,579,580,581,582,583,584,585,586,587,588,589,590,591,592,593,594,595,596,597,598,599,600,601,602,603,604,605,606,607,608],\"xaxis\":\"x\",\"y\":[0,10,20,30,40,50,60,70,80,90,100,150,200,250,300,350,400,450,500,550,600,650,700,750,800,850,900,950,1000,1050,1100,1150,1200,1250,1300,1350,1400,1450,1500,1550,1600,1650,1700,1750,1800,1850,1900,1950,2000,2100,2200,2300,2400,2500,2600,2700,2800,2900,3000,3100,3200,3300,3400,3500,3600,3700,3800,3900,4000,4100,4200,4300,4400,4500,4600,4700,4800,4900,5000,5100,5200,5300,5400,5500,5600,5700,5800,5900,6000,6100,6200,6300,6400,6500,6600,6700,6800,6900,7000,7100,7200,7300,7400,7500,7600,7700,7800,7900,8000,8100,8200,8300,8400,8500,8600,8700,8800,8900,9000,9100,9200,9300,9400,9500,9600,9700,9800,9900,10000,10100,10200,10300,10400,10500,10600,10700,10800,10900,11000,11100,11200,11300,11400,11500,11600,11700,11800,11900,12000,12100,12200,12300,12400,12500,12600,12700,12800,12900,13000,13100,13200,13300,13400,13500,13600,13700,13800,13900,14000,14100,14200,14300,14400,14500,14600,14700,14800,14900,15000,15100,15200,15300,15400,15500,15600,15700,15800,15900,16000,16100,16200,16300,16400,16500,16600,16700,16800,16900,17000,17100,17200,17300,17400,17500,17600,17700,17800,17900,18000,18100,18200,18300,18400,18500,18600,18700,18800,18900,19000,19100,19200,19300,19400,19500,19600,19700,19800,19900,20000,21000,22000,23000,24000,25000,26000,27000,28000,29000,30000,31000,32000,33000,34000,35000,36000,37000,38000,39000,40000,41000,42000,43000,44000,45000,46000,47000,48000,49000,50000,51000,52000,53000,54000,55000,56000,57000,58000,59000,60000,61000,62000,63000,64000,65000,66000,67000,68000,69000,70000,71000,72000,73000,74000,75000,76000,77000,78000,79000,80000,81000,82000,83000,84000,85000,86000,87000,88000,89000,90000,91000,92000,93000,94000,95000,96000,97000,98000,99000,100000,101000,102000,103000,104000,105000,106000,107000,108000,109000,110000,111000,112000,113000,114000,115000,116000,117000,118000,119000,120000,121000,122000,123000,124000,125000,126000,127000,128000,129000,130000,131000,132000,133000,134000,135000,136000,137000,138000,139000,140000,141000,142000,143000,144000,145000,146000,147000,148000,149000,150000,151000,152000,153000,154000,155000,156000,157000,158000,159000,160000,161000,162000,163000,164000,165000,166000,167000,168000,169000,170000,171000,172000,173000,174000,175000,176000,177000,178000,179000,180000,181000,182000,183000,184000,185000,186000,187000,188000,189000,190000,191000,192000,193000,194000,195000,196000,197000,198000,199000,200000,201000,202000,203000,204000,205000,206000,207000,208000,209000,210000,211000,212000,213000,214000,215000,216000,217000,218000,219000,220000,221000,222000,223000,224000,225000,226000,227000,228000,229000,230000,231000,232000,233000,234000,235000,236000,237000,238000,239000,240000,241000,242000,243000,244000,245000,246000,247000,248000,249000,250000,251000,252000,253000,254000,255000,256000,257000,258000,259000,260000,261000,262000,263000,264000,265000,266000,267000,268000,269000,270000,271000,272000,273000,274000,275000,276000,277000,278000,279000,280000,281000,282000,283000,284000,285000,286000,287000,288000,289000,290000,291000,292000,293000,294000,295000,296000,297000,298000,299000,300000,301000,302000,303000,304000,305000,306000,307000,308000,309000,310000,311000,312000,313000,314000,315000,316000,317000,318000,319000,320000,321000,322000,323000,324000,325000,326000,327000,328000,329000,330000,331000,332000,333000,334000,335000,336000,337000,338000,339000,340000,341000,342000,343000,344000,345000,346000,347000,348000,349000,350000,351000,352000,353000,354000,355000,356000,357000,358000,359000,360000,361000,362000,363000,364000,365000,366000,367000,368000,369000,370000,371000,372000,373000,374000,375000,376000,377000,378000,379000,380000,381000,382000,383000,384000,385000,386000,387000,388000,389000,390000,391000,392000,393000,394000,395000,396000,397000,398000,399000,400000],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"index\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"value\"},\"type\":\"log\"},\"legend\":{\"title\":{\"text\":\"variable\"},\"tracegroupgap\":0},\"title\":{\"text\":\"Checkpoint Values for stanford-gpt2-small-a (Log scale)\"}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('e322aaf3-5b5d-480a-b077-d0c17f7329d0');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                            </script>        </div>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<html>\n",
       "<head><meta charset=\"utf-8\" /></head>\n",
       "<body>\n",
       "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
       "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.27.0.min.js\"></script>                <div id=\"0e975b72-8103-40a3-9fd3-18e9501dfc65\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"0e975b72-8103-40a3-9fd3-18e9501dfc65\")) {                    Plotly.newPlot(                        \"0e975b72-8103-40a3-9fd3-18e9501dfc65\",                        [{\"hovertemplate\":\"variable=0\\u003cbr\\u003eindex=%{x}\\u003cbr\\u003evalue=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"0\",\"line\":{\"color\":\"#636efa\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines+markers\",\"name\":\"0\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49],\"xaxis\":\"x\",\"y\":[832,1664,2496,3328,4160,4992,5824,6656,7488,8320,9152,9984,10816,11648,12480,13312,14144,14976,15808,16640,17472,18304,19136,19968,20800,21632,22464,23296,24128,24960,25792,26624,27456,28288,29120,29952,30784,31616,32448,33280,34112,34944,35776,36608,37440,38272,39104,39936,40768,41600],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"index\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"value\"}},\"legend\":{\"title\":{\"text\":\"variable\"},\"tracegroupgap\":0},\"title\":{\"text\":\"Checkpoint Values for solu-1l-pile (Linear scale)\"}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('0e975b72-8103-40a3-9fd3-18e9501dfc65');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                            </script>        </div>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<html>\n",
       "<head><meta charset=\"utf-8\" /></head>\n",
       "<body>\n",
       "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
       "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.27.0.min.js\"></script>                <div id=\"a4892406-03d8-45c6-aa1e-2644d069e7c9\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"a4892406-03d8-45c6-aa1e-2644d069e7c9\")) {                    Plotly.newPlot(                        \"a4892406-03d8-45c6-aa1e-2644d069e7c9\",                        [{\"hovertemplate\":\"variable=0\\u003cbr\\u003eindex=%{x}\\u003cbr\\u003evalue=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"0\",\"line\":{\"color\":\"#636efa\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines+markers\",\"name\":\"0\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99],\"xaxis\":\"x\",\"y\":[326,652,978,1304,1630,1956,2282,2608,2934,3260,3586,3912,4238,4564,4890,5216,5542,5868,6194,6520,6846,7172,7498,7824,8150,8476,8802,9128,9454,9780,10106,10432,10758,11084,11410,11736,12062,12388,12714,13040,13366,13692,14018,14344,14670,14996,15322,15648,15974,16300,16626,16952,17278,17604,17930,18256,18582,18908,19234,19560,19886,20212,20538,20864,21190,21516,21842,22168,22494,22820,23146,23472,23798,24124,24450,24776,25102,25428,25754,26080,26406,26732,27058,27384,27710,28036,28362,28688,29014,29340,29666,29992,30318,30644,30970,31296,31622,31948,32274,32600],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"index\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"value\"}},\"legend\":{\"title\":{\"text\":\"variable\"},\"tracegroupgap\":0},\"title\":{\"text\":\"Checkpoint Values for solu-6l-pile (Linear scale)\"}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('a4892406-03d8-45c6-aa1e-2644d069e7c9');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                            </script>        </div>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformer_lens.loading_from_pretrained import get_checkpoint_labels\n",
    "for model_name in [\"attn-only-2l\", \"solu-12l\", \"stanford-gpt2-small-a\"]:\n",
    "    checkpoint_labels, checkpoint_label_type = get_checkpoint_labels(model_name)\n",
    "    line(checkpoint_labels, xaxis=\"Checkpoint Index\", yaxis=f\"Checkpoint Value ({checkpoint_label_type})\", title=f\"Checkpoint Values for {model_name} (Log scale)\", log_y=True, markers=True)\n",
    "for model_name in [\"solu-1l-pile\", \"solu-6l-pile\"]:\n",
    "    checkpoint_labels, checkpoint_label_type = get_checkpoint_labels(model_name)\n",
    "    line(checkpoint_labels, xaxis=\"Checkpoint Index\", yaxis=f\"Checkpoint Value ({checkpoint_label_type})\", title=f\"Checkpoint Values for {model_name} (Linear scale)\", log_y=False, markers=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Induction Head Phase Transition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the more interesting results analysing circuit formation during training is the [induction head phase transition](https://transformer-circuits.pub/2022/in-context-learning-and-induction-heads/index.html). They find a pretty dramatic shift in models during training - there's a brief period where models go from not having induction heads to having them, which leads to the models suddenly becoming much better at in-context learning (using far back tokens to predict the next token, eg over 500 words back). This is enough of a big deal that it leads to a visible *bump* in the loss curve, where the model's rate of improvement briefly increases. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a brief demonstration of the existence of the phase transition, let's load some checkpoints of a two layer model, and see whether they have induction heads. An easy test, as we used above, is to give the model a repeated sequence of random tokens, and to check how good its loss is on the second half. `evals.induction_loss` is a rough util that runs this test on a model.\n",
    "(Note - this is deliberately a rough, non-rigorous test for the purposes of demonstration, eg `evals.induction_loss` by default just runs it on 4 sequences of 384 tokens repeated twice. These results totally don't do the paper justice - go check it out if you want to see the full results!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the interests of time and memory, let's look at a handful of checkpoints (chosen to be around the phase change), indices `[10, 25, 35, 60, -1]`. These are roughly 22M, 200M, 500M, 1.6B and 21.8B tokens through training, respectively. (I generally recommend looking things up based on indices, rather than checkpoint value!). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-08T19:28:15.041204Z",
     "iopub.status.busy": "2023-11-08T19:28:15.041028Z",
     "iopub.status.idle": "2023-11-08T19:28:15.044269Z",
     "shell.execute_reply": "2023-11-08T19:28:15.043704Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformer_lens import evals\n",
    "# We use the two layer model with SoLU activations, chosen fairly arbitrarily as being both small (so fast to download and keep in memory) and pretty good at the induction task.\n",
    "model_name = \"solu-2l\"\n",
    "# We can load a model from a checkpoint by specifying the checkpoint_index, -1 means the final checkpoint\n",
    "checkpoint_indices = [10, 25, 35, 60, -1]\n",
    "checkpointed_models = []\n",
    "tokens_trained_on = []\n",
    "induction_losses = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the models, cache them in a list, and "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-08T19:28:15.046335Z",
     "iopub.status.busy": "2023-11-08T19:28:15.046037Z",
     "iopub.status.idle": "2023-11-08T19:28:15.049427Z",
     "shell.execute_reply": "2023-11-08T19:28:15.048984Z"
    }
   },
   "outputs": [],
   "source": [
    "if not IN_GITHUB:\n",
    "    for index in checkpoint_indices:\n",
    "        # Load the model from the relevant checkpoint by index\n",
    "        model_for_this_checkpoint = HookedTransformer.from_pretrained(model_name, checkpoint_index=index, device=device)\n",
    "        checkpointed_models.append(model_for_this_checkpoint)\n",
    "\n",
    "        tokens_seen_for_this_checkpoint = model_for_this_checkpoint.cfg.checkpoint_value\n",
    "        tokens_trained_on.append(tokens_seen_for_this_checkpoint)\n",
    "\n",
    "        induction_loss_for_this_checkpoint = evals.induction_loss(model_for_this_checkpoint, device=device).item()\n",
    "        induction_losses.append(induction_loss_for_this_checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot this, and see there's a sharp shift from ~200-500M tokens trained on (note the log scale on the x axis). Interestingly, this is notably earlier than the phase transition in the paper, I'm not sure what's up with that.\n",
    "\n",
    "(To contextualise the numbers, the tokens in the random sequence are uniformly chosen from the first 20,000 tokens (out of ~48,000 total), so random performance is at least $\\ln(20000)\\approx 10$. A naive strategy like \"randomly choose a token that's already appeared in the first half of the sequence (384 elements)\" would get $\\ln(384)\\approx 5.95$, so the model is doing pretty well here.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-08T19:28:15.051210Z",
     "iopub.status.busy": "2023-11-08T19:28:15.051050Z",
     "iopub.status.idle": "2023-11-08T19:28:15.081874Z",
     "shell.execute_reply": "2023-11-08T19:28:15.081404Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<html>\n",
       "<head><meta charset=\"utf-8\" /></head>\n",
       "<body>\n",
       "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
       "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.27.0.min.js\"></script>                <div id=\"e546d268-dd92-4d6b-8d41-2c2471e7bbea\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"e546d268-dd92-4d6b-8d41-2c2471e7bbea\")) {                    Plotly.newPlot(                        \"e546d268-dd92-4d6b-8d41-2c2471e7bbea\",                        [],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"value\"},\"type\":\"log\"},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"index\"}},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"Induction Loss over training: solu-2l\"}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('e546d268-dd92-4d6b-8d41-2c2471e7bbea');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                            </script>        </div>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "line(induction_losses, x=tokens_trained_on, xaxis=\"Tokens Trained On\", yaxis=\"Induction Loss\", title=\"Induction Loss over training: solu-2l\", markers=True, log_x=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "eb812820b5094695c8a581672e17220e30dd2c15d704c018326e3cc2e1a566f1"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0374f4ebe80844d99cb12d0b6d20c81b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "047c617474f3490b92f5ad7fb646e9ba": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_b053848dc6e14796925d11376a43df65",
       "placeholder": "​",
       "style": "IPY_MODEL_1468e63f954f4412a2e3cfca1bb9670d",
       "tabbable": null,
       "tooltip": null,
       "value": "Downloading (…)olve/main/merges.txt: 100%"
      }
     },
     "0652cfcd4a2f4d9cb51ac83d6c383c17": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "0a78ebe91db5451a82f859500c6a577d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_396287ce5a1249da9ccb7d8c681bff4b",
       "placeholder": "​",
       "style": "IPY_MODEL_29435b7ae80245bfb4486e6c6628fd24",
       "tabbable": null,
       "tooltip": null,
       "value": "Downloading (…)olve/main/vocab.json: 100%"
      }
     },
     "0c665847848d48939f774457f685c310": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0d93f50391df491abb6b0761e22c85e2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_f3b67fb5cdf14d7a8d545e22299599a2",
       "placeholder": "​",
       "style": "IPY_MODEL_75b1bd80a8a846fd944e4aee3b009840",
       "tabbable": null,
       "tooltip": null,
       "value": " 1.04M/1.04M [00:00&lt;00:00, 3.90MB/s]"
      }
     },
     "0dbec453b8bb478e8460b0c1d04cb880": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "10aa5f9051474a8b9d8c9c74607d2bd0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1468e63f954f4412a2e3cfca1bb9670d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "193653cbd70c45b5b96bb3a757ff3453": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "1b8977c1dc53463a9c2d4551314a4be7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1c9bd93966e644a1a5e8937b96d1aecb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1e70716705ea43cfbddd7e6754c80028": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_d661571ff27b4da196cde287e75c6612",
       "placeholder": "​",
       "style": "IPY_MODEL_c36d4e528d444938b7f2a583ef964d37",
       "tabbable": null,
       "tooltip": null,
       "value": " 12/12 [00:18&lt;00:00,  1.55s/it]"
      }
     },
     "2108f12bcbc045709b61bfcc69f45be4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_4e886c090b1e43c1be986a1de583d815",
       "max": 124.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_2823c1e8ff6946988029a29ed678dd10",
       "tabbable": null,
       "tooltip": null,
       "value": 124.0
      }
     },
     "243fe0588bc242f59607a502e38fbc83": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "27375efb45ef4e53ac4762e31c4a4590": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2823c1e8ff6946988029a29ed678dd10": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "29435b7ae80245bfb4486e6c6628fd24": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "396287ce5a1249da9ccb7d8c681bff4b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "39bb2ee6ad084d26a6f2ff601473ea90": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_0c665847848d48939f774457f685c310",
       "placeholder": "​",
       "style": "IPY_MODEL_8b908e3f25194e30adf2b6b77ab85a56",
       "tabbable": null,
       "tooltip": null,
       "value": "Downloading (…)neration_config.json: 100%"
      }
     },
     "410208d083654618886a270109132547": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "410b04b2c09543f99e0fe93210d6993b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_62ce74559dcf4ae4bd37fe63d04d747e",
       "placeholder": "​",
       "style": "IPY_MODEL_a3de35369afb4d3480a17201188e9926",
       "tabbable": null,
       "tooltip": null,
       "value": " 1.36M/1.36M [00:00&lt;00:00, 16.5MB/s]"
      }
     },
     "4c82e993ca20438fbdc6fc9274e53e99": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_c16a33d6b53049ef9bc7f2725dd0c579",
       "max": 352824413.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_af208ffc0a1548abb386c200695ab9da",
       "tabbable": null,
       "tooltip": null,
       "value": 352824413.0
      }
     },
     "4e886c090b1e43c1be986a1de583d815": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4ebf4cf6836546aaa2ced696a5bccdcd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4fbee53c45324073995782f51121083b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "57228d1bfa2c4d58ab253962be6991f8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5b63f83f988a497f88b2b8db0ef47f37": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_39bb2ee6ad084d26a6f2ff601473ea90",
        "IPY_MODEL_2108f12bcbc045709b61bfcc69f45be4",
        "IPY_MODEL_6d351068dc7d419c877f5d1306f9fb4d"
       ],
       "layout": "IPY_MODEL_1c9bd93966e644a1a5e8937b96d1aecb",
       "tabbable": null,
       "tooltip": null
      }
     },
     "5c1336468ece475bb714c80840747c1a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_0a78ebe91db5451a82f859500c6a577d",
        "IPY_MODEL_7c027117850a464388e053473c686542",
        "IPY_MODEL_0d93f50391df491abb6b0761e22c85e2"
       ],
       "layout": "IPY_MODEL_eba8b429c4b24424b5505259618c00c5",
       "tabbable": null,
       "tooltip": null
      }
     },
     "5f41ebf063df4f7ab31707e761ecaaa6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "62ce74559dcf4ae4bd37fe63d04d747e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "68770aabff654204bd6d7979864840e5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_afafaa4031c84df1bdba9aa5ff07b444",
        "IPY_MODEL_817b77bbf37c4da8bc81bfada484f642",
        "IPY_MODEL_410b04b2c09543f99e0fe93210d6993b"
       ],
       "layout": "IPY_MODEL_1b8977c1dc53463a9c2d4551314a4be7",
       "tabbable": null,
       "tooltip": null
      }
     },
     "6d351068dc7d419c877f5d1306f9fb4d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_410208d083654618886a270109132547",
       "placeholder": "​",
       "style": "IPY_MODEL_bc80279d126341cf86ac782bcf20db13",
       "tabbable": null,
       "tooltip": null,
       "value": " 124/124 [00:00&lt;00:00, 22.3kB/s]"
      }
     },
     "73266ab1ef4d4e60b3d2fa264a6c0b3f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "74c628f3de8043b7ad6c7fe05a13b924": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "75b1bd80a8a846fd944e4aee3b009840": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "7c027117850a464388e053473c686542": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_4ebf4cf6836546aaa2ced696a5bccdcd",
       "max": 1042301.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_abc901f3d205439c9517f1c01d7cf88b",
       "tabbable": null,
       "tooltip": null,
       "value": 1042301.0
      }
     },
     "7cc60d89418948b798343b9e20dd60e2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "7ecad4f76173496cb6831cdd7ef14580": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "80a236ce96164c0482d2743c95e8d333": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "817b77bbf37c4da8bc81bfada484f642": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_7ecad4f76173496cb6831cdd7ef14580",
       "max": 1355256.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_bb05700bcf2a4899bb8fc8e622434686",
       "tabbable": null,
       "tooltip": null,
       "value": 1355256.0
      }
     },
     "879a0d52cf184795a511bbf821cca63e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "889c5a207cf84320901b82d7bd112f15": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_c9f6339517534dff8ce2f579d41983d8",
        "IPY_MODEL_4c82e993ca20438fbdc6fc9274e53e99",
        "IPY_MODEL_a7c80ede40ca418894fa23eb84a1744b"
       ],
       "layout": "IPY_MODEL_95d580bf64b0449f957754ef9e633866",
       "tabbable": null,
       "tooltip": null
      }
     },
     "89ed6b9716734066842c2cb6e0fb2b49": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "8ac889a28ad34090834cf55c44e5d897": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8ad3bc18b18b4857b7014ebbc37dc996": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_bc76d1925410450db586fcbae2cd4e02",
       "max": 456318.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_5f41ebf063df4f7ab31707e761ecaaa6",
       "tabbable": null,
       "tooltip": null,
       "value": 456318.0
      }
     },
     "8b908e3f25194e30adf2b6b77ab85a56": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "90b9d97f3e2743d8b33fda14040a7c96": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_27375efb45ef4e53ac4762e31c4a4590",
       "placeholder": "​",
       "style": "IPY_MODEL_a2f5a1d46f784ccbaa04ce7cda933dff",
       "tabbable": null,
       "tooltip": null,
       "value": "100%"
      }
     },
     "93a4cf0cf9a24174a497e5db90fbdc46": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_047c617474f3490b92f5ad7fb646e9ba",
        "IPY_MODEL_8ad3bc18b18b4857b7014ebbc37dc996",
        "IPY_MODEL_d79ff597d05e409c9df93fd050afa1b3"
       ],
       "layout": "IPY_MODEL_57228d1bfa2c4d58ab253962be6991f8",
       "tabbable": null,
       "tooltip": null
      }
     },
     "95576ca76dc84d61959c6213bc97fdc3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_90b9d97f3e2743d8b33fda14040a7c96",
        "IPY_MODEL_e2eaad851b0347c8bae7736d607a861b",
        "IPY_MODEL_1e70716705ea43cfbddd7e6754c80028"
       ],
       "layout": "IPY_MODEL_ebc36b24e3d54701b8cff6defcca6dbd",
       "tabbable": null,
       "tooltip": null
      }
     },
     "95d580bf64b0449f957754ef9e633866": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a2f5a1d46f784ccbaa04ce7cda933dff": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "a3de35369afb4d3480a17201188e9926": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "a7c80ede40ca418894fa23eb84a1744b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_73266ab1ef4d4e60b3d2fa264a6c0b3f",
       "placeholder": "​",
       "style": "IPY_MODEL_7cc60d89418948b798343b9e20dd60e2",
       "tabbable": null,
       "tooltip": null,
       "value": " 353M/353M [00:01&lt;00:00, 209MB/s]"
      }
     },
     "abc901f3d205439c9517f1c01d7cf88b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "ae0ff6570ce340f2aa08782513c413ce": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "af208ffc0a1548abb386c200695ab9da": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "afafaa4031c84df1bdba9aa5ff07b444": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_e81435cb66df4fff8107e1a8b37e239f",
       "placeholder": "​",
       "style": "IPY_MODEL_0652cfcd4a2f4d9cb51ac83d6c383c17",
       "tabbable": null,
       "tooltip": null,
       "value": "Downloading (…)/main/tokenizer.json: 100%"
      }
     },
     "b053848dc6e14796925d11376a43df65": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b195d2f5abca4a85ac28a2331fb32435": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_ff7f4932e69340c2b93c77ec267cf32d",
        "IPY_MODEL_b38d8caf8f7b42e7ac06fd57c4e262c7",
        "IPY_MODEL_cab3709d411947b39f4a646d8202af08"
       ],
       "layout": "IPY_MODEL_0dbec453b8bb478e8460b0c1d04cb880",
       "tabbable": null,
       "tooltip": null
      }
     },
     "b38d8caf8f7b42e7ac06fd57c4e262c7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_d75483ef53f44abbbd0c314a612a23f2",
       "max": 50.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_4fbee53c45324073995782f51121083b",
       "tabbable": null,
       "tooltip": null,
       "value": 50.0
      }
     },
     "bb05700bcf2a4899bb8fc8e622434686": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "bc76d1925410450db586fcbae2cd4e02": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "bc80279d126341cf86ac782bcf20db13": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "c16a33d6b53049ef9bc7f2725dd0c579": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c36d4e528d444938b7f2a583ef964d37": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "c9f6339517534dff8ce2f579d41983d8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_879a0d52cf184795a511bbf821cca63e",
       "placeholder": "​",
       "style": "IPY_MODEL_ae0ff6570ce340f2aa08782513c413ce",
       "tabbable": null,
       "tooltip": null,
       "value": "Downloading model.safetensors: 100%"
      }
     },
     "cab3709d411947b39f4a646d8202af08": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_80a236ce96164c0482d2743c95e8d333",
       "placeholder": "​",
       "style": "IPY_MODEL_89ed6b9716734066842c2cb6e0fb2b49",
       "tabbable": null,
       "tooltip": null,
       "value": " 50/50 [00:02&lt;00:00, 24.60it/s]"
      }
     },
     "d661571ff27b4da196cde287e75c6612": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d75483ef53f44abbbd0c314a612a23f2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d79ff597d05e409c9df93fd050afa1b3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_10aa5f9051474a8b9d8c9c74607d2bd0",
       "placeholder": "​",
       "style": "IPY_MODEL_74c628f3de8043b7ad6c7fe05a13b924",
       "tabbable": null,
       "tooltip": null,
       "value": " 456k/456k [00:00&lt;00:00, 2.79MB/s]"
      }
     },
     "e2eaad851b0347c8bae7736d607a861b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_8ac889a28ad34090834cf55c44e5d897",
       "max": 12.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_193653cbd70c45b5b96bb3a757ff3453",
       "tabbable": null,
       "tooltip": null,
       "value": 12.0
      }
     },
     "e81435cb66df4fff8107e1a8b37e239f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "eba8b429c4b24424b5505259618c00c5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ebc36b24e3d54701b8cff6defcca6dbd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f3b67fb5cdf14d7a8d545e22299599a2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ff7f4932e69340c2b93c77ec267cf32d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_243fe0588bc242f59607a502e38fbc83",
       "placeholder": "​",
       "style": "IPY_MODEL_0374f4ebe80844d99cb12d0b6d20c81b",
       "tabbable": null,
       "tooltip": null,
       "value": "100%"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
