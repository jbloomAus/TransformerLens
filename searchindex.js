Search.setIndex({"docnames": ["content/citation", "content/development", "content/gallery", "content/getting_started", "content/tutorials", "easy_transformer", "index", "modules", "setup", "transformer_lens", "typing_demo"], "filenames": ["content/citation.md", "content/development.md", "content/gallery.md", "content/getting_started.md", "content/tutorials.md", "easy_transformer.rst", "index.md", "modules.rst", "setup.rst", "transformer_lens.rst", "typing_demo.rst"], "titles": ["Citation", "Local Development", "Gallery", "Getting Started", "Tutorials", "easy_transformer package", "TransformerLens", "TransformerLens", "setup module", "transformer_lens package", "typing_demo module"], "terms": {"pleas": [0, 1, 3], "cite": 0, "thi": [0, 1, 3, 6, 9], "librari": [0, 1, 2, 3, 4, 9], "misc": 0, "nandatransformerlens2022": 0, "titl": 0, "transformerlen": [0, 1, 3, 9], "author": 0, "nanda": [0, 9], "neel": [0, 9], "url": 0, "http": [0, 3, 9], "github": [0, 1, 3, 9], "com": [0, 3, 9], "neelnanda": [0, 3, 9], "io": [0, 3, 9], "year": 0, "2022": [0, 9], "i": [0, 3, 4, 6, 9], "my": [0, 3, 4, 6, 9], "best": [0, 9], "guess": 0, "how": [0, 3, 4, 6, 9], "softwar": 0, "work": [0, 2, 3, 4, 6, 9], "feel": [0, 6], "free": 0, "send": 0, "correct": [0, 9], "also": [0, 1, 9], "you": [0, 1, 3, 6, 9], "re": [0, 3, 9], "actual": [0, 9], "us": [0, 1, 2, 3, 4, 6, 9], "your": [0, 1, 9], "research": [0, 3, 4, 6], "d": [0, 9], "love": 0, "chat": 0, "reach": [0, 9], "out": [0, 3, 4, 9], "neelnanda27": 0, "gmail": 0, "For": [1, 9], "one": [1, 3, 6, 9], "click": 1, "environ": 1, "project": [1, 9], "includ": [1, 9], "It": [1, 3, 6, 9], "can": [1, 2, 3, 6, 9], "v": [1, 9], "code": [1, 9], "codespac": 1, "poetri": 1, "packag": [1, 7], "manag": [1, 9], "instal": 1, "follow": [1, 6, 9], "virtual": 1, "config": [1, 9], "virtualenv": 1, "true": [1, 9], "dev": 1, "option": [1, 9], "want": [1, 9], "jupyt": 1, "lab": 1, "run": [1, 3, 6, 9], "pip": [1, 3], "jupyterlab": 1, "same": [1, 3, 9], "Then": [1, 9], "import": [1, 3, 6, 9], "transformer_len": [1, 3, 7], "If": [1, 3, 9], "ad": [1, 9], "featur": [1, 3, 4, 6, 9], "add": [1, 6, 9], "unit": 1, "folder": 1, "check": [1, 3, 4, 9], "hasn": [1, 9], "t": [1, 6, 7, 9], "broken": [1, 9], "anyth": [1, 9], "major": 1, "exist": 1, "pytest": 1, "root": 1, "directori": 1, "To": [1, 3, 4, 9], "command": 1, "user": [2, 9], "contribut": [2, 9], "exampl": [2, 9], "being": [2, 9], "action": 2, "induct": [2, 9], "head": [2, 9], "phase": 2, "chang": [2, 3, 9], "replic": [2, 9], "A": [2, 9], "partial": [2, 9], "In": [2, 9], "context": [2, 9], "learn": [2, 3, 4, 6, 9], "from": [2, 3, 6, 9], "connor": 2, "kissan": 2, "decis": [2, 3], "transform": [2, 3, 4, 9], "interpret": [2, 3, 9], "set": [2, 9], "script": 2, "train": [2, 6, 7], "which": [2, 3, 9], "len": 2, "view": 2, "intermedi": [2, 9], "activ": [2, 3, 6, 9], "perform": [2, 9], "attribut": [2, 9], "ablat": 2, "write": [2, 3, 6, 9], "up": [2, 3, 9], "initi": [2, 9], "found": [2, 9], "here": [2, 9], "main": [3, 4, 9], "demo": [3, 4, 9], "basic": [3, 4, 9], "see": [3, 4, 6, 9], "what": [3, 4, 6, 9], "exploratori": [3, 4, 6, 9], "analysi": [3, 4, 6, 9], "practic": [3, 4], "look": [3, 4, 9], "like": [3, 4, 6, 9], "notebook": [3, 4, 6, 9], "analys": [3, 4, 9], "indirect": [3, 4], "object": [3, 4, 9], "identif": [3, 4], "record": [3, 4], "myself": [3, 4], "do": [3, 4, 6, 9], "mechanist": 3, "veri": [3, 6, 9], "young": 3, "small": [3, 6, 9], "field": [3, 6, 9], "ar": [3, 6, 9], "lot": [3, 6, 9], "open": [3, 6, 9], "problem": [3, 6], "would": [3, 6], "help": [3, 9], "try": [3, 9], "list": [3, 9], "concret": 3, "figur": 3, "where": [3, 9], "begin": [3, 9], "skill": 3, "kei": [3, 7, 9], "resourc": 3, "new": [3, 9], "tutori": 3, "gpt": [3, 6, 9], "2": [3, 6, 9], "scratch": 3, "an": [3, 6, 9], "accompani": 3, "templat": 3, "yourself": [3, 9], "One": [3, 6], "signific": [3, 9], "design": [3, 6, 9], "made": 3, "wa": [3, 9], "have": [3, 6, 9], "singl": [3, 9], "implement": [3, 9], "could": [3, 9], "support": [3, 9], "rang": [3, 9], "subtli": [3, 9], "differ": [3, 9], "style": [3, 6, 9], "model": [3, 9], "ha": [3, 9], "upsid": 3, "just": [3, 9], "arbitrari": [3, 9], "when": [3, 9], "name": [3, 9], "hookedtransform": [3, 7], "from_pretrain": [3, 7, 9], "But": [3, 9], "downsid": 3, "py": [3, 9], "compon": [3, 7], "difficult": 3, "recommend": [3, 9], "clean": [3, 9], "minim": 3, "intern": [3, 6, 9], "architectur": 3, "significantli": [3, 9], "clearer": 3, "better": [3, 9], "document": [3, 9], "git": 3, "note": [3, 9], "known": [3, 6], "easytransform": [3, 6], "some": [3, 9], "break": [3, 9], "been": [3, 9], "sinc": [3, 9], "renam": 3, "need": [3, 6, 9], "old": [3, 9], "version": [3, 9], "legaci": 3, "v1": 3, "start": [4, 9], "tutoti": 4, "formerli": 6, "The": [6, 9], "goal": 6, "take": [6, 9], "revers": [6, 9], "engin": 6, "algorithm": [6, 9], "dure": 6, "its": [6, 9], "weight": [6, 9], "fact": 6, "about": [6, 9], "world": 6, "todai": 6, "we": [6, 9], "comput": [6, 9], "program": 6, "essenti": [6, 9], "speak": 6, "english": 6, "human": 6, "level": 6, "3": [6, 9], "palm": 6, "etc": [6, 9], "yet": [6, 9], "idea": [6, 9], "thei": [6, 9], "nor": 6, "ourselv": [6, 9], "offend": 6, "me": [6, 9], "greatli": 6, "solv": [6, 9], "let": [6, 9], "load": [6, 9], "sourc": [6, 9], "expos": [6, 9], "cach": [6, 9], "ani": [6, 9], "function": [6, 9], "edit": [6, 9], "remov": [6, 9], "replac": [6, 9], "core": 6, "principl": 6, "ve": [6, 9], "enabl": [6, 9], "most": [6, 9], "fun": 6, "part": [6, 9], "compar": [6, 9], "normal": [6, 9], "ml": 6, "extrem": 6, "short": [6, 9], "feedback": [6, 9], "loop": [6, 9], "point": [6, 9], "keep": [6, 9], "gap": 6, "between": [6, 9], "experi": [6, 9], "result": [6, 9], "possibl": [6, 9], "make": [6, 9], "easi": [6, 9], "plai": 6, "enter": [6, 9], "flow": 6, "state": [6, 9], "aim": 6, "easier": [6, 9], "more": [6, 9], "hopefulli": [6, 9], "transfer": 6, "anthrop": 6, "team": 6, "wrote": 6, "becaus": [6, 9], "after": [6, 9], "left": [6, 9], "tri": 6, "independ": 6, "got": [6, 9], "frustrat": 6, "tool": 6, "There": [6, 9], "": [6, 7, 9], "excel": 6, "infrastructur": [6, 9], "huggingfac": [6, 9], "deepspe": 6, "littl": 6, "dig": 6, "get": [6, 9], "even": [6, 9], "don": [6, 9], "industri": 6, "org": [6, 9], "real": 6, "great": 6, "thing": [6, 9], "larg": [6, 9], "ton": [6, 9], "colab": 6, "were": [6, 9], "heavili": 6, "inspir": 6, "interfac": [6, 9], "garcon": 6, "credit": 6, "nelson": 6, "elhag": 6, "chri": 6, "olah": 6, "build": [6, 9], "show": 6, "valu": [6, 7, 9], "good": [6, 9], "easy_transform": 7, "modul": 7, "content": 7, "setup": [7, 9], "submodul": 7, "activationcach": 7, "accumulated_resid": [7, 9], "apply_ln_to_stack": [7, 9], "apply_slice_to_batch_dim": [7, 9], "compute_head_result": [7, 9], "decompose_resid": [7, 9], "get_full_resid_decomposit": [7, 9], "get_neuron_result": [7, 9], "item": [7, 9], "remove_batch_dim": [7, 9], "stack_activ": [7, 9], "stack_head_result": [7, 9], "stack_neuron_result": [7, 9], "toggle_autodiff": [7, 9], "factoredmatrix": 7, "ab": [7, 9], "ba": [7, 9], "u": [7, 9], "vh": [7, 9], "collapse_l": [7, 9], "collapse_r": [7, 9], "eigenvalu": [7, 9], "get_corn": [7, 9], "make_even": [7, 9], "ndim": [7, 9], "norm": [7, 9], "pair": [7, 9], "svd": [7, 9], "unsqueez": [7, 9], "ov": [7, 9], "qk": [7, 9], "w_e": [7, 9], "w_e_po": [7, 9], "w_k": [7, 9], "w_o": [7, 9], "w_q": [7, 9], "w_u": [7, 9], "w_v": [7, 9], "w_in": [7, 9], "w_out": [7, 9], "w_po": [7, 9], "accumulated_bia": [7, 9], "all_composition_scor": [7, 9], "all_head_label": [7, 9], "b_k": [7, 9], "b_o": [7, 9], "b_q": [7, 9], "b_u": [7, 9], "b_v": [7, 9], "b_in": [7, 9], "b_out": [7, 9], "center_unemb": [7, 9], "center_writing_weight": [7, 9], "cpu": [7, 9], "cuda": [7, 9], "fill_missing_kei": [7, 9], "fold_layer_norm": [7, 9], "fold_value_bias": [7, 9], "forward": [7, 9], "from_pretrained_no_process": [7, 9], "gener": [7, 9], "get_token_posit": [7, 9], "init_weight": [7, 9], "load_and_process_state_dict": [7, 9], "load_sample_training_dataset": [7, 9], "loss_fn": [7, 9], "process_weights_": [7, 9], "refactor_factored_attn_matric": [7, 9], "run_with_cach": [7, 9], "sample_datapoint": [7, 9], "set_token": [7, 9], "set_use_attn_result": [7, 9], "to_single_token": [7, 9], "to_str_token": [7, 9], "to_str": [7, 9], "to_token": [7, 9], "tokens_to_residual_direct": [7, 9], "output": [7, 9], "logit": [7, 9], "loss": [7, 9], "hookedtransformerconfig": 7, "act_fn": [7, 9], "attention_dir": [7, 9], "attn_onli": [7, 9], "attn_typ": [7, 9], "checkpoint_index": [7, 9], "checkpoint_label_typ": [7, 9], "checkpoint_valu": [7, 9], "d_head": [7, 9], "d_mlp": [7, 9], "d_model": [7, 9], "d_vocab": [7, 9], "d_vocab_out": [7, 9], "devic": [7, 9], "ep": [7, 9], "final_rm": [7, 9], "from_checkpoint": [7, 9], "from_dict": [7, 9], "init_mod": [7, 9], "initializer_rang": [7, 9], "model_nam": [7, 9], "n_ctx": [7, 9], "n_head": [7, 9], "n_layer": [7, 9], "n_param": [7, 9], "normalization_typ": [7, 9], "original_architectur": [7, 9], "parallel_attn_mlp": [7, 9], "positional_embedding_typ": [7, 9], "rotary_dim": [7, 9], "scale_attn_by_inverse_layer_idx": [7, 9], "seed": [7, 9], "set_seed_everywher": [7, 9], "to_dict": [7, 9], "tokenizer_nam": [7, 9], "use_attn_result": [7, 9], "use_attn_scal": [7, 9], "use_hook_token": [7, 9], "use_local_attn": [7, 9], "window_s": [7, 9], "attent": [7, 9], "apply_causal_mask": [7, 9], "apply_rotari": [7, 9], "calculate_sin_cos_rotari": [7, 9], "rotary_rotate_qk": [7, 9], "rotate_every_two": [7, 9], "shortformer_calculate_qk": [7, 9], "emb": [7, 9], "layernorm": [7, 9], "layernormpr": [7, 9], "mlp": [7, 9], "posemb": [7, 9], "rmsnorm": [7, 9], "rmsnormpr": [7, 9], "transformerblock": [7, 9], "unemb": [7, 9], "eval": 7, "evalu": [7, 9], "evaluate_on_dataset": [7, 9], "induction_loss": [7, 9], "make_code_data_load": [7, 9], "make_owt_data_load": [7, 9], "make_pile_data_load": [7, 9], "make_wiki_data_load": [7, 9], "sanity_check": [7, 9], "hook_point": 7, "hookpoint": [7, 9], "add_hook": [7, 9], "add_perma_hook": [7, 9], "clear_context": [7, 9], "layer": [7, 9], "remove_hook": [7, 9], "hookedrootmodul": [7, 9], "add_caching_hook": [7, 9], "cache_al": [7, 9], "cache_som": [7, 9], "remove_all_hook_fn": [7, 9], "reset_hook": [7, 9], "run_with_hook": [7, 9], "lenshandl": [7, 9], "hook": [7, 9], "is_perman": [7, 9], "loading_from_pretrain": 7, "convert_gpt2_weight": [7, 9], "convert_gptj_weight": [7, 9], "convert_hf_model_config": [7, 9], "convert_neel_model_config": [7, 9], "convert_neel_solu_old_weight": [7, 9], "convert_neo_weight": [7, 9], "convert_neox_weight": [7, 9], "convert_opt_weight": [7, 9], "convert_state_dict": [7, 9], "get_checkpoint_label": [7, 9], "get_num_params_of_pretrain": [7, 9], "get_official_model_nam": [7, 9], "get_pretrained_model_config": [7, 9], "get_pretrained_state_dict": [7, 9], "make_model_alias_map": [7, 9], "make_doc": 7, "past_key_value_cach": 7, "hookedtransformerkeyvaluecach": [7, 9], "entri": [7, 9], "init_cach": [7, 9], "hookedtransformerkeyvaluecacheentri": [7, 9], "append": [7, 9], "init_cache_entri": [7, 9], "past_kei": [7, 9], "past_valu": [7, 9], "patch": 7, "generic_activation_patch": [7, 9], "get_act_patch_attn_head_all_pos_everi": [7, 9], "get_act_patch_attn_head_by_pos_everi": [7, 9], "get_act_patch_attn_head_k_all_po": [7, 9], "get_act_patch_attn_head_k_by_po": [7, 9], "get_act_patch_attn_head_out_all_po": [7, 9], "get_act_patch_attn_head_out_by_po": [7, 9], "get_act_patch_attn_head_pattern_all_po": [7, 9], "get_act_patch_attn_head_pattern_by_po": [7, 9], "get_act_patch_attn_head_pattern_dest_src_po": [7, 9], "get_act_patch_attn_head_q_all_po": [7, 9], "get_act_patch_attn_head_q_by_po": [7, 9], "get_act_patch_attn_head_v_all_po": [7, 9], "get_act_patch_attn_head_v_by_po": [7, 9], "get_act_patch_attn_out": [7, 9], "get_act_patch_block_everi": [7, 9], "get_act_patch_mlp_out": [7, 9], "get_act_patch_resid_mid": [7, 9], "get_act_patch_resid_pr": [7, 9], "layer_head_dest_src_pos_pattern_patch_sett": [7, 9], "layer_head_pattern_patch_sett": [7, 9], "layer_head_pos_pattern_patch_sett": [7, 9], "layer_head_vector_patch_sett": [7, 9], "layer_pos_head_vector_patch_sett": [7, 9], "layer_pos_patch_sett": [7, 9], "make_df_from_rang": [7, 9], "torchtyping_help": 7, "b": [7, 9], "batch": [7, 9], "batch_and_pos_dim": [7, 9], "d_vocab_plus_n_ctx": [7, 9], "head_index": [7, 9], "layers_accumulated_ov": [7, 9], "layers_cov": [7, 9], "ldim": [7, 9], "leading_dim": [7, 9], "leading_dims_left": [7, 9], "leading_dims_right": [7, 9], "length": [7, 9], "mdim": [7, 9], "new_rdim": [7, 9], "new_token": [7, 9], "num_compon": [7, 9], "num_neuron": [7, 9], "past_kv_pos_offset": [7, 9], "po": [7, 9], "pos_plus_new_token": [7, 9], "pos_plus_past_kv_pos_offset": [7, 9], "pos_so_far": [7, 9], "rdim": [7, 9], "hookedtransformertrainconfig": [7, 9], "batch_siz": [7, 9], "lr": [7, 9], "max_grad_norm": [7, 9], "max_step": [7, 9], "momentum": [7, 9], "num_epoch": [7, 9], "optimizer_nam": [7, 9], "print_everi": [7, 9], "save_dir": [7, 9], "save_everi": [7, 9], "wandb": [7, 9], "wandb_project_nam": [7, 9], "warmup_step": [7, 9], "weight_decai": [7, 9], "util": 7, "slice": [7, 9], "appli": [7, 9], "indic": [7, 9], "composition_scor": [7, 9], "download_file_from_hf": [7, 9], "gelu_fast": [7, 9], "gelu_new": [7, 9], "get_act_nam": [7, 9], "get_dataset": [7, 9], "keep_single_column": [7, 9], "lm_accuraci": [7, 9], "lm_cross_entropy_loss": [7, 9], "print_gpu_mem": [7, 9], "sample_logit": [7, 9], "solu": [7, 9], "test_prompt": [7, 9], "to_numpi": [7, 9], "tokenize_and_concaten": [7, 9], "transpos": [7, 9], "typing_demo": 7, "test": [7, 9, 10], "test2": [7, 10], "test3": [7, 10], "test4": [7, 10], "class": 9, "cache_dict": 9, "dict": 9, "str": 9, "tensor": [9, 10], "has_batch_dim": 9, "bool": 9, "base": 9, "wrapper": 9, "around": 9, "dictionari": 9, "varieti": 9, "helper": 9, "specif": 9, "process": 9, "should": 9, "method": 9, "while": 9, "other": 9, "all": 9, "without": 9, "warn": 9, "biggest": 9, "footgun": 9, "bug": 9, "track": 9, "index": 9, "dimens": 9, "number": 9, "each": 9, "sever": 9, "kind": 9, "attn": 9, "vector": 9, "q": 9, "k": 9, "z": 9, "shape": 9, "pattern": 9, "post": 9, "softmax": 9, "attn_scor": 9, "pre": 9, "query_po": 9, "key_po": 9, "mid": 9, "onli": 9, "solu_ln": 9, "residu": 9, "stream": 9, "resid_pr": 9, "resid_mid": 9, "resid_post": 9, "attn_out": 9, "mlp_out": 9, "pos_emb": 9, "ln": 9, "lnpre": 9, "scale": 9, "1": 9, "sometim": 9, "miss": 9, "robust": 9, "think": 9, "everyth": 9, "easili": 9, "wrong": 9, "type": 9, "annot": 9, "queri": 9, "stack": 9, "default": 9, "posit": 9, "int": 9, "none": 9, "incl_mid": 9, "fals": 9, "pos_slic": 9, "union": 9, "sliceinput": 9, "mlp_input": 9, "return_label": 9, "tt": 9, "return": 9, "accumul": 9, "given": 9, "ie": 9, "previou": 9, "input": 9, "thought": 9, "seri": 9, "gradual": 9, "paramet": 9, "exclud": 9, "mean": 9, "final": 9, "immedi": 9, "taken": 9, "give": 9, "l": 9, "whether": 9, "current": 9, "rather": 9, "than": 9, "noth": 9, "label": 9, "graph": 9, "residual_stack": 9, "eg": 9, "treat": 9, "them": 9, "factor": 9, "simul": 9, "global": 9, "across": 9, "entir": 9, "element": 9, "why": 9, "doe": 9, "unchang": 9, "torch": 9, "whose": 9, "trail": 9, "assum": 9, "store": 9, "hook_scal": 9, "mai": 9, "0": 9, "map": 9, "case": 9, "ln2": 9, "ln1": 9, "must": 9, "ln_final": 9, "over": 9, "full": 9, "alreadi": 9, "detail": 9, "batch_slic": 9, "tupl": 9, "amount": 9, "sum": 9, "plu": 9, "intend": 9, "forget": 9, "mode": 9, "liter": 9, "incl_emb": 9, "decompos": 9, "embed": 9, "behaviour": 9, "incl": 9, "expand_neuron": 9, "apply_ln": 9, "decomposit": 9, "neuron": 9, "bias": 9, "down": 9, "expand": 9, "everi": 9, "neuron_slic": 9, "much": 9, "subset": 9, "specifi": 9, "expens": 9, "space": 9, "cheap": 9, "axi": 9, "activation_nam": 9, "sublayer_typ": 9, "wai": 9, "exactli": 9, "lead": 9, "strictli": 9, "befor": 9, "sub": 9, "pass": 9, "infer": 9, "incl_remaind": 9, "term": 9, "rest": 9, "x": [9, 10], "einop": 9, "notat": 9, "form": 9, "l0h0": 9, "individu": 9, "l0n0": 9, "super": 9, "gpu": 9, "memori": 9, "move_model": 9, "move": 9, "mostli": 9, "finish": 9, "save": 9, "matmul": 9, "slower": 9, "unless": 9, "autodiff": 9, "turn": 9, "off": 9, "pretti": 9, "danger": 9, "abil": 9, "gradient": 9, "complet": 9, "bunch": 9, "error": 9, "realis": 9, "consum": 9, "until": 9, "downstream": 9, "delet": 9, "stick": 9, "so": 9, "often": 9, "troubl": 9, "worth": 9, "mess": 9, "inference_mod": 9, "decor": 9, "achiev": 9, "similar": 9, "effect": 9, "repres": 9, "low": 9, "rank": 9, "matric": 9, "matrix": 9, "product": 9, "two": 9, "effici": 9, "calcul": 9, "properti": 9, "sens": 9, "collaps": 9, "side": 9, "orthogon": 9, "self": 9, "analog": 9, "apart": 9, "zero": 9, "bav": 9, "kv": 9, "abav": 9, "kav": 9, "av": 9, "eigenvector": 9, "sqrt": 9, "diag": 9, "equival": 9, "factoris": 9, "half": 9, "singular": 9, "row": 9, "col": 9, "frobeniu": 9, "squar": 9, "find": 9, "m": 9, "st": 9, "obviou": 9, "cfg": 9, "token": 9, "move_to_devic": 9, "interest": 9, "inherit": 9, "pretrain": 9, "automat": 9, "via": 9, "instanti": 9, "randomli": 9, "__init__": 9, "conveni": 9, "concaten": 9, "overcomplet": 9, "basi": 9, "circuit": 9, "unembed": 9, "linear": 9, "absolut": 9, "include_mlp_bias": 9, "bia": 9, "otherwis": 9, "composit": 9, "score": 9, "l1": 9, "h1": 9, "l2": 9, "h2": 9, "upper": 9, "triangular": 9, "first": 9, "third": 9, "ax": 9, "pub": 9, "2021": 9, "framework": 9, "html": 9, "text": 9, "20abov": 9, "20diagram": 9, "20show": 9, "20q": 9, "2d": 9, "2c": 9, "20k": 9, "20and": 9, "20v": 9, "2dcomposit": 9, "three": 9, "metric": 9, "state_dict": 9, "center": 9, "done": 9, "subtract": 9, "themselv": 9, "place": 9, "As": 9, "translat": 9, "invari": 9, "log": 9, "prob": 9, "slightli": 9, "understand": 9, "ll": 9, "less": 9, "misl": 9, "someth": 9, "buffer": 9, "modifi": 9, "associ": 9, "call": 9, "construct": 9, "optim": 9, "live": 9, "copi": 9, "fill": 9, "format": 9, "consist": 9, "fold": 9, "neighbour": 9, "further_com": 9, "md": 9, "alwai": 9, "constant": 9, "further": 9, "togeth": 9, "harder": 9, "doesn": 9, "matter": 9, "formal": 9, "b_o_new": 9, "b_o_origin": 9, "sum_head": 9, "b_v_head": 9, "w_o_head": 9, "return_typ": 9, "loss_per_token": 9, "prepend_bo": 9, "stop_at_lay": 9, "past_kv_cach": 9, "both": 9, "either": 9, "string": 9, "flag": 9, "cross": 9, "entropi": 9, "next": 9, "predict": 9, "per": 9, "averag": 9, "scalar": 9, "prepend": 9, "bo": 9, "unlik": 9, "explicitli": 9, "accordingli": 9, "lose": 9, "inform": 9, "empir": 9, "seem": 9, "stop": 9, "exclus": 9, "block": 9, "neg": 9, "24": 9, "standard": 9, "languag": 9, "custom": 9, "classmethod": 9, "fold_ln": 9, "hf_model": 9, "move_state_dict_to_devic": 9, "model_kwarg": 9, "autoregress": 9, "gpt2": 9, "gptneo": 9, "gptj": 9, "opt": 9, "toi": 9, "checkpoint": 9, "stanford": 9, "crfm": 9, "These": 9, "determin": 9, "1000": 9, "step": 9, "neither": 9, "official_model_nam": 9, "alia": 9, "subsequ": 9, "due": 9, "affect": 9, "convert": 9, "automodelforcausallm": 9, "recreat": 9, "onto": 9, "By": 9, "avail": 9, "els": 9, "relev": 9, "addit": 9, "kwarg": 9, "from_pretrained_kwarg": 9, "boolean": 9, "relat": 9, "simplifi": 9, "refer": 9, "max_new_token": 9, "10": 9, "stop_at_eo": 9, "eos_token_id": 9, "do_sampl": 9, "top_k": 9, "top_p": 9, "float": 9, "temperatur": 9, "freq_penalti": 9, "num_return_sequ": 9, "use_past_kv_cach": 9, "sampl": 9, "eos_token": 9, "avoid": 9, "fiddl": 9, "rag": 9, "sequenc": 9, "produc": 9, "eot": 9, "throw": 9, "awai": 9, "pad": 9, "messi": 9, "instead": 9, "size": 9, "maximum": 9, "id": 9, "end": 9, "sentenc": 9, "requir": 9, "distribut": 9, "greedi": 9, "search": 9, "max": 9, "time": 9, "probabl": 9, "mass": 9, "top": 9, "cumul": 9, "higher": 9, "random": 9, "limit": 9, "temp": 9, "inf": 9, "uniform": 9, "frequenc": 9, "penalti": 9, "penalis": 9, "creat": 9, "speed": 9, "bos_token_id": 9, "irrelev": 9, "whatev": 9, "single_token": 9, "rais": 9, "present": 9, "gotcha": 9, "Be": 9, "care": 9, "prompt": 9, "weird": 9, "carefulli": 9, "correspond": 9, "dummi": 9, "multipl": 9, "match": 9, "last": 9, "ignor": 9, "std": 9, "02": 9, "roughli": 9, "paper": 9, "scheme": 9, "truncat": 9, "halv": 9, "empti": 9, "bulk": 9, "w_": 9, "ensur": 9, "NOT": 9, "pytorch": 9, "far": 9, "tell": 9, "date": 9, "gotten": 9, "round": 9, "updat": 9, "issu": 9, "18182": 9, "especi": 9, "bad": 9, "transformerencod": 9, "exact": 9, "72253": 9, "mup": 9, "haven": 9, "integr": 9, "those": 9, "arxiv": 9, "2203": 9, "03466": 9, "10k": 9, "dataset": 9, "data": 9, "identifi": 9, "appropri": 9, "contain": 9, "info": 9, "meta": 9, "e": 9, "g": 9, "cache_dir": 9, "download": 9, "locat": 9, "openwebtext": 9, "link": 9, "karma": 9, "reddit": 9, "hard": 9, "pile": 9, "cover": 9, "imperfectli": 9, "suppli": 9, "valid": 9, "per_token": 9, "allow": 9, "cleaner": 9, "experiment": 9, "argu": 9, "mathemat": 9, "somewhat": 9, "w_qk": 9, "w_ov": 9, "mani": 9, "attempt": 9, "column": 9, "rotat": 9, "nth": 9, "formula": 9, "r": 9, "well": 9, "now": 9, "refactor": 9, "diagon": 9, "asymmetri": 9, "fiddli": 9, "deal": 9, "preserv": 9, "along": 9, "too": 9, "bilinear": 9, "y": 9, "fairli": 9, "dimension": 9, "coordin": 9, "separ": 9, "model_arg": 9, "return_cache_object": 9, "implicitli": 9, "manual": 9, "choic": 9, "pretrainedtoken": 9, "toggl": 9, "burn": 9, "through": 9, "device_or_dtyp": 9, "print_detail": 9, "dtype": 9, "uncertain": 9, "weirdli": 9, "sure": 9, "gotcha2": 9, "depend": 9, "preced": 9, "letter": 9, "capit": 9, "shoot": 9, "foot": 9, "str_token": 9, "ndarrai": 9, "accept": 9, "numpi": 9, "arrai": 9, "long": 9, "window": 9, "shorter": 9, "dot": 9, "mislead": 9, "incorrect": 9, "direct": 9, "integ": 9, "residual_direct": 9, "namedtupl": 9, "1e": 9, "05": 9, "causal": 9, "configur": 9, "complex": 9, "argument": 9, "AND": 9, "feedforward": 9, "network": 9, "4": 9, "vocabulari": 9, "vocab": 9, "lowercas": 9, "relu": 9, "gelu": 9, "silu": 9, "epsilon": 9, "5": 9, "THEN": 9, "intens": 9, "famili": 9, "access": 9, "local": 9, "destin": 9, "attend": 9, "certain": 9, "distanc": 9, "back": 9, "weight_init_mod": 9, "aka": 9, "unidirect": 9, "bidirect": 9, "python": 9, "reproduc": 9, "deviat": 9, "initialis": 9, "8": 9, "layer_id": 9, "mistral": 9, "numer": 9, "stabil": 9, "fp16": 9, "directli": 9, "rotari": 9, "describ": 9, "blog": 9, "eleuth": 9, "ai": 9, "shortform": 9, "res_stream": 9, "sinusoid": 9, "dumb": 9, "origin": 9, "equal": 9, "mainli": 9, "task": 9, "parallel": 9, "curs": 9, "j": 9, "hidden": 9, "non": 9, "law": 9, "pdf": 9, "2001": 9, "08361": 9, "meaning": 9, "Will": 9, "interven": 9, "config_dict": 9, "defin": 9, "pure": 9, "glossari": 9, "order": 9, "multipli": 9, "right": 9, "sorri": 9, "lru_cach": 9, "sai": 9, "investig": 9, "underli": 9, "destination_residu": 9, "destination_po": 9, "source_po": 9, "10000": 9, "sine": 9, "cosin": 9, "wave": 9, "inexplic": 9, "reason": 9, "adjac": 9, "neox": 9, "n": 9, "clue": 9, "resolv": 9, "shortformer_pos_emb": 9, "past_kv_cache_entri": 9, "past": 9, "split": 9, "x0": 9, "x1": 9, "overridden": 9, "subclass": 9, "although": 9, "recip": 9, "within": 9, "instanc": 9, "afterward": 9, "former": 9, "regist": 9, "latter": 9, "silent": 9, "unus": 9, "broadcast": 9, "dim": 9, "block_index": 9, "positional_embeddings_typ": 9, "_description_": 9, "_type_": 9, "file": 9, "rough": 9, "expect": 9, "properli": 9, "cheapli": 9, "baselin": 9, "100": 9, "data_load": 9, "subseq_len": 9, "384": 9, "repeat": 9, "twice": 9, "measur": 9, "second": 9, "codeparrot": 9, "dump": 9, "lower": 9, "presum": 9, "natur": 9, "corpu": 9, "wikitext": 9, "wikipedia": 9, "articl": 9, "larger": 9, "realli": 9, "anyon": 9, "bother": 9, "quarantin": 9, "nowadai": 9, "leakag": 9, "though": 9, "believ": 9, "feed": 9, "paragraph": 9, "zoom": 9, "quick": 9, "saniti": 9, "ok": 9, "7": 9, "gone": 9, "dir": 9, "fwd": 9, "including_perman": 9, "arg": 9, "nn": 9, "nice": 9, "variou": 9, "notabl": 9, "temporari": 9, "persist": 9, "debug": 9, "fix": 9, "still": 9, "api": 9, "intent": 9, "liber": 9, "accident": 9, "remain": 9, "goe": 9, "backward": 9, "disabl": 9, "reset_hooks_end": 9, "names_filt": 9, "callabl": 9, "incl_bwd": 9, "namesfilt": 9, "filter": 9, "lambda": 9, "provid": 9, "keyword": 9, "captur": 9, "fn": 9, "degrad": 9, "clear": 9, "whenev": 9, "reset": 9, "fwd_hook": 9, "bwd_hook": 9, "respect": 9, "ditto": 9, "removablehandl": 9, "autoconfig": 9, "json": 9, "1l": 9, "2l": 9, "4l": 9, "6l": 9, "face": 9, "dim_out": 9, "dim_in": 9, "8l": 9, "And": 9, "neo": 9, "compat": 9, "label_typ": 9, "suffici": 9, "offici": 9, "automodel": 9, "aren": 9, "reload": 9, "model_alias": 9, "alias": 9, "continu": 9, "iter": 9, "__torchtyping__": 9, "cls_name": 9, "tensortyp": 9, "new_kei": 9, "new_valu": 9, "techniqu": 9, "structur": 9, "specialis": 9, "explan": 9, "dynalist": 9, "n2zwtnoyhru1s4vnfsaq519j": 9, "qewbv": 9, "taffccq": 9, "s_hgmqx": 9, "corrupted_token": 9, "clean_cach": 9, "patching_metr": 9, "patch_sett": 9, "index_axis_nam": 9, "src_po": 9, "dest_po": 9, "index_df": 9, "datafram": 9, "return_index_df": 9, "studi": 9, "counterfactu": 9, "corrupt": 9, "eiffel": 9, "tower": 9, "colosseum": 9, "come": 9, "index_to_act_nam": 9, "recov": 9, "panda": 9, "param": 9, "diff": 9, "act": 9, "corrupted_activ": 9, "chunk": 9, "fulli": 9, "flatten": 9, "patched_output": 9, "corruptedactiv": 9, "patchedactiv": 9, "axisnam": 9, "pd": 9, "clean_activ": 9, "impliitli": 9, "column_max_rang": 9, "column_nam": 9, "cartesian": 9, "combin": 9, "increment": 9, "mypi": 9, "torchtyp": 9, "solidifi": 9, "convent": 9, "byproduct": 9, "001": 9, "adam": 9, "50": 9, "hyperparamet": 9, "epoch": 9, "rate": 9, "decai": 9, "warmup": 9, "wandb_project": 9, "print": 9, "termin": 9, "input_slic": 9, "syntax": 9, "reduc": 9, "extra": 9, "decreas": 9, "ident": 9, "leav": 9, "elif": 9, "1d": 9, "max_ctx": 9, "broadcast_dim": 9, "repo_nam": 9, "file_nam": 9, "subfold": 9, "home": 9, "runner": 9, "hub": 9, "force_is_torch": 9, "path": 9, "pth": 9, "extens": 9, "layer_typ": 9, "shorthand": 9, "hacki": 9, "hack": 9, "stuff": 9, "readabl": 9, "determinist": 9, "6": 9, "hook_k": 9, "hook_pr": 9, "hook_emb": 9, "27": 9, "hook_norm": 9, "k6": 9, "scale4ln1": 9, "pre5": 9, "dataset_nam": 9, "explor": 9, "000": 9, "enorm": 9, "100gb": 9, "2tb": 9, "effort": 9, "dataload": 9, "fanci": 9, "data_dir": 9, "approx": 9, "co": 9, "big": 9, "divers": 9, "c4": 9, "coloss": 9, "common": 9, "crawl": 9, "bigger": 9, "c4_code": 9, "mix": 9, "friendli": 9, "ratio": 9, "22m": 9, "5m": 9, "wiki": 9, "20220301": 9, "en": 9, "col_nam": 9, "accuraci": 9, "seq_len": 9, "cannot": 9, "int64": 9, "seq": 9, "altern": 9, "step_nam": 9, "final_logit": 9, "vocab_s": 9, "divid": 9, "high": 9, "argmaxi": 9, "encourag": 9, "9": 9, "90": 9, "renormalis": 9, "mutual": 9, "proport": 9, "itself": 9, "tune": 9, "input_token": 9, "todo": 9, "edg": 9, "randn": 9, "np": 9, "uniqu": 9, "return_count": 9, "answer": 9, "prepend_space_to_answ": 9, "multi": 9, "autotoken": 9, "max_length": 9, "1024": 9, "add_bos_token": 9, "num_proc": 9, "eo": 9, "reshap": 9, "____": 9, "sequence_length": 9, "drop": 9, "faster": 9, "parallelis": 9, "chop": 9, "20": 9, "vari": 9, "encod": 9, "privileg": 9, "earli": 9, "cnn": 9, "swap": 9, "regardless": 9}, "objects": {"": [[5, 0, 0, "-", "easy_transformer"], [9, 0, 0, "-", "transformer_lens"], [10, 0, 0, "-", "typing_demo"]], "transformer_lens": [[9, 0, 0, "-", "ActivationCache"], [9, 0, 0, "-", "FactoredMatrix"], [9, 0, 0, "-", "HookedTransformer"], [9, 0, 0, "-", "HookedTransformerConfig"], [9, 0, 0, "-", "components"], [9, 0, 0, "-", "evals"], [9, 0, 0, "-", "hook_points"], [9, 0, 0, "-", "loading_from_pretrained"], [9, 0, 0, "-", "past_key_value_caching"], [9, 0, 0, "-", "patching"], [9, 0, 0, "-", "torchtyping_helper"], [9, 0, 0, "-", "train"], [9, 0, 0, "-", "utils"]], "transformer_lens.ActivationCache": [[9, 1, 1, "", "ActivationCache"]], "transformer_lens.ActivationCache.ActivationCache": [[9, 2, 1, "", "accumulated_resid"], [9, 2, 1, "", "apply_ln_to_stack"], [9, 2, 1, "", "apply_slice_to_batch_dim"], [9, 2, 1, "", "compute_head_results"], [9, 2, 1, "", "decompose_resid"], [9, 2, 1, "", "get_full_resid_decomposition"], [9, 2, 1, "", "get_neuron_results"], [9, 2, 1, "", "items"], [9, 2, 1, "", "keys"], [9, 2, 1, "", "remove_batch_dim"], [9, 2, 1, "", "stack_activation"], [9, 2, 1, "", "stack_head_results"], [9, 2, 1, "", "stack_neuron_results"], [9, 2, 1, "", "to"], [9, 2, 1, "", "toggle_autodiff"], [9, 2, 1, "", "values"]], "transformer_lens.FactoredMatrix": [[9, 1, 1, "", "FactoredMatrix"]], "transformer_lens.FactoredMatrix.FactoredMatrix": [[9, 3, 1, "", "AB"], [9, 3, 1, "", "BA"], [9, 3, 1, "", "S"], [9, 3, 1, "", "T"], [9, 3, 1, "", "U"], [9, 3, 1, "", "Vh"], [9, 2, 1, "", "collapse_l"], [9, 2, 1, "", "collapse_r"], [9, 3, 1, "", "eigenvalues"], [9, 2, 1, "", "get_corner"], [9, 2, 1, "", "make_even"], [9, 3, 1, "", "ndim"], [9, 2, 1, "", "norm"], [9, 3, 1, "", "pair"], [9, 2, 1, "", "svd"], [9, 2, 1, "", "unsqueeze"]], "transformer_lens.HookedTransformer": [[9, 1, 1, "", "HookedTransformer"], [9, 1, 1, "", "Output"]], "transformer_lens.HookedTransformer.HookedTransformer": [[9, 3, 1, "", "OV"], [9, 3, 1, "", "QK"], [9, 3, 1, "", "W_E"], [9, 3, 1, "", "W_E_pos"], [9, 3, 1, "", "W_K"], [9, 3, 1, "", "W_O"], [9, 3, 1, "", "W_Q"], [9, 3, 1, "", "W_U"], [9, 3, 1, "", "W_V"], [9, 3, 1, "", "W_in"], [9, 3, 1, "", "W_out"], [9, 3, 1, "", "W_pos"], [9, 2, 1, "", "accumulated_bias"], [9, 2, 1, "", "all_composition_scores"], [9, 2, 1, "", "all_head_labels"], [9, 3, 1, "", "b_K"], [9, 3, 1, "", "b_O"], [9, 3, 1, "", "b_Q"], [9, 3, 1, "", "b_U"], [9, 3, 1, "", "b_V"], [9, 3, 1, "", "b_in"], [9, 3, 1, "", "b_out"], [9, 2, 1, "", "center_unembed"], [9, 2, 1, "", "center_writing_weights"], [9, 2, 1, "", "cpu"], [9, 2, 1, "", "cuda"], [9, 2, 1, "", "fill_missing_keys"], [9, 2, 1, "", "fold_layer_norm"], [9, 2, 1, "", "fold_value_biases"], [9, 2, 1, "", "forward"], [9, 2, 1, "", "from_pretrained"], [9, 2, 1, "", "from_pretrained_no_processing"], [9, 2, 1, "", "generate"], [9, 2, 1, "", "get_token_position"], [9, 2, 1, "", "init_weights"], [9, 2, 1, "", "load_and_process_state_dict"], [9, 2, 1, "", "load_sample_training_dataset"], [9, 2, 1, "", "loss_fn"], [9, 2, 1, "", "process_weights_"], [9, 2, 1, "", "refactor_factored_attn_matrices"], [9, 2, 1, "", "run_with_cache"], [9, 2, 1, "", "sample_datapoint"], [9, 2, 1, "", "set_tokenizer"], [9, 2, 1, "", "set_use_attn_result"], [9, 2, 1, "", "to"], [9, 2, 1, "", "to_single_token"], [9, 2, 1, "", "to_str_tokens"], [9, 2, 1, "", "to_string"], [9, 2, 1, "", "to_tokens"], [9, 2, 1, "", "tokens_to_residual_directions"], [9, 4, 1, "", "training"]], "transformer_lens.HookedTransformer.Output": [[9, 4, 1, "", "logits"], [9, 4, 1, "", "loss"]], "transformer_lens.HookedTransformerConfig": [[9, 1, 1, "", "HookedTransformerConfig"]], "transformer_lens.HookedTransformerConfig.HookedTransformerConfig": [[9, 4, 1, "", "act_fn"], [9, 4, 1, "", "attention_dir"], [9, 4, 1, "", "attn_only"], [9, 4, 1, "", "attn_types"], [9, 4, 1, "", "checkpoint_index"], [9, 4, 1, "", "checkpoint_label_type"], [9, 4, 1, "", "checkpoint_value"], [9, 4, 1, "", "d_head"], [9, 4, 1, "", "d_mlp"], [9, 4, 1, "", "d_model"], [9, 4, 1, "", "d_vocab"], [9, 4, 1, "", "d_vocab_out"], [9, 4, 1, "", "device"], [9, 4, 1, "", "eps"], [9, 4, 1, "", "final_rms"], [9, 4, 1, "", "from_checkpoint"], [9, 2, 1, "", "from_dict"], [9, 4, 1, "", "init_mode"], [9, 4, 1, "", "init_weights"], [9, 4, 1, "", "initializer_range"], [9, 4, 1, "", "model_name"], [9, 4, 1, "", "n_ctx"], [9, 4, 1, "", "n_heads"], [9, 4, 1, "", "n_layers"], [9, 4, 1, "", "n_params"], [9, 4, 1, "", "normalization_type"], [9, 4, 1, "", "original_architecture"], [9, 4, 1, "", "parallel_attn_mlp"], [9, 4, 1, "", "positional_embedding_type"], [9, 4, 1, "", "rotary_dim"], [9, 4, 1, "", "scale_attn_by_inverse_layer_idx"], [9, 4, 1, "", "seed"], [9, 2, 1, "", "set_seed_everywhere"], [9, 2, 1, "", "to_dict"], [9, 4, 1, "", "tokenizer_name"], [9, 4, 1, "", "use_attn_result"], [9, 4, 1, "", "use_attn_scale"], [9, 4, 1, "", "use_hook_tokens"], [9, 4, 1, "", "use_local_attn"], [9, 4, 1, "", "window_size"]], "transformer_lens.components": [[9, 1, 1, "", "Attention"], [9, 1, 1, "", "Embed"], [9, 1, 1, "", "LayerNorm"], [9, 1, 1, "", "LayerNormPre"], [9, 1, 1, "", "MLP"], [9, 1, 1, "", "PosEmbed"], [9, 1, 1, "", "RMSNorm"], [9, 1, 1, "", "RMSNormPre"], [9, 1, 1, "", "TransformerBlock"], [9, 1, 1, "", "Unembed"]], "transformer_lens.components.Attention": [[9, 3, 1, "", "OV"], [9, 3, 1, "", "QK"], [9, 2, 1, "", "apply_causal_mask"], [9, 2, 1, "", "apply_rotary"], [9, 2, 1, "", "calculate_sin_cos_rotary"], [9, 2, 1, "", "forward"], [9, 2, 1, "", "rotary_rotate_qk"], [9, 2, 1, "", "rotate_every_two"], [9, 2, 1, "", "shortformer_calculate_qk"], [9, 4, 1, "", "training"]], "transformer_lens.components.Embed": [[9, 2, 1, "", "forward"], [9, 4, 1, "", "training"]], "transformer_lens.components.LayerNorm": [[9, 2, 1, "", "forward"], [9, 4, 1, "", "training"]], "transformer_lens.components.LayerNormPre": [[9, 2, 1, "", "forward"], [9, 4, 1, "", "training"]], "transformer_lens.components.MLP": [[9, 2, 1, "", "forward"], [9, 4, 1, "", "training"]], "transformer_lens.components.PosEmbed": [[9, 2, 1, "", "forward"], [9, 4, 1, "", "training"]], "transformer_lens.components.RMSNorm": [[9, 2, 1, "", "forward"], [9, 4, 1, "", "training"]], "transformer_lens.components.RMSNormPre": [[9, 2, 1, "", "forward"], [9, 4, 1, "", "training"]], "transformer_lens.components.TransformerBlock": [[9, 2, 1, "", "forward"], [9, 4, 1, "", "training"]], "transformer_lens.components.Unembed": [[9, 2, 1, "", "forward"], [9, 4, 1, "", "training"]], "transformer_lens.evals": [[9, 5, 1, "", "evaluate"], [9, 5, 1, "", "evaluate_on_dataset"], [9, 5, 1, "", "induction_loss"], [9, 5, 1, "", "make_code_data_loader"], [9, 5, 1, "", "make_owt_data_loader"], [9, 5, 1, "", "make_pile_data_loader"], [9, 5, 1, "", "make_wiki_data_loader"], [9, 5, 1, "", "sanity_check"]], "transformer_lens.hook_points": [[9, 1, 1, "", "HookPoint"], [9, 1, 1, "", "HookedRootModule"], [9, 1, 1, "", "LensHandle"]], "transformer_lens.hook_points.HookPoint": [[9, 2, 1, "", "add_hook"], [9, 2, 1, "", "add_perma_hook"], [9, 2, 1, "", "clear_context"], [9, 2, 1, "", "forward"], [9, 2, 1, "", "layer"], [9, 2, 1, "", "remove_hooks"], [9, 4, 1, "", "training"]], "transformer_lens.hook_points.HookedRootModule": [[9, 2, 1, "", "add_caching_hooks"], [9, 2, 1, "", "add_hook"], [9, 2, 1, "", "add_perma_hook"], [9, 2, 1, "", "cache_all"], [9, 2, 1, "", "cache_some"], [9, 2, 1, "", "clear_contexts"], [9, 2, 1, "", "hook_points"], [9, 2, 1, "", "remove_all_hook_fns"], [9, 2, 1, "", "reset_hooks"], [9, 2, 1, "", "run_with_cache"], [9, 2, 1, "", "run_with_hooks"], [9, 2, 1, "", "setup"], [9, 4, 1, "", "training"]], "transformer_lens.hook_points.LensHandle": [[9, 4, 1, "", "hook"], [9, 4, 1, "", "is_permanent"]], "transformer_lens.loading_from_pretrained": [[9, 5, 1, "", "convert_gpt2_weights"], [9, 5, 1, "", "convert_gptj_weights"], [9, 5, 1, "", "convert_hf_model_config"], [9, 5, 1, "", "convert_neel_model_config"], [9, 5, 1, "", "convert_neel_solu_old_weights"], [9, 5, 1, "", "convert_neo_weights"], [9, 5, 1, "", "convert_neox_weights"], [9, 5, 1, "", "convert_opt_weights"], [9, 5, 1, "", "convert_state_dict"], [9, 5, 1, "", "get_checkpoint_labels"], [9, 5, 1, "", "get_num_params_of_pretrained"], [9, 5, 1, "", "get_official_model_name"], [9, 5, 1, "", "get_pretrained_model_config"], [9, 5, 1, "", "get_pretrained_state_dict"], [9, 5, 1, "", "make_model_alias_map"]], "transformer_lens.past_key_value_caching": [[9, 1, 1, "", "HookedTransformerKeyValueCache"], [9, 1, 1, "", "HookedTransformerKeyValueCacheEntry"]], "transformer_lens.past_key_value_caching.HookedTransformerKeyValueCache": [[9, 4, 1, "", "entries"], [9, 2, 1, "", "init_cache"]], "transformer_lens.past_key_value_caching.HookedTransformerKeyValueCacheEntry": [[9, 2, 1, "", "append"], [9, 2, 1, "", "init_cache_entry"], [9, 4, 1, "", "past_keys"], [9, 4, 1, "", "past_values"]], "transformer_lens.patching": [[9, 5, 1, "", "generic_activation_patch"], [9, 5, 1, "", "get_act_patch_attn_head_all_pos_every"], [9, 5, 1, "", "get_act_patch_attn_head_by_pos_every"], [9, 5, 1, "", "get_act_patch_attn_head_k_all_pos"], [9, 5, 1, "", "get_act_patch_attn_head_k_by_pos"], [9, 5, 1, "", "get_act_patch_attn_head_out_all_pos"], [9, 5, 1, "", "get_act_patch_attn_head_out_by_pos"], [9, 5, 1, "", "get_act_patch_attn_head_pattern_all_pos"], [9, 5, 1, "", "get_act_patch_attn_head_pattern_by_pos"], [9, 5, 1, "", "get_act_patch_attn_head_pattern_dest_src_pos"], [9, 5, 1, "", "get_act_patch_attn_head_q_all_pos"], [9, 5, 1, "", "get_act_patch_attn_head_q_by_pos"], [9, 5, 1, "", "get_act_patch_attn_head_v_all_pos"], [9, 5, 1, "", "get_act_patch_attn_head_v_by_pos"], [9, 5, 1, "", "get_act_patch_attn_out"], [9, 5, 1, "", "get_act_patch_block_every"], [9, 5, 1, "", "get_act_patch_mlp_out"], [9, 5, 1, "", "get_act_patch_resid_mid"], [9, 5, 1, "", "get_act_patch_resid_pre"], [9, 5, 1, "", "layer_head_dest_src_pos_pattern_patch_setter"], [9, 5, 1, "", "layer_head_pattern_patch_setter"], [9, 5, 1, "", "layer_head_pos_pattern_patch_setter"], [9, 5, 1, "", "layer_head_vector_patch_setter"], [9, 5, 1, "", "layer_pos_head_vector_patch_setter"], [9, 5, 1, "", "layer_pos_patch_setter"], [9, 5, 1, "", "make_df_from_ranges"]], "transformer_lens.torchtyping_helper": [[9, 1, 1, "", "T"]], "transformer_lens.torchtyping_helper.T": [[9, 4, 1, "", "a"], [9, 4, 1, "", "b"], [9, 4, 1, "", "batch"], [9, 4, 1, "", "batch_and_pos_dims"], [9, 4, 1, "", "d_head"], [9, 4, 1, "", "d_mlp"], [9, 4, 1, "", "d_model"], [9, 4, 1, "", "d_vocab"], [9, 4, 1, "", "d_vocab_out"], [9, 4, 1, "", "d_vocab_plus_n_ctx"], [9, 4, 1, "", "head_index"], [9, 4, 1, "", "layers_accumulated_over"], [9, 4, 1, "", "layers_covered"], [9, 4, 1, "", "ldim"], [9, 4, 1, "", "leading_dims"], [9, 4, 1, "", "leading_dims_left"], [9, 4, 1, "", "leading_dims_right"], [9, 4, 1, "", "length"], [9, 4, 1, "", "mdim"], [9, 4, 1, "", "n_ctx"], [9, 4, 1, "", "n_heads"], [9, 4, 1, "", "n_layers"], [9, 4, 1, "", "new_rdim"], [9, 4, 1, "", "new_tokens"], [9, 4, 1, "", "num_components"], [9, 4, 1, "", "num_neurons"], [9, 4, 1, "", "past_kv_pos_offset"], [9, 4, 1, "", "pos"], [9, 4, 1, "", "pos_plus_new_tokens"], [9, 4, 1, "", "pos_plus_past_kv_pos_offset"], [9, 4, 1, "", "pos_so_far"], [9, 4, 1, "", "rdim"], [9, 4, 1, "", "rotary_dim"]], "transformer_lens.train": [[9, 1, 1, "", "HookedTransformerTrainConfig"], [9, 5, 1, "", "train"]], "transformer_lens.train.HookedTransformerTrainConfig": [[9, 4, 1, "", "batch_size"], [9, 4, 1, "", "device"], [9, 4, 1, "", "lr"], [9, 4, 1, "", "max_grad_norm"], [9, 4, 1, "", "max_steps"], [9, 4, 1, "", "momentum"], [9, 4, 1, "", "num_epochs"], [9, 4, 1, "", "optimizer_name"], [9, 4, 1, "", "print_every"], [9, 4, 1, "", "save_dir"], [9, 4, 1, "", "save_every"], [9, 4, 1, "", "seed"], [9, 4, 1, "", "wandb"], [9, 4, 1, "", "wandb_project_name"], [9, 4, 1, "", "warmup_steps"], [9, 4, 1, "", "weight_decay"]], "transformer_lens.utils": [[9, 1, 1, "", "Slice"], [9, 5, 1, "", "composition_scores"], [9, 5, 1, "", "download_file_from_hf"], [9, 5, 1, "", "gelu_fast"], [9, 5, 1, "", "gelu_new"], [9, 5, 1, "", "get_act_name"], [9, 5, 1, "", "get_corner"], [9, 5, 1, "", "get_dataset"], [9, 5, 1, "", "keep_single_column"], [9, 5, 1, "", "lm_accuracy"], [9, 5, 1, "", "lm_cross_entropy_loss"], [9, 5, 1, "", "print_gpu_mem"], [9, 5, 1, "", "remove_batch_dim"], [9, 5, 1, "", "sample_logits"], [9, 5, 1, "", "solu"], [9, 5, 1, "", "test_prompt"], [9, 5, 1, "", "to_numpy"], [9, 5, 1, "", "tokenize_and_concatenate"], [9, 5, 1, "", "transpose"]], "transformer_lens.utils.Slice": [[9, 2, 1, "", "apply"], [9, 2, 1, "", "indices"]], "typing_demo": [[10, 5, 1, "", "test"], [10, 5, 1, "", "test2"], [10, 5, 1, "", "test3"], [10, 5, 1, "", "test4"]]}, "objtypes": {"0": "py:module", "1": "py:class", "2": "py:method", "3": "py:property", "4": "py:attribute", "5": "py:function"}, "objnames": {"0": ["py", "module", "Python module"], "1": ["py", "class", "Python class"], "2": ["py", "method", "Python method"], "3": ["py", "property", "Python property"], "4": ["py", "attribute", "Python attribute"], "5": ["py", "function", "Python function"]}, "titleterms": {"citat": 0, "local": 1, "develop": 1, "devcontain": 1, "manual": 1, "setup": [1, 8], "test": 1, "galleri": 2, "get": 3, "start": 3, "advic": 3, "read": 3, "code": 3, "instal": 3, "tutori": 4, "easy_transform": 5, "packag": [5, 9], "modul": [5, 8, 9, 10], "content": [5, 9], "transformerlen": [6, 7], "A": 6, "librari": 6, "mechanist": 6, "interpret": 6, "gener": 6, "languag": 6, "model": 6, "transformer_len": 9, "submodul": 9, "activationcach": 9, "factoredmatrix": 9, "hookedtransform": 9, "hookedtransformerconfig": 9, "compon": 9, "eval": 9, "hook_point": 9, "loading_from_pretrain": 9, "make_doc": 9, "past_key_value_cach": 9, "patch": 9, "torchtyping_help": 9, "train": 9, "util": 9, "typing_demo": 10}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 8, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx": 57}, "alltitles": {"Citation": [[0, "citation"]], "Local Development": [[1, "local-development"]], "DevContainer": [[1, "devcontainer"]], "Manual Setup": [[1, "manual-setup"]], "Testing": [[1, "testing"]], "Gallery": [[2, "gallery"]], "Getting Started": [[3, "getting-started"]], "Advice for Reading the Code": [[3, "advice-for-reading-the-code"]], "Installation": [[3, "installation"]], "Tutorials": [[4, "tutorials"]], "easy_transformer package": [[5, "easy-transformer-package"]], "Module contents": [[5, "module-easy_transformer"], [9, "module-transformer_lens"]], "TransformerLens": [[6, "transformerlens"], [7, "transformerlens"]], "A Library for Mechanistic Interpretability of Generative Language Models": [[6, "a-library-for-mechanistic-interpretability-of-generative-language-models"]], "setup module": [[8, "setup-module"]], "transformer_lens package": [[9, "transformer-lens-package"]], "Submodules": [[9, "submodules"]], "transformer_lens.ActivationCache module": [[9, "module-transformer_lens.ActivationCache"]], "transformer_lens.FactoredMatrix module": [[9, "module-transformer_lens.FactoredMatrix"]], "transformer_lens.HookedTransformer module": [[9, "module-transformer_lens.HookedTransformer"]], "transformer_lens.HookedTransformerConfig module": [[9, "module-transformer_lens.HookedTransformerConfig"]], "transformer_lens.components module": [[9, "module-transformer_lens.components"]], "transformer_lens.evals module": [[9, "module-transformer_lens.evals"]], "transformer_lens.hook_points module": [[9, "module-transformer_lens.hook_points"]], "transformer_lens.loading_from_pretrained module": [[9, "module-transformer_lens.loading_from_pretrained"]], "transformer_lens.make_docs module": [[9, "transformer-lens-make-docs-module"]], "transformer_lens.past_key_value_caching module": [[9, "module-transformer_lens.past_key_value_caching"]], "transformer_lens.patching module": [[9, "module-transformer_lens.patching"]], "transformer_lens.torchtyping_helper module": [[9, "module-transformer_lens.torchtyping_helper"]], "transformer_lens.train module": [[9, "module-transformer_lens.train"]], "transformer_lens.utils module": [[9, "module-transformer_lens.utils"]], "typing_demo module": [[10, "module-typing_demo"]]}, "indexentries": {"easy_transformer": [[5, "module-easy_transformer"]], "module": [[5, "module-easy_transformer"], [9, "module-transformer_lens"], [9, "module-transformer_lens.ActivationCache"], [9, "module-transformer_lens.FactoredMatrix"], [9, "module-transformer_lens.HookedTransformer"], [9, "module-transformer_lens.HookedTransformerConfig"], [9, "module-transformer_lens.components"], [9, "module-transformer_lens.evals"], [9, "module-transformer_lens.hook_points"], [9, "module-transformer_lens.loading_from_pretrained"], [9, "module-transformer_lens.past_key_value_caching"], [9, "module-transformer_lens.patching"], [9, "module-transformer_lens.torchtyping_helper"], [9, "module-transformer_lens.train"], [9, "module-transformer_lens.utils"], [10, "module-typing_demo"]], "ab (transformer_lens.factoredmatrix.factoredmatrix property)": [[9, "transformer_lens.FactoredMatrix.FactoredMatrix.AB"]], "activationcache (class in transformer_lens.activationcache)": [[9, "transformer_lens.ActivationCache.ActivationCache"]], "attention (class in transformer_lens.components)": [[9, "transformer_lens.components.Attention"]], "ba (transformer_lens.factoredmatrix.factoredmatrix property)": [[9, "transformer_lens.FactoredMatrix.FactoredMatrix.BA"]], "embed (class in transformer_lens.components)": [[9, "transformer_lens.components.Embed"]], "factoredmatrix (class in transformer_lens.factoredmatrix)": [[9, "transformer_lens.FactoredMatrix.FactoredMatrix"]], "hookpoint (class in transformer_lens.hook_points)": [[9, "transformer_lens.hook_points.HookPoint"]], "hookedrootmodule (class in transformer_lens.hook_points)": [[9, "transformer_lens.hook_points.HookedRootModule"]], "hookedtransformer (class in transformer_lens.hookedtransformer)": [[9, "transformer_lens.HookedTransformer.HookedTransformer"]], "hookedtransformerconfig (class in transformer_lens.hookedtransformerconfig)": [[9, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig"]], "hookedtransformerkeyvaluecache (class in transformer_lens.past_key_value_caching)": [[9, "transformer_lens.past_key_value_caching.HookedTransformerKeyValueCache"]], "hookedtransformerkeyvaluecacheentry (class in transformer_lens.past_key_value_caching)": [[9, "transformer_lens.past_key_value_caching.HookedTransformerKeyValueCacheEntry"]], "hookedtransformertrainconfig (class in transformer_lens.train)": [[9, "transformer_lens.train.HookedTransformerTrainConfig"]], "layernorm (class in transformer_lens.components)": [[9, "transformer_lens.components.LayerNorm"]], "layernormpre (class in transformer_lens.components)": [[9, "transformer_lens.components.LayerNormPre"]], "lenshandle (class in transformer_lens.hook_points)": [[9, "transformer_lens.hook_points.LensHandle"]], "mlp (class in transformer_lens.components)": [[9, "transformer_lens.components.MLP"]], "ov (transformer_lens.hookedtransformer.hookedtransformer property)": [[9, "transformer_lens.HookedTransformer.HookedTransformer.OV"]], "ov (transformer_lens.components.attention property)": [[9, "transformer_lens.components.Attention.OV"]], "output (class in transformer_lens.hookedtransformer)": [[9, "transformer_lens.HookedTransformer.Output"]], "posembed (class in transformer_lens.components)": [[9, "transformer_lens.components.PosEmbed"]], "qk (transformer_lens.hookedtransformer.hookedtransformer property)": [[9, "transformer_lens.HookedTransformer.HookedTransformer.QK"]], "qk (transformer_lens.components.attention property)": [[9, "transformer_lens.components.Attention.QK"]], "rmsnorm (class in transformer_lens.components)": [[9, "transformer_lens.components.RMSNorm"]], "rmsnormpre (class in transformer_lens.components)": [[9, "transformer_lens.components.RMSNormPre"]], "s (transformer_lens.factoredmatrix.factoredmatrix property)": [[9, "transformer_lens.FactoredMatrix.FactoredMatrix.S"]], "slice (class in transformer_lens.utils)": [[9, "transformer_lens.utils.Slice"]], "t (class in transformer_lens.torchtyping_helper)": [[9, "transformer_lens.torchtyping_helper.T"]], "t (transformer_lens.factoredmatrix.factoredmatrix property)": [[9, "transformer_lens.FactoredMatrix.FactoredMatrix.T"]], "transformerblock (class in transformer_lens.components)": [[9, "transformer_lens.components.TransformerBlock"]], "u (transformer_lens.factoredmatrix.factoredmatrix property)": [[9, "transformer_lens.FactoredMatrix.FactoredMatrix.U"]], "unembed (class in transformer_lens.components)": [[9, "transformer_lens.components.Unembed"]], "vh (transformer_lens.factoredmatrix.factoredmatrix property)": [[9, "transformer_lens.FactoredMatrix.FactoredMatrix.Vh"]], "w_e (transformer_lens.hookedtransformer.hookedtransformer property)": [[9, "transformer_lens.HookedTransformer.HookedTransformer.W_E"]], "w_e_pos (transformer_lens.hookedtransformer.hookedtransformer property)": [[9, "transformer_lens.HookedTransformer.HookedTransformer.W_E_pos"]], "w_k (transformer_lens.hookedtransformer.hookedtransformer property)": [[9, "transformer_lens.HookedTransformer.HookedTransformer.W_K"]], "w_o (transformer_lens.hookedtransformer.hookedtransformer property)": [[9, "transformer_lens.HookedTransformer.HookedTransformer.W_O"]], "w_q (transformer_lens.hookedtransformer.hookedtransformer property)": [[9, "transformer_lens.HookedTransformer.HookedTransformer.W_Q"]], "w_u (transformer_lens.hookedtransformer.hookedtransformer property)": [[9, "transformer_lens.HookedTransformer.HookedTransformer.W_U"]], "w_v (transformer_lens.hookedtransformer.hookedtransformer property)": [[9, "transformer_lens.HookedTransformer.HookedTransformer.W_V"]], "w_in (transformer_lens.hookedtransformer.hookedtransformer property)": [[9, "transformer_lens.HookedTransformer.HookedTransformer.W_in"]], "w_out (transformer_lens.hookedtransformer.hookedtransformer property)": [[9, "transformer_lens.HookedTransformer.HookedTransformer.W_out"]], "w_pos (transformer_lens.hookedtransformer.hookedtransformer property)": [[9, "transformer_lens.HookedTransformer.HookedTransformer.W_pos"]], "a (transformer_lens.torchtyping_helper.t attribute)": [[9, "transformer_lens.torchtyping_helper.T.a"]], "accumulated_bias() (transformer_lens.hookedtransformer.hookedtransformer method)": [[9, "transformer_lens.HookedTransformer.HookedTransformer.accumulated_bias"]], "accumulated_resid() (transformer_lens.activationcache.activationcache method)": [[9, "transformer_lens.ActivationCache.ActivationCache.accumulated_resid"]], "act_fn (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[9, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.act_fn"]], "add_caching_hooks() (transformer_lens.hook_points.hookedrootmodule method)": [[9, "transformer_lens.hook_points.HookedRootModule.add_caching_hooks"]], "add_hook() (transformer_lens.hook_points.hookpoint method)": [[9, "transformer_lens.hook_points.HookPoint.add_hook"]], "add_hook() (transformer_lens.hook_points.hookedrootmodule method)": [[9, "transformer_lens.hook_points.HookedRootModule.add_hook"]], "add_perma_hook() (transformer_lens.hook_points.hookpoint method)": [[9, "transformer_lens.hook_points.HookPoint.add_perma_hook"]], "add_perma_hook() (transformer_lens.hook_points.hookedrootmodule method)": [[9, "transformer_lens.hook_points.HookedRootModule.add_perma_hook"]], "all_composition_scores() (transformer_lens.hookedtransformer.hookedtransformer method)": [[9, "transformer_lens.HookedTransformer.HookedTransformer.all_composition_scores"]], "all_head_labels() (transformer_lens.hookedtransformer.hookedtransformer method)": [[9, "transformer_lens.HookedTransformer.HookedTransformer.all_head_labels"]], "append() (transformer_lens.past_key_value_caching.hookedtransformerkeyvaluecacheentry method)": [[9, "transformer_lens.past_key_value_caching.HookedTransformerKeyValueCacheEntry.append"]], "apply() (transformer_lens.utils.slice method)": [[9, "transformer_lens.utils.Slice.apply"]], "apply_causal_mask() (transformer_lens.components.attention method)": [[9, "transformer_lens.components.Attention.apply_causal_mask"]], "apply_ln_to_stack() (transformer_lens.activationcache.activationcache method)": [[9, "transformer_lens.ActivationCache.ActivationCache.apply_ln_to_stack"]], "apply_rotary() (transformer_lens.components.attention method)": [[9, "transformer_lens.components.Attention.apply_rotary"]], "apply_slice_to_batch_dim() (transformer_lens.activationcache.activationcache method)": [[9, "transformer_lens.ActivationCache.ActivationCache.apply_slice_to_batch_dim"]], "attention_dir (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[9, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.attention_dir"]], "attn_only (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[9, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.attn_only"]], "attn_types (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[9, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.attn_types"]], "b (transformer_lens.torchtyping_helper.t attribute)": [[9, "transformer_lens.torchtyping_helper.T.b"]], "b_k (transformer_lens.hookedtransformer.hookedtransformer property)": [[9, "transformer_lens.HookedTransformer.HookedTransformer.b_K"]], "b_o (transformer_lens.hookedtransformer.hookedtransformer property)": [[9, "transformer_lens.HookedTransformer.HookedTransformer.b_O"]], "b_q (transformer_lens.hookedtransformer.hookedtransformer property)": [[9, "transformer_lens.HookedTransformer.HookedTransformer.b_Q"]], "b_u (transformer_lens.hookedtransformer.hookedtransformer property)": [[9, "transformer_lens.HookedTransformer.HookedTransformer.b_U"]], "b_v (transformer_lens.hookedtransformer.hookedtransformer property)": [[9, "transformer_lens.HookedTransformer.HookedTransformer.b_V"]], "b_in (transformer_lens.hookedtransformer.hookedtransformer property)": [[9, "transformer_lens.HookedTransformer.HookedTransformer.b_in"]], "b_out (transformer_lens.hookedtransformer.hookedtransformer property)": [[9, "transformer_lens.HookedTransformer.HookedTransformer.b_out"]], "batch (transformer_lens.torchtyping_helper.t attribute)": [[9, "transformer_lens.torchtyping_helper.T.batch"]], "batch_and_pos_dims (transformer_lens.torchtyping_helper.t attribute)": [[9, "transformer_lens.torchtyping_helper.T.batch_and_pos_dims"]], "batch_size (transformer_lens.train.hookedtransformertrainconfig attribute)": [[9, "transformer_lens.train.HookedTransformerTrainConfig.batch_size"]], "cache_all() (transformer_lens.hook_points.hookedrootmodule method)": [[9, "transformer_lens.hook_points.HookedRootModule.cache_all"]], "cache_some() (transformer_lens.hook_points.hookedrootmodule method)": [[9, "transformer_lens.hook_points.HookedRootModule.cache_some"]], "calculate_sin_cos_rotary() (transformer_lens.components.attention method)": [[9, "transformer_lens.components.Attention.calculate_sin_cos_rotary"]], "center_unembed() (transformer_lens.hookedtransformer.hookedtransformer method)": [[9, "transformer_lens.HookedTransformer.HookedTransformer.center_unembed"]], "center_writing_weights() (transformer_lens.hookedtransformer.hookedtransformer method)": [[9, "transformer_lens.HookedTransformer.HookedTransformer.center_writing_weights"]], "checkpoint_index (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[9, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.checkpoint_index"]], "checkpoint_label_type (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[9, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.checkpoint_label_type"]], "checkpoint_value (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[9, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.checkpoint_value"]], "clear_context() (transformer_lens.hook_points.hookpoint method)": [[9, "transformer_lens.hook_points.HookPoint.clear_context"]], "clear_contexts() (transformer_lens.hook_points.hookedrootmodule method)": [[9, "transformer_lens.hook_points.HookedRootModule.clear_contexts"]], "collapse_l() (transformer_lens.factoredmatrix.factoredmatrix method)": [[9, "transformer_lens.FactoredMatrix.FactoredMatrix.collapse_l"]], "collapse_r() (transformer_lens.factoredmatrix.factoredmatrix method)": [[9, "transformer_lens.FactoredMatrix.FactoredMatrix.collapse_r"]], "composition_scores() (in module transformer_lens.utils)": [[9, "transformer_lens.utils.composition_scores"]], "compute_head_results() (transformer_lens.activationcache.activationcache method)": [[9, "transformer_lens.ActivationCache.ActivationCache.compute_head_results"]], "convert_gpt2_weights() (in module transformer_lens.loading_from_pretrained)": [[9, "transformer_lens.loading_from_pretrained.convert_gpt2_weights"]], "convert_gptj_weights() (in module transformer_lens.loading_from_pretrained)": [[9, "transformer_lens.loading_from_pretrained.convert_gptj_weights"]], "convert_hf_model_config() (in module transformer_lens.loading_from_pretrained)": [[9, "transformer_lens.loading_from_pretrained.convert_hf_model_config"]], "convert_neel_model_config() (in module transformer_lens.loading_from_pretrained)": [[9, "transformer_lens.loading_from_pretrained.convert_neel_model_config"]], "convert_neel_solu_old_weights() (in module transformer_lens.loading_from_pretrained)": [[9, "transformer_lens.loading_from_pretrained.convert_neel_solu_old_weights"]], "convert_neo_weights() (in module transformer_lens.loading_from_pretrained)": [[9, "transformer_lens.loading_from_pretrained.convert_neo_weights"]], "convert_neox_weights() (in module transformer_lens.loading_from_pretrained)": [[9, "transformer_lens.loading_from_pretrained.convert_neox_weights"]], "convert_opt_weights() (in module transformer_lens.loading_from_pretrained)": [[9, "transformer_lens.loading_from_pretrained.convert_opt_weights"]], "convert_state_dict() (in module transformer_lens.loading_from_pretrained)": [[9, "transformer_lens.loading_from_pretrained.convert_state_dict"]], "cpu() (transformer_lens.hookedtransformer.hookedtransformer method)": [[9, "transformer_lens.HookedTransformer.HookedTransformer.cpu"]], "cuda() (transformer_lens.hookedtransformer.hookedtransformer method)": [[9, "transformer_lens.HookedTransformer.HookedTransformer.cuda"]], "d_head (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[9, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.d_head"]], "d_head (transformer_lens.torchtyping_helper.t attribute)": [[9, "transformer_lens.torchtyping_helper.T.d_head"]], "d_mlp (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[9, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.d_mlp"]], "d_mlp (transformer_lens.torchtyping_helper.t attribute)": [[9, "transformer_lens.torchtyping_helper.T.d_mlp"]], "d_model (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[9, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.d_model"]], "d_model (transformer_lens.torchtyping_helper.t attribute)": [[9, "transformer_lens.torchtyping_helper.T.d_model"]], "d_vocab (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[9, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.d_vocab"]], "d_vocab (transformer_lens.torchtyping_helper.t attribute)": [[9, "transformer_lens.torchtyping_helper.T.d_vocab"]], "d_vocab_out (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[9, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.d_vocab_out"]], "d_vocab_out (transformer_lens.torchtyping_helper.t attribute)": [[9, "transformer_lens.torchtyping_helper.T.d_vocab_out"]], "d_vocab_plus_n_ctx (transformer_lens.torchtyping_helper.t attribute)": [[9, "transformer_lens.torchtyping_helper.T.d_vocab_plus_n_ctx"]], "decompose_resid() (transformer_lens.activationcache.activationcache method)": [[9, "transformer_lens.ActivationCache.ActivationCache.decompose_resid"]], "device (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[9, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.device"]], "device (transformer_lens.train.hookedtransformertrainconfig attribute)": [[9, "transformer_lens.train.HookedTransformerTrainConfig.device"]], "download_file_from_hf() (in module transformer_lens.utils)": [[9, "transformer_lens.utils.download_file_from_hf"]], "eigenvalues (transformer_lens.factoredmatrix.factoredmatrix property)": [[9, "transformer_lens.FactoredMatrix.FactoredMatrix.eigenvalues"]], "entries (transformer_lens.past_key_value_caching.hookedtransformerkeyvaluecache attribute)": [[9, "transformer_lens.past_key_value_caching.HookedTransformerKeyValueCache.entries"]], "eps (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[9, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.eps"]], "evaluate() (in module transformer_lens.evals)": [[9, "transformer_lens.evals.evaluate"]], "evaluate_on_dataset() (in module transformer_lens.evals)": [[9, "transformer_lens.evals.evaluate_on_dataset"]], "fill_missing_keys() (transformer_lens.hookedtransformer.hookedtransformer method)": [[9, "transformer_lens.HookedTransformer.HookedTransformer.fill_missing_keys"]], "final_rms (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[9, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.final_rms"]], "fold_layer_norm() (transformer_lens.hookedtransformer.hookedtransformer method)": [[9, "transformer_lens.HookedTransformer.HookedTransformer.fold_layer_norm"]], "fold_value_biases() (transformer_lens.hookedtransformer.hookedtransformer method)": [[9, "transformer_lens.HookedTransformer.HookedTransformer.fold_value_biases"]], "forward() (transformer_lens.hookedtransformer.hookedtransformer method)": [[9, "transformer_lens.HookedTransformer.HookedTransformer.forward"]], "forward() (transformer_lens.components.attention method)": [[9, "transformer_lens.components.Attention.forward"]], "forward() (transformer_lens.components.embed method)": [[9, "transformer_lens.components.Embed.forward"]], "forward() (transformer_lens.components.layernorm method)": [[9, "transformer_lens.components.LayerNorm.forward"]], "forward() (transformer_lens.components.layernormpre method)": [[9, "transformer_lens.components.LayerNormPre.forward"]], "forward() (transformer_lens.components.mlp method)": [[9, "transformer_lens.components.MLP.forward"]], "forward() (transformer_lens.components.posembed method)": [[9, "transformer_lens.components.PosEmbed.forward"]], "forward() (transformer_lens.components.rmsnorm method)": [[9, "transformer_lens.components.RMSNorm.forward"]], "forward() (transformer_lens.components.rmsnormpre method)": [[9, "transformer_lens.components.RMSNormPre.forward"]], "forward() (transformer_lens.components.transformerblock method)": [[9, "transformer_lens.components.TransformerBlock.forward"]], "forward() (transformer_lens.components.unembed method)": [[9, "transformer_lens.components.Unembed.forward"]], "forward() (transformer_lens.hook_points.hookpoint method)": [[9, "transformer_lens.hook_points.HookPoint.forward"]], "from_checkpoint (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[9, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.from_checkpoint"]], "from_dict() (transformer_lens.hookedtransformerconfig.hookedtransformerconfig class method)": [[9, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.from_dict"]], "from_pretrained() (transformer_lens.hookedtransformer.hookedtransformer class method)": [[9, "transformer_lens.HookedTransformer.HookedTransformer.from_pretrained"]], "from_pretrained_no_processing() (transformer_lens.hookedtransformer.hookedtransformer class method)": [[9, "transformer_lens.HookedTransformer.HookedTransformer.from_pretrained_no_processing"]], "gelu_fast() (in module transformer_lens.utils)": [[9, "transformer_lens.utils.gelu_fast"]], "gelu_new() (in module transformer_lens.utils)": [[9, "transformer_lens.utils.gelu_new"]], "generate() (transformer_lens.hookedtransformer.hookedtransformer method)": [[9, "transformer_lens.HookedTransformer.HookedTransformer.generate"]], "generic_activation_patch() (in module transformer_lens.patching)": [[9, "transformer_lens.patching.generic_activation_patch"]], "get_act_name() (in module transformer_lens.utils)": [[9, "transformer_lens.utils.get_act_name"]], "get_act_patch_attn_head_all_pos_every() (in module transformer_lens.patching)": [[9, "transformer_lens.patching.get_act_patch_attn_head_all_pos_every"]], "get_act_patch_attn_head_by_pos_every() (in module transformer_lens.patching)": [[9, "transformer_lens.patching.get_act_patch_attn_head_by_pos_every"]], "get_act_patch_attn_head_k_all_pos() (in module transformer_lens.patching)": [[9, "transformer_lens.patching.get_act_patch_attn_head_k_all_pos"]], "get_act_patch_attn_head_k_by_pos() (in module transformer_lens.patching)": [[9, "transformer_lens.patching.get_act_patch_attn_head_k_by_pos"]], "get_act_patch_attn_head_out_all_pos() (in module transformer_lens.patching)": [[9, "transformer_lens.patching.get_act_patch_attn_head_out_all_pos"]], "get_act_patch_attn_head_out_by_pos() (in module transformer_lens.patching)": [[9, "transformer_lens.patching.get_act_patch_attn_head_out_by_pos"]], "get_act_patch_attn_head_pattern_all_pos() (in module transformer_lens.patching)": [[9, "transformer_lens.patching.get_act_patch_attn_head_pattern_all_pos"]], "get_act_patch_attn_head_pattern_by_pos() (in module transformer_lens.patching)": [[9, "transformer_lens.patching.get_act_patch_attn_head_pattern_by_pos"]], "get_act_patch_attn_head_pattern_dest_src_pos() (in module transformer_lens.patching)": [[9, "transformer_lens.patching.get_act_patch_attn_head_pattern_dest_src_pos"]], "get_act_patch_attn_head_q_all_pos() (in module transformer_lens.patching)": [[9, "transformer_lens.patching.get_act_patch_attn_head_q_all_pos"]], "get_act_patch_attn_head_q_by_pos() (in module transformer_lens.patching)": [[9, "transformer_lens.patching.get_act_patch_attn_head_q_by_pos"]], "get_act_patch_attn_head_v_all_pos() (in module transformer_lens.patching)": [[9, "transformer_lens.patching.get_act_patch_attn_head_v_all_pos"]], "get_act_patch_attn_head_v_by_pos() (in module transformer_lens.patching)": [[9, "transformer_lens.patching.get_act_patch_attn_head_v_by_pos"]], "get_act_patch_attn_out() (in module transformer_lens.patching)": [[9, "transformer_lens.patching.get_act_patch_attn_out"]], "get_act_patch_block_every() (in module transformer_lens.patching)": [[9, "transformer_lens.patching.get_act_patch_block_every"]], "get_act_patch_mlp_out() (in module transformer_lens.patching)": [[9, "transformer_lens.patching.get_act_patch_mlp_out"]], "get_act_patch_resid_mid() (in module transformer_lens.patching)": [[9, "transformer_lens.patching.get_act_patch_resid_mid"]], "get_act_patch_resid_pre() (in module transformer_lens.patching)": [[9, "transformer_lens.patching.get_act_patch_resid_pre"]], "get_checkpoint_labels() (in module transformer_lens.loading_from_pretrained)": [[9, "transformer_lens.loading_from_pretrained.get_checkpoint_labels"]], "get_corner() (in module transformer_lens.utils)": [[9, "transformer_lens.utils.get_corner"]], "get_corner() (transformer_lens.factoredmatrix.factoredmatrix method)": [[9, "transformer_lens.FactoredMatrix.FactoredMatrix.get_corner"]], "get_dataset() (in module transformer_lens.utils)": [[9, "transformer_lens.utils.get_dataset"]], "get_full_resid_decomposition() (transformer_lens.activationcache.activationcache method)": [[9, "transformer_lens.ActivationCache.ActivationCache.get_full_resid_decomposition"]], "get_neuron_results() (transformer_lens.activationcache.activationcache method)": [[9, "transformer_lens.ActivationCache.ActivationCache.get_neuron_results"]], "get_num_params_of_pretrained() (in module transformer_lens.loading_from_pretrained)": [[9, "transformer_lens.loading_from_pretrained.get_num_params_of_pretrained"]], "get_official_model_name() (in module transformer_lens.loading_from_pretrained)": [[9, "transformer_lens.loading_from_pretrained.get_official_model_name"]], "get_pretrained_model_config() (in module transformer_lens.loading_from_pretrained)": [[9, "transformer_lens.loading_from_pretrained.get_pretrained_model_config"]], "get_pretrained_state_dict() (in module transformer_lens.loading_from_pretrained)": [[9, "transformer_lens.loading_from_pretrained.get_pretrained_state_dict"]], "get_token_position() (transformer_lens.hookedtransformer.hookedtransformer method)": [[9, "transformer_lens.HookedTransformer.HookedTransformer.get_token_position"]], "head_index (transformer_lens.torchtyping_helper.t attribute)": [[9, "transformer_lens.torchtyping_helper.T.head_index"]], "hook (transformer_lens.hook_points.lenshandle attribute)": [[9, "transformer_lens.hook_points.LensHandle.hook"]], "hook_points() (transformer_lens.hook_points.hookedrootmodule method)": [[9, "transformer_lens.hook_points.HookedRootModule.hook_points"]], "indices() (transformer_lens.utils.slice method)": [[9, "transformer_lens.utils.Slice.indices"]], "induction_loss() (in module transformer_lens.evals)": [[9, "transformer_lens.evals.induction_loss"]], "init_cache() (transformer_lens.past_key_value_caching.hookedtransformerkeyvaluecache class method)": [[9, "transformer_lens.past_key_value_caching.HookedTransformerKeyValueCache.init_cache"]], "init_cache_entry() (transformer_lens.past_key_value_caching.hookedtransformerkeyvaluecacheentry class method)": [[9, "transformer_lens.past_key_value_caching.HookedTransformerKeyValueCacheEntry.init_cache_entry"]], "init_mode (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[9, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.init_mode"]], "init_weights (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[9, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.init_weights"]], "init_weights() (transformer_lens.hookedtransformer.hookedtransformer method)": [[9, "transformer_lens.HookedTransformer.HookedTransformer.init_weights"]], "initializer_range (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[9, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.initializer_range"]], "is_permanent (transformer_lens.hook_points.lenshandle attribute)": [[9, "transformer_lens.hook_points.LensHandle.is_permanent"]], "items() (transformer_lens.activationcache.activationcache method)": [[9, "transformer_lens.ActivationCache.ActivationCache.items"]], "keep_single_column() (in module transformer_lens.utils)": [[9, "transformer_lens.utils.keep_single_column"]], "keys() (transformer_lens.activationcache.activationcache method)": [[9, "transformer_lens.ActivationCache.ActivationCache.keys"]], "layer() (transformer_lens.hook_points.hookpoint method)": [[9, "transformer_lens.hook_points.HookPoint.layer"]], "layer_head_dest_src_pos_pattern_patch_setter() (in module transformer_lens.patching)": [[9, "transformer_lens.patching.layer_head_dest_src_pos_pattern_patch_setter"]], "layer_head_pattern_patch_setter() (in module transformer_lens.patching)": [[9, "transformer_lens.patching.layer_head_pattern_patch_setter"]], "layer_head_pos_pattern_patch_setter() (in module transformer_lens.patching)": [[9, "transformer_lens.patching.layer_head_pos_pattern_patch_setter"]], "layer_head_vector_patch_setter() (in module transformer_lens.patching)": [[9, "transformer_lens.patching.layer_head_vector_patch_setter"]], "layer_pos_head_vector_patch_setter() (in module transformer_lens.patching)": [[9, "transformer_lens.patching.layer_pos_head_vector_patch_setter"]], "layer_pos_patch_setter() (in module transformer_lens.patching)": [[9, "transformer_lens.patching.layer_pos_patch_setter"]], "layers_accumulated_over (transformer_lens.torchtyping_helper.t attribute)": [[9, "transformer_lens.torchtyping_helper.T.layers_accumulated_over"]], "layers_covered (transformer_lens.torchtyping_helper.t attribute)": [[9, "transformer_lens.torchtyping_helper.T.layers_covered"]], "ldim (transformer_lens.torchtyping_helper.t attribute)": [[9, "transformer_lens.torchtyping_helper.T.ldim"]], "leading_dims (transformer_lens.torchtyping_helper.t attribute)": [[9, "transformer_lens.torchtyping_helper.T.leading_dims"]], "leading_dims_left (transformer_lens.torchtyping_helper.t attribute)": [[9, "transformer_lens.torchtyping_helper.T.leading_dims_left"]], "leading_dims_right (transformer_lens.torchtyping_helper.t attribute)": [[9, "transformer_lens.torchtyping_helper.T.leading_dims_right"]], "length (transformer_lens.torchtyping_helper.t attribute)": [[9, "transformer_lens.torchtyping_helper.T.length"]], "lm_accuracy() (in module transformer_lens.utils)": [[9, "transformer_lens.utils.lm_accuracy"]], "lm_cross_entropy_loss() (in module transformer_lens.utils)": [[9, "transformer_lens.utils.lm_cross_entropy_loss"]], "load_and_process_state_dict() (transformer_lens.hookedtransformer.hookedtransformer method)": [[9, "transformer_lens.HookedTransformer.HookedTransformer.load_and_process_state_dict"]], "load_sample_training_dataset() (transformer_lens.hookedtransformer.hookedtransformer method)": [[9, "transformer_lens.HookedTransformer.HookedTransformer.load_sample_training_dataset"]], "logits (transformer_lens.hookedtransformer.output attribute)": [[9, "transformer_lens.HookedTransformer.Output.logits"]], "loss (transformer_lens.hookedtransformer.output attribute)": [[9, "transformer_lens.HookedTransformer.Output.loss"]], "loss_fn() (transformer_lens.hookedtransformer.hookedtransformer method)": [[9, "transformer_lens.HookedTransformer.HookedTransformer.loss_fn"]], "lr (transformer_lens.train.hookedtransformertrainconfig attribute)": [[9, "transformer_lens.train.HookedTransformerTrainConfig.lr"]], "make_code_data_loader() (in module transformer_lens.evals)": [[9, "transformer_lens.evals.make_code_data_loader"]], "make_df_from_ranges() (in module transformer_lens.patching)": [[9, "transformer_lens.patching.make_df_from_ranges"]], "make_even() (transformer_lens.factoredmatrix.factoredmatrix method)": [[9, "transformer_lens.FactoredMatrix.FactoredMatrix.make_even"]], "make_model_alias_map() (in module transformer_lens.loading_from_pretrained)": [[9, "transformer_lens.loading_from_pretrained.make_model_alias_map"]], "make_owt_data_loader() (in module transformer_lens.evals)": [[9, "transformer_lens.evals.make_owt_data_loader"]], "make_pile_data_loader() (in module transformer_lens.evals)": [[9, "transformer_lens.evals.make_pile_data_loader"]], "make_wiki_data_loader() (in module transformer_lens.evals)": [[9, "transformer_lens.evals.make_wiki_data_loader"]], "max_grad_norm (transformer_lens.train.hookedtransformertrainconfig attribute)": [[9, "transformer_lens.train.HookedTransformerTrainConfig.max_grad_norm"]], "max_steps (transformer_lens.train.hookedtransformertrainconfig attribute)": [[9, "transformer_lens.train.HookedTransformerTrainConfig.max_steps"]], "mdim (transformer_lens.torchtyping_helper.t attribute)": [[9, "transformer_lens.torchtyping_helper.T.mdim"]], "model_name (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[9, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.model_name"]], "momentum (transformer_lens.train.hookedtransformertrainconfig attribute)": [[9, "transformer_lens.train.HookedTransformerTrainConfig.momentum"]], "n_ctx (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[9, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.n_ctx"]], "n_ctx (transformer_lens.torchtyping_helper.t attribute)": [[9, "transformer_lens.torchtyping_helper.T.n_ctx"]], "n_heads (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[9, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.n_heads"]], "n_heads (transformer_lens.torchtyping_helper.t attribute)": [[9, "transformer_lens.torchtyping_helper.T.n_heads"]], "n_layers (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[9, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.n_layers"]], "n_layers (transformer_lens.torchtyping_helper.t attribute)": [[9, "transformer_lens.torchtyping_helper.T.n_layers"]], "n_params (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[9, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.n_params"]], "ndim (transformer_lens.factoredmatrix.factoredmatrix property)": [[9, "transformer_lens.FactoredMatrix.FactoredMatrix.ndim"]], "new_rdim (transformer_lens.torchtyping_helper.t attribute)": [[9, "transformer_lens.torchtyping_helper.T.new_rdim"]], "new_tokens (transformer_lens.torchtyping_helper.t attribute)": [[9, "transformer_lens.torchtyping_helper.T.new_tokens"]], "norm() (transformer_lens.factoredmatrix.factoredmatrix method)": [[9, "transformer_lens.FactoredMatrix.FactoredMatrix.norm"]], "normalization_type (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[9, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.normalization_type"]], "num_components (transformer_lens.torchtyping_helper.t attribute)": [[9, "transformer_lens.torchtyping_helper.T.num_components"]], "num_epochs (transformer_lens.train.hookedtransformertrainconfig attribute)": [[9, "transformer_lens.train.HookedTransformerTrainConfig.num_epochs"]], "num_neurons (transformer_lens.torchtyping_helper.t attribute)": [[9, "transformer_lens.torchtyping_helper.T.num_neurons"]], "optimizer_name (transformer_lens.train.hookedtransformertrainconfig attribute)": [[9, "transformer_lens.train.HookedTransformerTrainConfig.optimizer_name"]], "original_architecture (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[9, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.original_architecture"]], "pair (transformer_lens.factoredmatrix.factoredmatrix property)": [[9, "transformer_lens.FactoredMatrix.FactoredMatrix.pair"]], "parallel_attn_mlp (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[9, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.parallel_attn_mlp"]], "past_keys (transformer_lens.past_key_value_caching.hookedtransformerkeyvaluecacheentry attribute)": [[9, "transformer_lens.past_key_value_caching.HookedTransformerKeyValueCacheEntry.past_keys"]], "past_kv_pos_offset (transformer_lens.torchtyping_helper.t attribute)": [[9, "transformer_lens.torchtyping_helper.T.past_kv_pos_offset"]], "past_values (transformer_lens.past_key_value_caching.hookedtransformerkeyvaluecacheentry attribute)": [[9, "transformer_lens.past_key_value_caching.HookedTransformerKeyValueCacheEntry.past_values"]], "pos (transformer_lens.torchtyping_helper.t attribute)": [[9, "transformer_lens.torchtyping_helper.T.pos"]], "pos_plus_new_tokens (transformer_lens.torchtyping_helper.t attribute)": [[9, "transformer_lens.torchtyping_helper.T.pos_plus_new_tokens"]], "pos_plus_past_kv_pos_offset (transformer_lens.torchtyping_helper.t attribute)": [[9, "transformer_lens.torchtyping_helper.T.pos_plus_past_kv_pos_offset"]], "pos_so_far (transformer_lens.torchtyping_helper.t attribute)": [[9, "transformer_lens.torchtyping_helper.T.pos_so_far"]], "positional_embedding_type (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[9, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.positional_embedding_type"]], "print_every (transformer_lens.train.hookedtransformertrainconfig attribute)": [[9, "transformer_lens.train.HookedTransformerTrainConfig.print_every"]], "print_gpu_mem() (in module transformer_lens.utils)": [[9, "transformer_lens.utils.print_gpu_mem"]], "process_weights_() (transformer_lens.hookedtransformer.hookedtransformer method)": [[9, "transformer_lens.HookedTransformer.HookedTransformer.process_weights_"]], "rdim (transformer_lens.torchtyping_helper.t attribute)": [[9, "transformer_lens.torchtyping_helper.T.rdim"]], "refactor_factored_attn_matrices() (transformer_lens.hookedtransformer.hookedtransformer method)": [[9, "transformer_lens.HookedTransformer.HookedTransformer.refactor_factored_attn_matrices"]], "remove_all_hook_fns() (transformer_lens.hook_points.hookedrootmodule method)": [[9, "transformer_lens.hook_points.HookedRootModule.remove_all_hook_fns"]], "remove_batch_dim() (in module transformer_lens.utils)": [[9, "transformer_lens.utils.remove_batch_dim"]], "remove_batch_dim() (transformer_lens.activationcache.activationcache method)": [[9, "transformer_lens.ActivationCache.ActivationCache.remove_batch_dim"]], "remove_hooks() (transformer_lens.hook_points.hookpoint method)": [[9, "transformer_lens.hook_points.HookPoint.remove_hooks"]], "reset_hooks() (transformer_lens.hook_points.hookedrootmodule method)": [[9, "transformer_lens.hook_points.HookedRootModule.reset_hooks"]], "rotary_dim (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[9, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.rotary_dim"]], "rotary_dim (transformer_lens.torchtyping_helper.t attribute)": [[9, "transformer_lens.torchtyping_helper.T.rotary_dim"]], "rotary_rotate_qk() (transformer_lens.components.attention method)": [[9, "transformer_lens.components.Attention.rotary_rotate_qk"]], "rotate_every_two() (transformer_lens.components.attention method)": [[9, "transformer_lens.components.Attention.rotate_every_two"]], "run_with_cache() (transformer_lens.hookedtransformer.hookedtransformer method)": [[9, "transformer_lens.HookedTransformer.HookedTransformer.run_with_cache"]], "run_with_cache() (transformer_lens.hook_points.hookedrootmodule method)": [[9, "transformer_lens.hook_points.HookedRootModule.run_with_cache"]], "run_with_hooks() (transformer_lens.hook_points.hookedrootmodule method)": [[9, "transformer_lens.hook_points.HookedRootModule.run_with_hooks"]], "sample_datapoint() (transformer_lens.hookedtransformer.hookedtransformer method)": [[9, "transformer_lens.HookedTransformer.HookedTransformer.sample_datapoint"]], "sample_logits() (in module transformer_lens.utils)": [[9, "transformer_lens.utils.sample_logits"]], "sanity_check() (in module transformer_lens.evals)": [[9, "transformer_lens.evals.sanity_check"]], "save_dir (transformer_lens.train.hookedtransformertrainconfig attribute)": [[9, "transformer_lens.train.HookedTransformerTrainConfig.save_dir"]], "save_every (transformer_lens.train.hookedtransformertrainconfig attribute)": [[9, "transformer_lens.train.HookedTransformerTrainConfig.save_every"]], "scale_attn_by_inverse_layer_idx (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[9, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.scale_attn_by_inverse_layer_idx"]], "seed (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[9, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.seed"]], "seed (transformer_lens.train.hookedtransformertrainconfig attribute)": [[9, "transformer_lens.train.HookedTransformerTrainConfig.seed"]], "set_seed_everywhere() (transformer_lens.hookedtransformerconfig.hookedtransformerconfig method)": [[9, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.set_seed_everywhere"]], "set_tokenizer() (transformer_lens.hookedtransformer.hookedtransformer method)": [[9, "transformer_lens.HookedTransformer.HookedTransformer.set_tokenizer"]], "set_use_attn_result() (transformer_lens.hookedtransformer.hookedtransformer method)": [[9, "transformer_lens.HookedTransformer.HookedTransformer.set_use_attn_result"]], "setup() (transformer_lens.hook_points.hookedrootmodule method)": [[9, "transformer_lens.hook_points.HookedRootModule.setup"]], "shortformer_calculate_qk() (transformer_lens.components.attention method)": [[9, "transformer_lens.components.Attention.shortformer_calculate_qk"]], "solu() (in module transformer_lens.utils)": [[9, "transformer_lens.utils.solu"]], "stack_activation() (transformer_lens.activationcache.activationcache method)": [[9, "transformer_lens.ActivationCache.ActivationCache.stack_activation"]], "stack_head_results() (transformer_lens.activationcache.activationcache method)": [[9, "transformer_lens.ActivationCache.ActivationCache.stack_head_results"]], "stack_neuron_results() (transformer_lens.activationcache.activationcache method)": [[9, "transformer_lens.ActivationCache.ActivationCache.stack_neuron_results"]], "svd() (transformer_lens.factoredmatrix.factoredmatrix method)": [[9, "transformer_lens.FactoredMatrix.FactoredMatrix.svd"]], "test_prompt() (in module transformer_lens.utils)": [[9, "transformer_lens.utils.test_prompt"]], "to() (transformer_lens.activationcache.activationcache method)": [[9, "transformer_lens.ActivationCache.ActivationCache.to"]], "to() (transformer_lens.hookedtransformer.hookedtransformer method)": [[9, "transformer_lens.HookedTransformer.HookedTransformer.to"]], "to_dict() (transformer_lens.hookedtransformerconfig.hookedtransformerconfig method)": [[9, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.to_dict"]], "to_numpy() (in module transformer_lens.utils)": [[9, "transformer_lens.utils.to_numpy"]], "to_single_token() (transformer_lens.hookedtransformer.hookedtransformer method)": [[9, "transformer_lens.HookedTransformer.HookedTransformer.to_single_token"]], "to_str_tokens() (transformer_lens.hookedtransformer.hookedtransformer method)": [[9, "transformer_lens.HookedTransformer.HookedTransformer.to_str_tokens"]], "to_string() (transformer_lens.hookedtransformer.hookedtransformer method)": [[9, "transformer_lens.HookedTransformer.HookedTransformer.to_string"]], "to_tokens() (transformer_lens.hookedtransformer.hookedtransformer method)": [[9, "transformer_lens.HookedTransformer.HookedTransformer.to_tokens"]], "toggle_autodiff() (transformer_lens.activationcache.activationcache method)": [[9, "transformer_lens.ActivationCache.ActivationCache.toggle_autodiff"]], "tokenize_and_concatenate() (in module transformer_lens.utils)": [[9, "transformer_lens.utils.tokenize_and_concatenate"]], "tokenizer_name (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[9, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.tokenizer_name"]], "tokens_to_residual_directions() (transformer_lens.hookedtransformer.hookedtransformer method)": [[9, "transformer_lens.HookedTransformer.HookedTransformer.tokens_to_residual_directions"]], "train() (in module transformer_lens.train)": [[9, "transformer_lens.train.train"]], "training (transformer_lens.hookedtransformer.hookedtransformer attribute)": [[9, "transformer_lens.HookedTransformer.HookedTransformer.training"]], "training (transformer_lens.components.attention attribute)": [[9, "transformer_lens.components.Attention.training"]], "training (transformer_lens.components.embed attribute)": [[9, "transformer_lens.components.Embed.training"]], "training (transformer_lens.components.layernorm attribute)": [[9, "transformer_lens.components.LayerNorm.training"]], "training (transformer_lens.components.layernormpre attribute)": [[9, "transformer_lens.components.LayerNormPre.training"]], "training (transformer_lens.components.mlp attribute)": [[9, "transformer_lens.components.MLP.training"]], "training (transformer_lens.components.posembed attribute)": [[9, "transformer_lens.components.PosEmbed.training"]], "training (transformer_lens.components.rmsnorm attribute)": [[9, "transformer_lens.components.RMSNorm.training"]], "training (transformer_lens.components.rmsnormpre attribute)": [[9, "transformer_lens.components.RMSNormPre.training"]], "training (transformer_lens.components.transformerblock attribute)": [[9, "transformer_lens.components.TransformerBlock.training"]], "training (transformer_lens.components.unembed attribute)": [[9, "transformer_lens.components.Unembed.training"]], "training (transformer_lens.hook_points.hookpoint attribute)": [[9, "transformer_lens.hook_points.HookPoint.training"]], "training (transformer_lens.hook_points.hookedrootmodule attribute)": [[9, "transformer_lens.hook_points.HookedRootModule.training"]], "transformer_lens": [[9, "module-transformer_lens"]], "transformer_lens.activationcache": [[9, "module-transformer_lens.ActivationCache"]], "transformer_lens.factoredmatrix": [[9, "module-transformer_lens.FactoredMatrix"]], "transformer_lens.hookedtransformer": [[9, "module-transformer_lens.HookedTransformer"]], "transformer_lens.hookedtransformerconfig": [[9, "module-transformer_lens.HookedTransformerConfig"]], "transformer_lens.components": [[9, "module-transformer_lens.components"]], "transformer_lens.evals": [[9, "module-transformer_lens.evals"]], "transformer_lens.hook_points": [[9, "module-transformer_lens.hook_points"]], "transformer_lens.loading_from_pretrained": [[9, "module-transformer_lens.loading_from_pretrained"]], "transformer_lens.past_key_value_caching": [[9, "module-transformer_lens.past_key_value_caching"]], "transformer_lens.patching": [[9, "module-transformer_lens.patching"]], "transformer_lens.torchtyping_helper": [[9, "module-transformer_lens.torchtyping_helper"]], "transformer_lens.train": [[9, "module-transformer_lens.train"]], "transformer_lens.utils": [[9, "module-transformer_lens.utils"]], "transpose() (in module transformer_lens.utils)": [[9, "transformer_lens.utils.transpose"]], "unsqueeze() (transformer_lens.factoredmatrix.factoredmatrix method)": [[9, "transformer_lens.FactoredMatrix.FactoredMatrix.unsqueeze"]], "use_attn_result (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[9, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.use_attn_result"]], "use_attn_scale (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[9, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.use_attn_scale"]], "use_hook_tokens (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[9, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.use_hook_tokens"]], "use_local_attn (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[9, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.use_local_attn"]], "values() (transformer_lens.activationcache.activationcache method)": [[9, "transformer_lens.ActivationCache.ActivationCache.values"]], "wandb (transformer_lens.train.hookedtransformertrainconfig attribute)": [[9, "transformer_lens.train.HookedTransformerTrainConfig.wandb"]], "wandb_project_name (transformer_lens.train.hookedtransformertrainconfig attribute)": [[9, "transformer_lens.train.HookedTransformerTrainConfig.wandb_project_name"]], "warmup_steps (transformer_lens.train.hookedtransformertrainconfig attribute)": [[9, "transformer_lens.train.HookedTransformerTrainConfig.warmup_steps"]], "weight_decay (transformer_lens.train.hookedtransformertrainconfig attribute)": [[9, "transformer_lens.train.HookedTransformerTrainConfig.weight_decay"]], "window_size (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[9, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.window_size"]], "test() (in module typing_demo)": [[10, "typing_demo.test"]], "test2() (in module typing_demo)": [[10, "typing_demo.test2"]], "test3() (in module typing_demo)": [[10, "typing_demo.test3"]], "test4() (in module typing_demo)": [[10, "typing_demo.test4"]], "typing_demo": [[10, "module-typing_demo"]]}})